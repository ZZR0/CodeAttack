Some weights of the model checkpoint at microsoft/codebert-base were not used when initializing RobertaForSequenceClassification: ['pooler.dense.weight', 'pooler.dense.bias']
- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).
- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).
Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['classifier.out_proj.weight', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.bias']
You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.
  0%|          | 0/2690 [00:00<?, ?it/s]  0%|          | 1/2690 [00:00<11:12,  4.00it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 1 / 1:   0%|          | 1/2690 [00:00<11:13,  3.99it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 2 / 2:   0%|          | 2/2690 [00:00<05:52,  7.63it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 3 / 3:   0%|          | 3/2690 [00:00<04:03, 11.05it/s]Attack(
  (search_method): GreedyWordSwapWIR(
    (wir_method):  delete
  )
  (goal_function):  DefectClassification
  (transformation):  WordSwapEmbedding(
    (max_candidates):  50
    (embedding):  WordEmbedding
  )
  (constraints): 
    (0): MaxWordsPerturbed(
        (max_num_words):  5
        (compare_against_original):  True
      )
    (1): KeyWord(
        (compare_against_original):  True
      )
    (2): RepeatModification
  (is_black_box):  True
) 

--------------------------------------------- Result 1 ---------------------------------------------
[[0 (51%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: int ff_get_wav_header(AVFormatContext *s, AVIOContext *pb, AVCodecContext *codec, int size, int big_endian) { int id; uint64_t bitrate; if (size < 14) { avpriv_request_sample(codec, "wav header size < 14"); return AVERROR_INVALIDDATA; } codec->codec_type = AVMEDIA_TYPE_AUDIO; if (!big_endian) { id = avio_rl16(pb); if (id != 0x0165) { codec->channels = avio_rl16(pb); codec->sample_rate = avio_rl32(pb); bitrate = avio_rl32(pb) * 8LL; codec->block_align = avio_rl16(pb); } } else { id = avio_rb16(pb); codec->channels = avio_rb16(pb); codec->sample_rate = avio_rb32(pb); bitrate = avio_rb32(pb) * 8LL; codec->block_align = avio_rb16(pb); } if (size == 14) { codec->bits_per_coded_sample = 8; } else { if (!big_endian) { codec->bits_per_coded_sample = avio_rl16(pb); } else { codec->bits_per_coded_sample = avio_rb16(pb); } } if (id == 0xFFFE) { codec->codec_tag = 0; } else { codec->codec_tag = id; codec->codec_id = ff_wav_codec_get_id(id, codec->bits_per_coded_sample); } if (size >= 18 && id != 0x0165) { int cbSize = avio_rl16(pb); if (big_endian) { avpriv_report_missing_feature(codec, "WAVEFORMATEX support for RIFX files\n"); return AVERROR_PATCHWELCOME; } size -= 18; cbSize = FFMIN(size, cbSize); if (cbSize >= 22 && id == 0xfffe) { parse_waveformatex(pb, codec); cbSize -= 22; size -= 22; } if (cbSize > 0) { av_freep(&codec->extradata); if (ff_get_extradata(codec, pb, cbSize) < 0) return AVERROR(ENOMEM); size -= cbSize; } if (size > 0) avio_skip(pb, size); } else if (id == 0x0165 && size >= 32) { int nb_streams, i; size -= 4; av_freep(&codec->extradata); if (ff_get_extradata(codec, pb, size) < 0) return AVERROR(ENOMEM); nb_streams = AV_RL16(codec->extradata + 4); codec->sample_rate = AV_RL32(codec->extradata + 12); codec->channels = 0; bitrate = 0; if (size < 8 + nb_streams * 20) return AVERROR_INVALIDDATA; for (i = 0; i < nb_streams; i++) codec->channels += codec->extradata[8 + i * 20 + 17]; } if (bitrate > INT_MAX) { if (s->error_recognition & AV_EF_EXPLODE) { av_log(s, AV_LOG_ERROR, "The bitrate %"PRIu64" is too large.\n", bitrate); return AVERROR_INVALIDDATA; } else { av_log(s, AV_LOG_WARNING, "The bitrate %"PRIu64" is too large, resetting to 0.", bitrate); codec->bit_rate = 0; } } else { codec->bit_rate = bitrate; } if (codec->sample_rate <= 0) { av_log(s, AV_LOG_ERROR, "Invalid sample rate: %d\n", codec->sample_rate); return AVERROR_INVALIDDATA; } if (codec->codec_id == AV_CODEC_ID_AAC_LATM) { codec->channels = 0; codec->sample_rate = 0; } if (codec->codec_id == AV_CODEC_ID_ADPCM_G726 && codec->sample_rate) codec->bits_per_coded_sample = codec->bit_rate / codec->sample_rate; return 0; }


--------------------------------------------- Result 2 ---------------------------------------------
[[0 (43%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int xen_9pfs_connect(struct XenDevice *xendev) { int i; Xen9pfsDev *xen_9pdev = container_of(xendev, Xen9pfsDev, xendev); V9fsState *s = &xen_9pdev->state; QemuOpts *fsdev; if (xenstore_read_fe_int(&xen_9pdev->xendev, "num-rings", &xen_9pdev->num_rings) == -1 || xen_9pdev->num_rings > MAX_RINGS || xen_9pdev->num_rings < 1) { return -1; } xen_9pdev->rings = g_malloc0(xen_9pdev->num_rings * sizeof(Xen9pfsRing)); for (i = 0; i < xen_9pdev->num_rings; i++) { char *str; int ring_order; xen_9pdev->rings[i].priv = xen_9pdev; xen_9pdev->rings[i].evtchn = -1; xen_9pdev->rings[i].local_port = -1; str = g_strdup_printf("ring-ref%u", i); if (xenstore_read_fe_int(&xen_9pdev->xendev, str, &xen_9pdev->rings[i].ref) == -1) { goto out; } str = g_strdup_printf("event-channel-%u", i); if (xenstore_read_fe_int(&xen_9pdev->xendev, str, &xen_9pdev->rings[i].evtchn) == -1) { goto out; } xen_9pdev->rings[i].intf = xengnttab_map_grant_ref( xen_9pdev->xendev.gnttabdev, xen_9pdev->xendev.dom, xen_9pdev->rings[i].ref, PROT_READ | PROT_WRITE); if (!xen_9pdev->rings[i].intf) { goto out; } ring_order = xen_9pdev->rings[i].intf->ring_order; if (ring_order > MAX_RING_ORDER) { goto out; } xen_9pdev->rings[i].ring_order = ring_order; xen_9pdev->rings[i].data = xengnttab_map_domain_grant_refs( xen_9pdev->xendev.gnttabdev, (1 << ring_order), xen_9pdev->xendev.dom, xen_9pdev->rings[i].intf->ref, PROT_READ | PROT_WRITE); if (!xen_9pdev->rings[i].data) { goto out; } xen_9pdev->rings[i].ring.in = xen_9pdev->rings[i].data; xen_9pdev->rings[i].ring.out = xen_9pdev->rings[i].data + XEN_FLEX_RING_SIZE(ring_order); xen_9pdev->rings[i].bh = qemu_bh_new(xen_9pfs_bh, &xen_9pdev->rings[i]); xen_9pdev->rings[i].out_cons = 0; xen_9pdev->rings[i].out_size = 0; xen_9pdev->rings[i].inprogress = False; xen_9pdev->rings[i].evtchndev = xenevtchn_open(NULL, 0); if (xen_9pdev->rings[i].evtchndev == NULL) { goto out; } fcntl(xenevtchn_fd(xen_9pdev->rings[i].evtchndev), F_SETFD, FD_CLOEXEC); xen_9pdev->rings[i].local_port = xenevtchn_bind_interdomain (xen_9pdev->rings[i].evtchndev, xendev->dom, xen_9pdev->rings[i].evtchn); if (xen_9pdev->rings[i].local_port == -1) { xen_pv_printf(xendev, 0, "xenevtchn_bind_interdomain failed port=%d\n", xen_9pdev->rings[i].evtchn); goto out; } xen_pv_printf(xendev, 2, "bind evtchn port %d\n", xendev->local_port); qemu_set_fd_handler(xenevtchn_fd(xen_9pdev->rings[i].evtchndev), xen_9pfs_evtchn_event, NULL, &xen_9pdev->rings[i]); } xen_9pdev->security_model = xenstore_read_be_str(xendev, "security_model"); xen_9pdev->path = xenstore_read_be_str(xendev, "path"); xen_9pdev->id = s->fsconf.fsdev_id = g_strdup_printf("xen9p%d", xendev->dev); xen_9pdev->tag = s->fsconf.tag = xenstore_read_fe_str(xendev, "tag"); v9fs_register_transport(s, &xen_9p_transport); fsdev = qemu_opts_create(qemu_find_opts("fsdev"), s->fsconf.tag, 1, NULL); qemu_opt_set(fsdev, "fsdriver", "local", NULL); qemu_opt_set(fsdev, "path", xen_9pdev->path, NULL); qemu_opt_set(fsdev, "security_model", xen_9pdev->security_model, NULL); qemu_opts_set_id(fsdev, s->fsconf.fsdev_id); qemu_fsdev_add(fsdev); v9fs_device_realize_common(s, NULL); return 0; out: xen_9pfs_free(xendev); return -1; }


--------------------------------------------- Result 3 ---------------------------------------------
[[0 (9%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int subframe_count_exact(FlacEncodeContext *s, FlacSubframe *sub, int pred_order) { int p, porder, psize; int i, part_end; int count = 0; count += 8; if (sub->type == FLAC_SUBFRAME_CONSTANT) { count += sub->obits; } else if (sub->type == FLAC_SUBFRAME_VERBATIM) { count += s->frame.blocksize * sub->obits; } else { count += pred_order * sub->obits; if (sub->type == FLAC_SUBFRAME_LPC) count += 4 + 5 + pred_order * s->options.lpc_coeff_precision; count += 2; porder = sub->rc.porder; psize = s->frame.blocksize >> porder; count += 4; i = pred_order; part_end = psize; for (p = 0; p < 1 << porder; p++) { int k = sub->rc.params[p]; count += 4; count += rice_count_exact(&sub->residual[i], part_end - i, k); i = part_end; part_end = FFMIN(s->frame.blocksize, part_end + psize); } } return count; }


--------------------------------------------- Result 4 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 0 / 0 / 4 / 4:   0%|          | 4/2690 [00:00<03:11, 14.03it/s][Succeeded / Failed / Skipped / Total] 0 / 0 / 4 / 4:   0%|          | 5/2690 [00:00<08:25,  5.31it/s][[0 (58%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static void ppc_spapr_init(QEMUMachineInitArgs *args) { ram_addr_t ram_size = args->ram_size; const char *cpu_model = args->cpu_model; const char *kernel_filename = args->kernel_filename; const char *kernel_cmdline = args->kernel_cmdline; const char *initrd_filename = args->initrd_filename; const char *boot_device = args->boot_order; PowerPCCPU *cpu; CPUPPCState *env; PCIHostState *phb; int i; MemoryRegion *sysmem = get_system_memory(); MemoryRegion *ram = g_new(MemoryRegion, 1); hwaddr rma_alloc_size; uint32_t initrd_base = 0; long kernel_size = 0, initrd_size = 0; long load_limit, rtas_limit, fw_size; bool kernel_le = False; char *filename; msi_supported = True; spapr = g_malloc0(sizeof(*spapr)); QLIST_INIT(&spapr->phbs); cpu_ppc_hypercall = emulate_spapr_hypercall; rma_alloc_size = kvmppc_alloc_rma("ppc_spapr.rma", sysmem); if (rma_alloc_size == -1) { hw_error("qemu: Unable to create RMA\n"); exit(1); } if (rma_alloc_size && (rma_alloc_size < ram_size)) { spapr->rma_size = rma_alloc_size; } else { spapr->rma_size = ram_size; if (kvm_enabled()) { spapr->vrma_adjust = 1; spapr->rma_size = MIN(spapr->rma_size, 0x10000000); } } rtas_limit = MIN(spapr->rma_size, 0x80000000); spapr->rtas_addr = rtas_limit - RTAS_MAX_SIZE; spapr->fdt_addr = spapr->rtas_addr - FDT_MAX_SIZE; load_limit = spapr->fdt_addr - FW_OVERHEAD; spapr->htab_shift = 18; while (spapr->htab_shift <= 46) { if ((1ULL << (spapr->htab_shift + 7)) >= ram_size) { break; } spapr->htab_shift++; } spapr->icp = xics_system_init(smp_cpus * kvmppc_smt_threads() / smp_threads, XICS_IRQS); spapr->next_irq = XICS_IRQ_BASE; if (cpu_model == NULL) { cpu_model = kvm_enabled() ? "host" : "POWER7"; } for (i = 0; i < smp_cpus; i++) { cpu = cpu_ppc_init(cpu_model); if (cpu == NULL) { fprintf(stderr, "Unable to find PowerPC CPU definition\n"); exit(1); } env = &cpu->env; xics_cpu_setup(spapr->icp, cpu); cpu_ppc_tb_init(env, TIMEBASE_FREQ); env->msr_mask &= ~(1 << 6); if (kvm_enabled()) { kvmppc_set_papr(cpu); } qemu_register_reset(spapr_cpu_reset, cpu); } spapr->ram_limit = ram_size; if (spapr->ram_limit > rma_alloc_size) { ram_addr_t nonrma_base = rma_alloc_size; ram_addr_t nonrma_size = spapr->ram_limit - rma_alloc_size; memory_region_init_ram(ram, NULL, "ppc_spapr.ram", nonrma_size); vmstate_register_ram_global(ram); memory_region_add_subregion(sysmem, nonrma_base, ram); } filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, "spapr-rtas.bin"); spapr->rtas_size = load_image_targphys(filename, spapr->rtas_addr, rtas_limit - spapr->rtas_addr); if (spapr->rtas_size < 0) { hw_error("qemu: could not load LPAR rtas '%s'\n", filename); exit(1); } if (spapr->rtas_size > RTAS_MAX_SIZE) { hw_error("RTAS too big ! 0x%lx bytes (max is 0x%x)\n", spapr->rtas_size, RTAS_MAX_SIZE); exit(1); } g_free(filename); spapr_events_init(spapr); spapr->vio_bus = spapr_vio_bus_init(); for (i = 0; i < MAX_SERIAL_PORTS; i++) { if (serial_hds[i]) { spapr_vty_create(spapr->vio_bus, serial_hds[i]); } } spapr_create_nvram(spapr); spapr_pci_msi_init(spapr, SPAPR_PCI_MSI_WINDOW); spapr_pci_rtas_init(); phb = spapr_create_phb(spapr, 0); for (i = 0; i < nb_nics; i++) { NICInfo *nd = &nd_table[i]; if (!nd->model) { nd->model = g_strdup("ibmveth"); } if (strcmp(nd->model, "ibmveth") == 0) { spapr_vlan_create(spapr->vio_bus, nd); } else { pci_nic_init_nofail(&nd_table[i], phb->bus, nd->model, NULL); } } for (i = 0; i <= drive_get_max_bus(IF_SCSI); i++) { spapr_vscsi_create(spapr->vio_bus); } if (spapr_vga_init(phb->bus)) { spapr->has_graphics = True; } if (usb_enabled(spapr->has_graphics)) { pci_create_simple(phb->bus, -1, "pci-ohci"); if (spapr->has_graphics) { usbdevice_create("keyboard"); usbdevice_create("mouse"); } } if (spapr->rma_size < (MIN_RMA_SLOF << 20)) { fprintf(stderr, "qemu: pSeries SLOF firmware requires >= " "%ldM guest RMA (Real Mode Area memory)\n", MIN_RMA_SLOF); exit(1); } if (kernel_filename) { uint64_t lowaddr = 0; kernel_size = load_elf(kernel_filename, translate_kernel_address, NULL, NULL, &lowaddr, NULL, 1, ELF_MACHINE, 0); if (kernel_size < 0) { kernel_size = load_elf(kernel_filename, translate_kernel_address, NULL, NULL, &lowaddr, NULL, 0, ELF_MACHINE, 0); kernel_le = kernel_size > 0; } if (kernel_size < 0) { kernel_size = load_image_targphys(kernel_filename, KERNEL_LOAD_ADDR, load_limit - KERNEL_LOAD_ADDR); } if (kernel_size < 0) { fprintf(stderr, "qemu: could not load kernel '%s'\n", kernel_filename); exit(1); } if (initrd_filename) { initrd_base = (KERNEL_LOAD_ADDR + kernel_size + 0x1ffff) & ~0xffff; initrd_size = load_image_targphys(initrd_filename, initrd_base, load_limit - initrd_base); if (initrd_size < 0) { fprintf(stderr, "qemu: could not load initial ram disk '%s'\n", initrd_filename); exit(1); } } else { initrd_base = 0; initrd_size = 0; } } if (bios_name == NULL) { bios_name = FW_FILE_NAME; } filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, bios_name); fw_size = load_image_targphys(filename, 0, FW_MAX_SIZE); if (fw_size < 0) { hw_error("qemu: could not load LPAR rtas '%s'\n", filename); exit(1); } g_free(filename); spapr->entry_point = 0x100; vmstate_register(NULL, 0, &vmstate_spapr, spapr); register_savevm_live(NULL, "spapr/htab", -1, 1, &savevm_htab_handlers, spapr); spapr->fdt_skel = spapr_create_fdt_skel(cpu_model, initrd_base, initrd_size, kernel_size, kernel_le, boot_device, kernel_cmdline, spapr->epow_irq); assert(spapr->fdt_skel != NULL); }


--------------------------------------------- Result 5 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 1 / 0 / 4 / 5:   0%|          | 5/2690 [00:00<08:25,  5.31it/s][Succeeded / Failed / Skipped / Total] 1 / 1 / 4 / 6:   0%|          | 6/2690 [00:01<10:29,  4.27it/s][Succeeded / Failed / Skipped / Total] 2 / 1 / 4 / 7:   0%|          | 7/2690 [00:01<10:40,  4.19it/s][[0 (36%)]] --> [[0 (52%)]] --> Socre: 0.5231466293334961

[[[[Adv]]]]: static int mpeg1_decode_sequence(AVCodecContext *[[avctx]], UINT8 *buf, int buf_size) { Mpeg1Context *s1 = [[avctx]]->priv_data; MpegEncContext *s = &s1->mpeg_enc_ctx; int [[width]], height, i, v, j; float aspect; init_get_bits(&s->gb, buf, buf_size); [[width]] = get_bits(&s->gb, 12); height = get_bits(&s->gb, 12); s->aspect_ratio_info= get_bits(&s->gb, 4); if(!s->mpeg2){ aspect= mpeg1_aspect[s->aspect_ratio_info]; if(aspect!=0.0) [[avctx]]->aspect_ratio= [[width]]/(aspect*height); } s->frame_rate_index = get_bits(&s->gb, 4); if (s->frame_rate_index == 0) return -1; s->bit_rate = get_bits(&s->gb, 18) * 400; if (get_bits1(&s->gb) == 0) return -1; if ([[width]] <= 0 || height <= 0 || ([[width]] % 2) != 0 || (height % 2) != 0) return -1; if ([[width]] != s->width || height != s->height) { s->out_format = FMT_MPEG1; if (s1->mpeg_enc_ctx_allocated) { MPV_common_end(s); } s->width = [[width]]; s->height = height; [[avctx]]->has_b_frames= 1; s->avctx = [[avctx]]; [[avctx]]->width = [[width]]; [[avctx]]->height = height; if (s->frame_rate_index >= 9) { [[avctx]]->frame_rate = 25 * FRAME_RATE_BASE; } else { [[avctx]]->frame_rate = frame_rate_tab[s->frame_rate_index]; } s->frame_rate = [[avctx]]->frame_rate; [[avctx]]->bit_rate = s->bit_rate; if (MPV_common_init(s) < 0) return -1; s1->mpeg_enc_ctx_allocated = 1; } skip_bits(&s->gb, 10); skip_bits(&s->gb, 1); if (get_bits1(&s->gb)) { for(i=0;i<64;i++) { v = get_bits(&s->gb, 8); j = s->intra_scantable.permutated[i]; s->intra_matrix[j] = v; s->chroma_intra_matrix[j] = v; } #ifdef DEBUG dprintf("intra matrix present\n"); for(i=0;i<64;i++) dprintf(" %d", s->intra_matrix[s->intra_scantable.permutated[i]]); printf("\n"); #endif } else { for(i=0;i<64;i++) { int j= s->idct_permutation[i]; v = ff_mpeg1_default_intra_matrix[i]; s->intra_matrix[j] = v; s->chroma_intra_matrix[j] = v; } } if (get_bits1(&s->gb)) { for(i=0;i<64;i++) { v = get_bits(&s->gb, 8); j = s->intra_scantable.permutated[i]; s->inter_matrix[j] = v; s->chroma_inter_matrix[j] = v; } #ifdef DEBUG dprintf("non intra matrix present\n"); for(i=0;i<64;i++) dprintf(" %d", s->inter_matrix[s->intra_scantable.permutated[i]]); printf("\n"); #endif } else { for(i=0;i<64;i++) { int j= s->idct_permutation[i]; v = ff_mpeg1_default_non_intra_matrix[i]; s->inter_matrix[j] = v; s->chroma_inter_matrix[j] = v; } } s->progressive_sequence = 1; s->progressive_frame = 1; s->picture_structure = PICT_FRAME; s->frame_pred_frame_dct = 1; s->mpeg2 = 0; [[avctx]]->sub_id = 1; return 0; }

[[[[Adv]]]]: static int mpeg1_decode_sequence(AVCodecContext *[[miscarriage]], UINT8 *buf, int buf_size) { Mpeg1Context *s1 = [[miscarriage]]->priv_data; MpegEncContext *s = &s1->mpeg_enc_ctx; int [[assortment]], height, i, v, j; float aspect; init_get_bits(&s->gb, buf, buf_size); [[assortment]] = get_bits(&s->gb, 12); height = get_bits(&s->gb, 12); s->aspect_ratio_info= get_bits(&s->gb, 4); if(!s->mpeg2){ aspect= mpeg1_aspect[s->aspect_ratio_info]; if(aspect!=0.0) [[miscarriage]]->aspect_ratio= [[assortment]]/(aspect*height); } s->frame_rate_index = get_bits(&s->gb, 4); if (s->frame_rate_index == 0) return -1; s->bit_rate = get_bits(&s->gb, 18) * 400; if (get_bits1(&s->gb) == 0) return -1; if ([[assortment]] <= 0 || height <= 0 || ([[assortment]] % 2) != 0 || (height % 2) != 0) return -1; if ([[assortment]] != s->width || height != s->height) { s->out_format = FMT_MPEG1; if (s1->mpeg_enc_ctx_allocated) { MPV_common_end(s); } s->width = [[assortment]]; s->height = height; [[miscarriage]]->has_b_frames= 1; s->avctx = [[miscarriage]]; [[miscarriage]]->width = [[assortment]]; [[miscarriage]]->height = height; if (s->frame_rate_index >= 9) { [[miscarriage]]->frame_rate = 25 * FRAME_RATE_BASE; } else { [[miscarriage]]->frame_rate = frame_rate_tab[s->frame_rate_index]; } s->frame_rate = [[miscarriage]]->frame_rate; [[miscarriage]]->bit_rate = s->bit_rate; if (MPV_common_init(s) < 0) return -1; s1->mpeg_enc_ctx_allocated = 1; } skip_bits(&s->gb, 10); skip_bits(&s->gb, 1); if (get_bits1(&s->gb)) { for(i=0;i<64;i++) { v = get_bits(&s->gb, 8); j = s->intra_scantable.permutated[i]; s->intra_matrix[j] = v; s->chroma_intra_matrix[j] = v; } #ifdef DEBUG dprintf("intra matrix present\n"); for(i=0;i<64;i++) dprintf(" %d", s->intra_matrix[s->intra_scantable.permutated[i]]); printf("\n"); #endif } else { for(i=0;i<64;i++) { int j= s->idct_permutation[i]; v = ff_mpeg1_default_intra_matrix[i]; s->intra_matrix[j] = v; s->chroma_intra_matrix[j] = v; } } if (get_bits1(&s->gb)) { for(i=0;i<64;i++) { v = get_bits(&s->gb, 8); j = s->intra_scantable.permutated[i]; s->inter_matrix[j] = v; s->chroma_inter_matrix[j] = v; } #ifdef DEBUG dprintf("non intra matrix present\n"); for(i=0;i<64;i++) dprintf(" %d", s->inter_matrix[s->intra_scantable.permutated[i]]); printf("\n"); #endif } else { for(i=0;i<64;i++) { int j= s->idct_permutation[i]; v = ff_mpeg1_default_non_intra_matrix[i]; s->inter_matrix[j] = v; s->chroma_inter_matrix[j] = v; } } s->progressive_sequence = 1; s->progressive_frame = 1; s->picture_structure = PICT_FRAME; s->frame_pred_frame_dct = 1; s->mpeg2 = 0; [[miscarriage]]->sub_id = 1; return 0; }


--------------------------------------------- Result 6 ---------------------------------------------
[[0 (2%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static uint32_t drc_set_unusable(sPAPRDRConnector *[[drc]]) { [[drc]]->allocation_state = SPAPR_DR_ALLOCATION_STATE_UNUSABLE; if ([[drc]]->awaiting_release) { uint32_t [[drc_index]] = spapr_drc_index([[drc]]); trace_spapr_drc_set_allocation_state_finalizing([[drc_index]]); spapr_drc_detach([[drc]]); } return RTAS_OUT_SUCCESS; }

[[[[Adv]]]]: static uint32_t drc_set_unusable(sPAPRDRConnector *[[sandra]]) { [[sandra]]->allocation_state = SPAPR_DR_ALLOCATION_STATE_UNUSABLE; if ([[sandra]]->awaiting_release) { uint32_t [[guys]] = spapr_drc_index([[sandra]]); trace_spapr_drc_set_allocation_state_finalizing([[guys]]); spapr_drc_detach([[sandra]]); } return RTAS_OUT_SUCCESS; }


--------------------------------------------- Result 7 ---------------------------------------------
[[0 (52%)]] --> [[0 (45%)]] --> Socre: 0.5504452884197235

[[[[Adv]]]]: static void scsi_read_request(SCSIDiskReq *[[r]]) { SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, [[r]]->req.dev); uint32_t n; if ([[r]]->sector_count == (uint32_t)-1) { DPRINTF("Read buf_len=%zd\n", [[r]]->iov.iov_len); [[r]]->sector_count = 0; scsi_req_data(&[[r]]->req, [[r]]->iov.iov_len); return; } DPRINTF("Read sector_count=%d\n", [[r]]->sector_count); if ([[r]]->sector_count == 0) { scsi_command_complete([[r]], GOOD, NO_SENSE); return; } assert([[r]]->req.aiocb == NULL); n = [[r]]->sector_count; if (n > SCSI_DMA_BUF_SIZE / 512) n = SCSI_DMA_BUF_SIZE / 512; [[r]]->iov.iov_len = n * 512; qemu_iovec_init_external(&[[r]]->qiov, &[[r]]->iov, 1); [[r]]->req.aiocb = bdrv_aio_readv(s->bs, [[r]]->sector, &[[r]]->qiov, n, scsi_read_complete, [[r]]); if ([[r]]->req.aiocb == NULL) { scsi_read_complete([[r]], -EIO); } }

[[[[Adv]]]]: static void scsi_read_request(SCSIDiskReq *[[prakash]]) { SCSIDiskState *s = DO_UPCAST(SCSIDiskState, qdev, [[prakash]]->req.dev); uint32_t n; if ([[prakash]]->sector_count == (uint32_t)-1) { DPRINTF("Read buf_len=%zd\n", [[prakash]]->iov.iov_len); [[prakash]]->sector_count = 0; scsi_req_data(&[[prakash]]->req, [[prakash]]->iov.iov_len); return; } DPRINTF("Read sector_count=%d\n", [[prakash]]->sector_count); if ([[prakash]]->sector_count == 0) { scsi_command_complete([[prakash]], GOOD, NO_SENSE); return; } assert([[prakash]]->req.aiocb == NULL); n = [[prakash]]->sector_count; if (n > SCSI_DMA_BUF_SIZE / 512) n = SCSI_DMA_BUF_SIZE / 512; [[prakash]]->iov.iov_len = n * 512; qemu_iovec_init_external(&[[prakash]]->qiov, &[[prakash]]->iov, 1); [[prakash]]->req.aiocb = bdrv_aio_readv(s->bs, [[prakash]]->sector, &[[prakash]]->qiov, n, scsi_read_complete, [[prakash]]); if ([[prakash]]->req.aiocb == NULL) { scsi_read_complete([[prakash]], -EIO); } }


--------------------------------------------- Result 8 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 3 / 1 / 4 / 8:   0%|          | 8/2690 [00:02<11:45,  3.80it/s][Succeeded / Failed / Skipped / Total] 3 / 1 / 4 / 8:   0%|          | 9/2690 [00:03<17:12,  2.60it/s][[0 (50%)]] --> [[0 (41%)]] --> Socre: 0.5921002626419067

[[[[Adv]]]]: static void lm32_evr_init(MachineState *[[machine]]) { const char *cpu_model = [[machine]]->cpu_model; const char *kernel_filename = [[machine]]->kernel_filename; LM32CPU *cpu; CPULM32State *env; DriveInfo *dinfo; MemoryRegion *address_space_mem = get_system_memory(); MemoryRegion *phys_ram = g_new(MemoryRegion, 1); qemu_irq irq[32]; ResetInfo *reset_info; int i; hwaddr flash_base = 0x04000000; size_t flash_sector_size = 256 * 1024; size_t flash_size = 32 * 1024 * 1024; hwaddr ram_base = 0x08000000; size_t ram_size = 64 * 1024 * 1024; hwaddr timer0_base = 0x80002000; hwaddr uart0_base = 0x80006000; hwaddr timer1_base = 0x8000a000; int uart0_irq = 0; int timer0_irq = 1; int timer1_irq = 3; reset_info = g_malloc0(sizeof(ResetInfo)); if (cpu_model == NULL) { cpu_model = "lm32-full"; } cpu = LM32_CPU(cpu_generic_init(TYPE_LM32_CPU, cpu_model)); if (cpu == NULL) { fprintf(stderr, "qemu: unable to find CPU '%s'\n", cpu_model); exit(1); } env = &cpu->env; reset_info->cpu = cpu; reset_info->flash_base = flash_base; memory_region_allocate_system_memory(phys_ram, NULL, "lm32_evr.sdram", ram_size); memory_region_add_subregion(address_space_mem, ram_base, phys_ram); dinfo = drive_get(IF_PFLASH, 0, 0); pflash_cfi02_register(flash_base, NULL, "lm32_evr.flash", flash_size, dinfo ? blk_by_legacy_dinfo(dinfo) : NULL, flash_sector_size, flash_size / flash_sector_size, 1, 2, 0x01, 0x7e, 0x43, 0x00, 0x555, 0x2aa, 1); env->pic_state = lm32_pic_init(qemu_allocate_irq(cpu_irq_handler, cpu, 0)); for (i = 0; i < 32; i++) { irq[i] = qdev_get_gpio_in(env->pic_state, i); } lm32_uart_create(uart0_base, irq[uart0_irq], serial_hds[0]); sysbus_create_simple("lm32-timer", timer0_base, irq[timer0_irq]); sysbus_create_simple("lm32-timer", timer1_base, irq[timer1_irq]); env->juart_state = lm32_juart_init(serial_hds[1]); reset_info->bootstrap_pc = flash_base; if (kernel_filename) { uint64_t entry; int kernel_size; kernel_size = load_elf(kernel_filename, NULL, NULL, &entry, NULL, NULL, 1, EM_LATTICEMICO32, 0, 0); reset_info->bootstrap_pc = entry; if (kernel_size < 0) { kernel_size = load_image_targphys(kernel_filename, ram_base, ram_size); reset_info->bootstrap_pc = ram_base; } if (kernel_size < 0) { fprintf(stderr, "qemu: could not load kernel '%s'\n", kernel_filename); exit(1); } } qemu_register_reset(main_cpu_reset, reset_info); }

[[[[Adv]]]]: static void lm32_evr_init(MachineState *[[typewriters]]) { const char *cpu_model = [[typewriters]]->cpu_model; const char *kernel_filename = [[typewriters]]->kernel_filename; LM32CPU *cpu; CPULM32State *env; DriveInfo *dinfo; MemoryRegion *address_space_mem = get_system_memory(); MemoryRegion *phys_ram = g_new(MemoryRegion, 1); qemu_irq irq[32]; ResetInfo *reset_info; int i; hwaddr flash_base = 0x04000000; size_t flash_sector_size = 256 * 1024; size_t flash_size = 32 * 1024 * 1024; hwaddr ram_base = 0x08000000; size_t ram_size = 64 * 1024 * 1024; hwaddr timer0_base = 0x80002000; hwaddr uart0_base = 0x80006000; hwaddr timer1_base = 0x8000a000; int uart0_irq = 0; int timer0_irq = 1; int timer1_irq = 3; reset_info = g_malloc0(sizeof(ResetInfo)); if (cpu_model == NULL) { cpu_model = "lm32-full"; } cpu = LM32_CPU(cpu_generic_init(TYPE_LM32_CPU, cpu_model)); if (cpu == NULL) { fprintf(stderr, "qemu: unable to find CPU '%s'\n", cpu_model); exit(1); } env = &cpu->env; reset_info->cpu = cpu; reset_info->flash_base = flash_base; memory_region_allocate_system_memory(phys_ram, NULL, "lm32_evr.sdram", ram_size); memory_region_add_subregion(address_space_mem, ram_base, phys_ram); dinfo = drive_get(IF_PFLASH, 0, 0); pflash_cfi02_register(flash_base, NULL, "lm32_evr.flash", flash_size, dinfo ? blk_by_legacy_dinfo(dinfo) : NULL, flash_sector_size, flash_size / flash_sector_size, 1, 2, 0x01, 0x7e, 0x43, 0x00, 0x555, 0x2aa, 1); env->pic_state = lm32_pic_init(qemu_allocate_irq(cpu_irq_handler, cpu, 0)); for (i = 0; i < 32; i++) { irq[i] = qdev_get_gpio_in(env->pic_state, i); } lm32_uart_create(uart0_base, irq[uart0_irq], serial_hds[0]); sysbus_create_simple("lm32-timer", timer0_base, irq[timer0_irq]); sysbus_create_simple("lm32-timer", timer1_base, irq[timer1_irq]); env->juart_state = lm32_juart_init(serial_hds[1]); reset_info->bootstrap_pc = flash_base; if (kernel_filename) { uint64_t entry; int kernel_size; kernel_size = load_elf(kernel_filename, NULL, NULL, &entry, NULL, NULL, 1, EM_LATTICEMICO32, 0, 0); reset_info->bootstrap_pc = entry; if (kernel_size < 0) { kernel_size = load_image_targphys(kernel_filename, ram_base, ram_size); reset_info->bootstrap_pc = ram_base; } if (kernel_size < 0) { fprintf(stderr, "qemu: could not load kernel '%s'\n", kernel_filename); exit(1); } } qemu_register_reset(main_cpu_reset, reset_info); }


--------------------------------------------- Result 9 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 3 / 2 / 4 / 9:   0%|          | 9/2690 [00:03<17:12,  2.60it/s][Succeeded / Failed / Skipped / Total] 4 / 2 / 4 / 10:   0%|          | 10/2690 [00:04<18:45,  2.38it/s][Succeeded / Failed / Skipped / Total] 4 / 2 / 5 / 11:   0%|          | 11/2690 [00:04<17:04,  2.61it/s][Succeeded / Failed / Skipped / Total] 4 / 2 / 6 / 12:   0%|          | 12/2690 [00:04<15:40,  2.85it/s][Succeeded / Failed / Skipped / Total] 4 / 2 / 6 / 12:   0%|          | 13/2690 [00:04<16:03,  2.78it/s][[0 (30%)]] --> [[[FAILED]]]

[[[[Adv]]]]: aio_write_f(int [[argc]], char **[[argv]]) { char *p; int [[count]] = 0; int [[nr_iov]], i, c; int pattern = 0xcd; struct aio_ctx *[[ctx]] = calloc(1, sizeof(struct aio_ctx)); BlockDriverAIOCB *acb; while ((c = getopt([[argc]], [[argv]], "CqP:")) != EOF) { switch (c) { case 'C': [[ctx]]->Cflag = 1; break; case 'q': [[ctx]]->qflag = 1; break; case 'P': pattern = atoi(optarg); break; default: return command_usage(&aio_write_cmd); } } if (optind > [[argc]] - 2) return command_usage(&aio_write_cmd); [[ctx]]->offset = cvtnum([[argv]][optind]); if ([[ctx]]->offset < 0) { printf("non-numeric length argument -- %s\n", [[argv]][optind]); return 0; } optind++; if ([[ctx]]->offset & 0x1ff) { printf("offset %lld is not sector aligned\n", (long long)[[ctx]]->offset); return 0; } if ([[count]] & 0x1ff) { printf("count %d is not sector aligned\n", [[count]]); return 0; } for (i = optind; i < [[argc]]; i++) { size_t len; len = cvtnum([[argv]][optind]); if (len < 0) { printf("non-numeric length argument -- %s\n", [[argv]][i]); return 0; } [[count]] += len; } [[nr_iov]] = [[argc]] - optind; qemu_iovec_init(&[[ctx]]->qiov, [[nr_iov]]); [[ctx]]->buf = p = qemu_io_alloc([[count]], pattern); for (i = 0; i < [[nr_iov]]; i++) { size_t len; len = cvtnum([[argv]][optind]); if (len < 0) { printf("non-numeric length argument -- %s\n", [[argv]][optind]); return 0; } qemu_iovec_add(&[[ctx]]->qiov, p, len); p += len; optind++; } gettimeofday(&[[ctx]]->t1, NULL); acb = bdrv_aio_writev(bs, [[ctx]]->offset >> 9, &[[ctx]]->qiov, [[ctx]]->qiov.size >> 9, aio_write_done, [[ctx]]); if (!acb) return -EIO; return 0; }

[[[[Adv]]]]: aio_write_f(int [[lymphoma]], char **[[billionaires]]) { char *p; int [[accusations]] = 0; int [[bernhardt]], i, c; int pattern = 0xcd; struct aio_ctx *[[exec]] = calloc(1, sizeof(struct aio_ctx)); BlockDriverAIOCB *acb; while ((c = getopt([[lymphoma]], [[billionaires]], "CqP:")) != EOF) { switch (c) { case 'C': [[exec]]->Cflag = 1; break; case 'q': [[exec]]->qflag = 1; break; case 'P': pattern = atoi(optarg); break; default: return command_usage(&aio_write_cmd); } } if (optind > [[lymphoma]] - 2) return command_usage(&aio_write_cmd); [[exec]]->offset = cvtnum([[billionaires]][optind]); if ([[exec]]->offset < 0) { printf("non-numeric length argument -- %s\n", [[billionaires]][optind]); return 0; } optind++; if ([[exec]]->offset & 0x1ff) { printf("offset %lld is not sector aligned\n", (long long)[[exec]]->offset); return 0; } if ([[accusations]] & 0x1ff) { printf("count %d is not sector aligned\n", [[accusations]]); return 0; } for (i = optind; i < [[lymphoma]]; i++) { size_t len; len = cvtnum([[billionaires]][optind]); if (len < 0) { printf("non-numeric length argument -- %s\n", [[billionaires]][i]); return 0; } [[accusations]] += len; } [[bernhardt]] = [[lymphoma]] - optind; qemu_iovec_init(&[[exec]]->qiov, [[bernhardt]]); [[exec]]->buf = p = qemu_io_alloc([[accusations]], pattern); for (i = 0; i < [[bernhardt]]; i++) { size_t len; len = cvtnum([[billionaires]][optind]); if (len < 0) { printf("non-numeric length argument -- %s\n", [[billionaires]][optind]); return 0; } qemu_iovec_add(&[[exec]]->qiov, p, len); p += len; optind++; } gettimeofday(&[[exec]]->t1, NULL); acb = bdrv_aio_writev(bs, [[exec]]->offset >> 9, &[[exec]]->qiov, [[exec]]->qiov.size >> 9, aio_write_done, [[exec]]); if (!acb) return -EIO; return 0; }


--------------------------------------------- Result 10 ---------------------------------------------
[[0 (85%)]] --> [[0 (26%)]] --> Socre: 0.739501416683197

[[[[Adv]]]]: static void vc1_inv_trans_8x8_dc_c(uint8_t *dest, int [[linesize]], DCTELEM *block) { int [[i]]; int dc = block[0]; const uint8_t *[[cm]]; dc = (3 * dc + 1) >> 1; dc = (3 * dc + 16) >> 5; [[cm]] = ff_cropTbl + MAX_NEG_CROP + dc; for([[i]] = 0; [[i]] < 8; [[i]]++){ dest[0] = [[cm]][dest[0]]; dest[1] = [[cm]][dest[1]]; dest[2] = [[cm]][dest[2]]; dest[3] = [[cm]][dest[3]]; dest[4] = [[cm]][dest[4]]; dest[5] = [[cm]][dest[5]]; dest[6] = [[cm]][dest[6]]; dest[7] = [[cm]][dest[7]]; dest += [[linesize]]; } }

[[[[Adv]]]]: static void vc1_inv_trans_8x8_dc_c(uint8_t *dest, int [[assembler]], DCTELEM *block) { int [[lee]]; int dc = block[0]; const uint8_t *[[girth]]; dc = (3 * dc + 1) >> 1; dc = (3 * dc + 16) >> 5; [[girth]] = ff_cropTbl + MAX_NEG_CROP + dc; for([[lee]] = 0; [[lee]] < 8; [[lee]]++){ dest[0] = [[girth]][dest[0]]; dest[1] = [[girth]][dest[1]]; dest[2] = [[girth]][dest[2]]; dest[3] = [[girth]][dest[3]]; dest[4] = [[girth]][dest[4]]; dest[5] = [[girth]][dest[5]]; dest[6] = [[girth]][dest[6]]; dest[7] = [[girth]][dest[7]]; dest += [[assembler]]; } }


--------------------------------------------- Result 11 ---------------------------------------------
[[0 (42%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int vmdk_parse_extents(const char *desc, BlockDriverState *bs, const char *desc_file_path) { int ret; char access[11]; char type[11]; char fname[512]; const char *p = desc; int64_t sectors = 0; int64_t flat_offset; char extent_path[PATH_MAX]; BlockDriverState *extent_file; Error *local_err = NULL; while (*p) { flat_offset = -1; ret = sscanf(p, "%10s %" SCNd64 " %10s \"%511[^\n\r\"]\" %" SCNd64, access, &sectors, type, fname, &flat_offset); if (ret < 4 || strcmp(access, "RW")) { goto next_line; } else if (!strcmp(type, "FLAT")) { if (ret != 5 || flat_offset < 0) { return -EINVAL; } } else if (ret != 4) { return -EINVAL; } if (sectors <= 0 || (strcmp(type, "FLAT") && strcmp(type, "SPARSE") && strcmp(type, "VMFS") && strcmp(type, "VMFSSPARSE")) || (strcmp(access, "RW"))) { goto next_line; } path_combine(extent_path, sizeof(extent_path), desc_file_path, fname); ret = bdrv_file_open(&extent_file, extent_path, NULL, bs->open_flags, &local_err); if (ret) { qerror_report_err(local_err); error_free(local_err); return ret; } if (!strcmp(type, "FLAT") || !strcmp(type, "VMFS")) { VmdkExtent *extent; ret = vmdk_add_extent(bs, extent_file, True, sectors, 0, 0, 0, 0, sectors, &extent); if (ret < 0) { return ret; } extent->flat_start_offset = flat_offset << 9; } else if (!strcmp(type, "SPARSE") || !strcmp(type, "VMFSSPARSE")) { ret = vmdk_open_sparse(bs, extent_file, bs->open_flags); if (ret) { bdrv_unref(extent_file); return ret; } } else { fprintf(stderr, "VMDK: Not supported extent type \"%s\""".\n", type); return -ENOTSUP; } next_line: while (*p && *p != '\n') { p++; } p++; } return 0; }


--------------------------------------------- Result 12 ---------------------------------------------
[[0 (35%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static void compute_rematrixing_strategy(AC3EncodeContext *s) { int nb_coefs; int blk, bnd, i; AC3Block *block, *block0; s->num_rematrixing_bands = 4; if (s->rematrixing & AC3_REMATRIXING_IS_STATIC) return; nb_coefs = FFMIN(s->nb_coefs[0], s->nb_coefs[1]); for (blk = 0; blk < AC3_MAX_BLOCKS; blk++) { block = &s->blocks[blk]; block->new_rematrixing_strategy = !blk; for (bnd = 0; bnd < s->num_rematrixing_bands; bnd++) { int start = ff_ac3_rematrix_band_tab[bnd]; int end = FFMIN(nb_coefs, ff_ac3_rematrix_band_tab[bnd+1]); CoefSumType sum[4] = {0,}; for (i = start; i < end; i++) { CoefType lt = block->mdct_coef[0][i]; CoefType rt = block->mdct_coef[1][i]; CoefType md = lt + rt; CoefType sd = lt - rt; sum[0] += lt * lt; sum[1] += rt * rt; sum[2] += md * md; sum[3] += sd * sd; } if (FFMIN(sum[2], sum[3]) < FFMIN(sum[0], sum[1])) block->rematrixing_flags[bnd] = 1; else block->rematrixing_flags[bnd] = 0; if (blk && block->rematrixing_flags[bnd] != block0->rematrixing_flags[bnd]) { block->new_rematrixing_strategy = 1; } } block0 = block; } }


--------------------------------------------- Result 13 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 4 / 3 / 6 / 13:   0%|          | 13/2690 [00:04<16:03,  2.78it/s][Succeeded / Failed / Skipped / Total] 4 / 4 / 6 / 14:   1%|          | 14/2690 [00:04<15:38,  2.85it/s][Succeeded / Failed / Skipped / Total] 4 / 5 / 6 / 15:   1%|          | 15/2690 [00:05<15:15,  2.92it/s][Succeeded / Failed / Skipped / Total] 5 / 5 / 6 / 16:   1%|          | 16/2690 [00:05<15:31,  2.87it/s][Succeeded / Failed / Skipped / Total] 5 / 5 / 6 / 16:   1%|          | 17/2690 [00:05<14:38,  3.04it/s][Succeeded / Failed / Skipped / Total] 5 / 5 / 7 / 17:   1%|          | 17/2690 [00:05<14:38,  3.04it/s][Succeeded / Failed / Skipped / Total] 5 / 5 / 8 / 18:   1%|          | 18/2690 [00:05<13:51,  3.21it/s][Succeeded / Failed / Skipped / Total] 5 / 6 / 8 / 19:   1%|          | 19/2690 [00:06<14:12,  3.13it/s][[0 (98%)]] --> [[[FAILED]]]

[[[[Adv]]]]: void OPPROTO op_udiv_T1_T0(void) { uint64_t [[x0]]; uint32_t x1; [[x0]] = T0 | ((uint64_t) (env->y) << 32); x1 = T1; [[x0]] = [[x0]] / x1; if ([[x0]] > 0xffffffff) { T0 = 0xffffffff; T1 = 1; } else { T0 = [[x0]]; T1 = 0; FORCE_RET();

[[[[Adv]]]]: void OPPROTO op_udiv_T1_T0(void) { uint64_t [[hormone]]; uint32_t x1; [[hormone]] = T0 | ((uint64_t) (env->y) << 32); x1 = T1; [[hormone]] = [[hormone]] / x1; if ([[hormone]] > 0xffffffff) { T0 = 0xffffffff; T1 = 1; } else { T0 = [[hormone]]; T1 = 0; FORCE_RET();


--------------------------------------------- Result 14 ---------------------------------------------
[[0 (2%)]] --> [[[FAILED]]]

[[[[Adv]]]]: void cpu_x86_init_mmu(CPUX86State *[[env]]) { a20_enabled = 1; a20_mask = 0xffffffff; last_pg_state = -1; cpu_x86_update_cr0([[env]]); }

[[[[Adv]]]]: void cpu_x86_init_mmu(CPUX86State *[[switcheroo]]) { a20_enabled = 1; a20_mask = 0xffffffff; last_pg_state = -1; cpu_x86_update_cr0([[switcheroo]]); }


--------------------------------------------- Result 15 ---------------------------------------------
[[0 (3%)]] --> [[[FAILED]]]

[[[[Adv]]]]: int qemu_cpu_self(void *[[env]]) { return 1; }

[[[[Adv]]]]: int qemu_cpu_self(void *[[brylcreem]]) { return 1; }


--------------------------------------------- Result 16 ---------------------------------------------
[[0 (32%)]] --> [[0 (56%)]] --> Socre: 0.5623660683631897

[[[[Adv]]]]: static void net_vhost_link_down(VhostUserState *[[s]], bool [[link_down]]) { [[s]]->nc.link_down = [[link_down]]; if ([[s]]->nc.peer) { [[s]]->nc.peer->link_down = [[link_down]]; } if ([[s]]->nc.info->link_status_changed) { [[s]]->nc.info->link_status_changed(&[[s]]->nc); } if ([[s]]->nc.peer && [[s]]->nc.peer->info->link_status_changed) { [[s]]->nc.peer->info->link_status_changed([[s]]->nc.peer); } }

[[[[Adv]]]]: static void net_vhost_link_down(VhostUserState *[[among]], bool [[people]]) { [[among]]->nc.link_down = [[people]]; if ([[among]]->nc.peer) { [[among]]->nc.peer->link_down = [[people]]; } if ([[among]]->nc.info->link_status_changed) { [[among]]->nc.info->link_status_changed(&[[among]]->nc); } if ([[among]]->nc.peer && [[among]]->nc.peer->info->link_status_changed) { [[among]]->nc.peer->info->link_status_changed([[among]]->nc.peer); } }


--------------------------------------------- Result 17 ---------------------------------------------
[[0 (60%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int rv34_decode_mv(RV34DecContext *r, int block_type) { MpegEncContext *s = &r->s; GetBitContext *gb = &s->gb; int i, j, k, l; int mv_pos = s->mb_x * 2 + s->mb_y * 2 * s->b8_stride; int next_bt; memset(r->dmv, 0, sizeof(r->dmv)); for(i = 0; i < num_mvs[block_type]; i++){ r->dmv[i][0] = svq3_get_se_golomb(gb); r->dmv[i][1] = svq3_get_se_golomb(gb); } switch(block_type){ case RV34_MB_TYPE_INTRA: case RV34_MB_TYPE_INTRA16x16: ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride); return 0; case RV34_MB_SKIP: if(s->pict_type == AV_PICTURE_TYPE_P){ ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride); rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0); break; } case RV34_MB_B_DIRECT: if (HAVE_THREADS && (s->avctx->active_thread_type & FF_THREAD_FRAME)) ff_thread_await_progress(&s->next_picture_ptr->f, s->mb_y - 1, 0); next_bt = s->next_picture_ptr->f.mb_type[s->mb_x + s->mb_y * s->mb_stride]; if(IS_INTRA(next_bt) || IS_SKIP(next_bt)){ ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride); ZERO8x2(s->current_picture_ptr->f.motion_val[1][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride); }else for(j = 0; j < 2; j++) for(i = 0; i < 2; i++) for(k = 0; k < 2; k++) for(l = 0; l < 2; l++) s->current_picture_ptr->f.motion_val[l][mv_pos + i + j*s->b8_stride][k] = calc_add_mv(r, l, s->next_picture_ptr->f.motion_val[0][mv_pos + i + j*s->b8_stride][k]); if(!(IS_16X8(next_bt) || IS_8X16(next_bt) || IS_8X8(next_bt))) rv34_mc_2mv(r, block_type); else rv34_mc_2mv_skip(r); ZERO8x2(s->current_picture_ptr->f.motion_val[0][s->mb_x * 2 + s->mb_y * 2 * s->b8_stride], s->b8_stride); break; case RV34_MB_P_16x16: case RV34_MB_P_MIX16x16: rv34_pred_mv(r, block_type, 0, 0); rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, 0); break; case RV34_MB_B_FORWARD: case RV34_MB_B_BACKWARD: r->dmv[1][0] = r->dmv[0][0]; r->dmv[1][1] = r->dmv[0][1]; if(r->rv30) rv34_pred_mv_rv3(r, block_type, block_type == RV34_MB_B_BACKWARD); else rv34_pred_mv_b (r, block_type, block_type == RV34_MB_B_BACKWARD); rv34_mc_1mv (r, block_type, 0, 0, 0, 2, 2, block_type == RV34_MB_B_BACKWARD); break; case RV34_MB_P_16x8: case RV34_MB_P_8x16: rv34_pred_mv(r, block_type, 0, 0); rv34_pred_mv(r, block_type, 1 + (block_type == RV34_MB_P_16x8), 1); if(block_type == RV34_MB_P_16x8){ rv34_mc_1mv(r, block_type, 0, 0, 0, 2, 1, 0); rv34_mc_1mv(r, block_type, 0, 8, s->b8_stride, 2, 1, 0); } if(block_type == RV34_MB_P_8x16){ rv34_mc_1mv(r, block_type, 0, 0, 0, 1, 2, 0); rv34_mc_1mv(r, block_type, 8, 0, 1, 1, 2, 0); } break; case RV34_MB_B_BIDIR: rv34_pred_mv_b (r, block_type, 0); rv34_pred_mv_b (r, block_type, 1); rv34_mc_2mv (r, block_type); break; case RV34_MB_P_8x8: for(i=0;i< 4;i++){ rv34_pred_mv(r, block_type, i, i); rv34_mc_1mv (r, block_type, (i&1)<<3, (i&2)<<2, (i&1)+(i>>1)*s->b8_stride, 1, 1, 0); } break; } return 0; }


--------------------------------------------- Result 18 ---------------------------------------------
[[0 (41%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static void mirror_start_job(BlockDriverState *bs, BlockDriverState *target, const char *replaces, int64_t speed, uint32_t granularity, int64_t buf_size, BlockdevOnError on_source_error, BlockdevOnError on_target_error, bool unmap, BlockCompletionFunc *cb, void *opaque, Error **errp, const BlockJobDriver *driver, bool is_none_mode, BlockDriverState *base) { MirrorBlockJob *s; if (granularity == 0) { granularity = bdrv_get_default_bitmap_granularity(target); } assert ((granularity & (granularity - 1)) == 0); if ((on_source_error == BLOCKDEV_ON_ERROR_STOP || on_source_error == BLOCKDEV_ON_ERROR_ENOSPC) && (!bs->blk || !blk_iostatus_is_enabled(bs->blk))) { error_setg(errp, QERR_INVALID_PARAMETER, "on-source-error"); return; } if (buf_size < 0) { error_setg(errp, "Invalid parameter 'buf-size'"); return; } if (buf_size == 0) { buf_size = DEFAULT_MIRROR_BUF_SIZE; } if (replaces) { replaced_bs = bdrv_lookup_bs(replaces, replaces, errp); if (replaced_bs == NULL) { return; } } else { replaced_bs = bs; } if (replaced_bs->blk && target->blk) { error_setg(errp, "Can't create node with two BlockBackends"); return; } s = block_job_create(driver, bs, speed, cb, opaque, errp); if (!s) { return; } s->replaces = g_strdup(replaces); s->on_source_error = on_source_error; s->on_target_error = on_target_error; s->target = target; s->is_none_mode = is_none_mode; s->base = base; s->granularity = granularity; s->buf_size = ROUND_UP(buf_size, granularity); s->unmap = unmap; s->dirty_bitmap = bdrv_create_dirty_bitmap(bs, granularity, NULL, errp); if (!s->dirty_bitmap) { g_free(s->replaces); block_job_unref(&s->common); return; } bdrv_op_block_all(s->target, s->common.blocker); bdrv_set_enable_write_cache(s->target, True); if (s->target->blk) { blk_set_on_error(s->target->blk, on_target_error, on_target_error); blk_iostatus_enable(s->target->blk); } s->common.co = qemu_coroutine_create(mirror_run); trace_mirror_start(bs, s, s->common.co, opaque); qemu_coroutine_enter(s->common.co, s); }


--------------------------------------------- Result 19 ---------------------------------------------
[[0 (1%)]] --> [[[FAILED]]]

[[[[Adv]]]]: START_TEST(qint_get_int_test) { QInt *[[qi]]; const int [[value]] = 123456; [[qi]] = qint_from_int([[value]]); fail_unless(qint_get_int([[qi]]) == [[value]]); QDECREF([[qi]]); }

[[[[Adv]]]]: START_TEST(qint_get_int_test) { QInt *[[shen]]; const int [[worthwhile]] = 123456; [[shen]] = qint_from_int([[worthwhile]]); fail_unless(qint_get_int([[shen]]) == [[worthwhile]]); QDECREF([[shen]]); }


--------------------------------------------- Result 20 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 5 / 7 / 8 / 20:   1%|          | 20/2690 [00:07<16:18,  2.73it/s][Succeeded / Failed / Skipped / Total] 5 / 7 / 8 / 20:   1%|          | 21/2690 [00:07<15:32,  2.86it/s][Succeeded / Failed / Skipped / Total] 5 / 7 / 9 / 21:   1%|          | 21/2690 [00:07<15:32,  2.86it/s][Succeeded / Failed / Skipped / Total] 5 / 7 / 10 / 22:   1%|          | 22/2690 [00:07<14:51,  2.99it/s][Succeeded / Failed / Skipped / Total] 6 / 7 / 10 / 23:   1%|          | 23/2690 [00:07<14:47,  3.00it/s][[0 (99%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static int read_code_table(CLLCContext *ctx, GetBitContext *[[gb]], VLC *[[vlc]]) { uint8_t [[symbols]][256]; uint8_t [[bits]][256]; uint16_t codes[256]; int [[num_lens]], num_codes, num_codes_sum, prefix; int i, j, count; prefix = 0; count = 0; num_codes_sum = 0; [[num_lens]] = get_bits([[gb]], 5); for (i = 0; i < [[num_lens]]; i++) { num_codes = get_bits([[gb]], 9); num_codes_sum += num_codes; if (num_codes_sum > 256) { av_log(ctx->avctx, AV_LOG_ERROR, "Too many VLCs (%d) to be read.\n", num_codes_sum); for (j = 0; j < num_codes; j++) { [[symbols]][count] = get_bits([[gb]], 8); [[bits]][count] = i + 1; codes[count] = prefix++; count++; if (prefix > (65535 - 256)/2) { prefix <<= 1; return ff_init_vlc_sparse([[vlc]], VLC_BITS, count, [[bits]], 1, 1, codes, 2, 2, [[symbols]], 1, 1, 0);

[[[[Adv]]]]: static int read_code_table(CLLCContext *ctx, GetBitContext *[[clocked]], VLC *[[playlist]]) { uint8_t [[documentation]][256]; uint8_t [[part]][256]; uint16_t codes[256]; int [[gluttons]], num_codes, num_codes_sum, prefix; int i, j, count; prefix = 0; count = 0; num_codes_sum = 0; [[gluttons]] = get_bits([[clocked]], 5); for (i = 0; i < [[gluttons]]; i++) { num_codes = get_bits([[clocked]], 9); num_codes_sum += num_codes; if (num_codes_sum > 256) { av_log(ctx->avctx, AV_LOG_ERROR, "Too many VLCs (%d) to be read.\n", num_codes_sum); for (j = 0; j < num_codes; j++) { [[documentation]][count] = get_bits([[clocked]], 8); [[part]][count] = i + 1; codes[count] = prefix++; count++; if (prefix > (65535 - 256)/2) { prefix <<= 1; return ff_init_vlc_sparse([[playlist]], VLC_BITS, count, [[part]], 1, 1, codes, 2, 2, [[documentation]], 1, 1, 0);


--------------------------------------------- Result 21 ---------------------------------------------
[[0 (35%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int cbs_h265_read_nal_unit(CodedBitstreamContext *ctx, CodedBitstreamUnit *unit) { BitstreamContext bc; int err; err = bitstream_init(&bc, unit->data, 8 * unit->data_size); if (err < 0) return err; switch (unit->type) { case HEVC_NAL_VPS: { H265RawVPS *vps; vps = av_mallocz(sizeof(*vps)); if (!vps) return AVERROR(ENOMEM); err = cbs_h265_read_vps(ctx, &bc, vps); if (err >= 0) err = cbs_h265_replace_vps(ctx, vps); if (err < 0) { av_free(vps); return err; } unit->content = vps; } break; case HEVC_NAL_SPS: { H265RawSPS *sps; sps = av_mallocz(sizeof(*sps)); if (!sps) return AVERROR(ENOMEM); err = cbs_h265_read_sps(ctx, &bc, sps); if (err >= 0) err = cbs_h265_replace_sps(ctx, sps); if (err < 0) { av_free(sps); return err; } unit->content = sps; } break; case HEVC_NAL_PPS: { H265RawPPS *pps; pps = av_mallocz(sizeof(*pps)); if (!pps) return AVERROR(ENOMEM); err = cbs_h265_read_pps(ctx, &bc, pps); if (err >= 0) err = cbs_h265_replace_pps(ctx, pps); if (err < 0) { av_free(pps); return err; } unit->content = pps; } break; case HEVC_NAL_TRAIL_N: case HEVC_NAL_TRAIL_R: case HEVC_NAL_TSA_N: case HEVC_NAL_TSA_R: case HEVC_NAL_STSA_N: case HEVC_NAL_STSA_R: case HEVC_NAL_RADL_N: case HEVC_NAL_RADL_R: case HEVC_NAL_RASL_N: case HEVC_NAL_RASL_R: case HEVC_NAL_BLA_W_LP: case HEVC_NAL_BLA_W_RADL: case HEVC_NAL_BLA_N_LP: case HEVC_NAL_IDR_W_RADL: case HEVC_NAL_IDR_N_LP: case HEVC_NAL_CRA_NUT: { H265RawSlice *slice; int pos, len; slice = av_mallocz(sizeof(*slice)); if (!slice) return AVERROR(ENOMEM); err = cbs_h265_read_slice_segment_header(ctx, &bc, &slice->header); if (err < 0) { av_free(slice); return err; } pos = bitstream_tell(&bc); len = unit->data_size; if (!unit->data[len - 1]) { int z; for (z = 0; z < len && !unit->data[len - z - 1]; z++); av_log(ctx->log_ctx, AV_LOG_DEBUG, "Deleted %d trailing zeroes " "from slice data.\n", z); len -= z; } slice->data_size = len - pos / 8; slice->data = av_malloc(slice->data_size); if (!slice->data) { av_free(slice); return AVERROR(ENOMEM); } memcpy(slice->data, unit->data + pos / 8, slice->data_size); slice->data_bit_start = pos % 8; unit->content = slice; } break; case HEVC_NAL_AUD: { H265RawAUD *aud; aud = av_mallocz(sizeof(*aud)); if (!aud) return AVERROR(ENOMEM); err = cbs_h265_read_aud(ctx, &bc, aud); if (err < 0) { av_free(aud); return err; } unit->content = aud; } break; default: return AVERROR(ENOSYS); } return 0; }


--------------------------------------------- Result 22 ---------------------------------------------
[[0 (1%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static void qpa_audio_fini (void *opaque) { (void) opaque; }


--------------------------------------------- Result 23 ---------------------------------------------
[[0 (53%)]] --> [[0 (45%)]] --> Socre: 0.5510514974594116

[[[[Adv]]]]: static void usbredir_bulk_packet(void *priv, uint32_t id, struct usb_redir_bulk_packet_header *bulk_packet, uint8_t *data, int data_len) { USBRedirDevice *dev = priv; uint8_t ep = bulk_packet->endpoint; int len = bulk_packet->length; AsyncURB *[[aurb]]; DPRINTF("bulk-in status %d ep %02X len %d id %u\n", bulk_packet->status, ep, len, id); [[aurb]] = async_find(dev, id); if (![[aurb]]) { free(data); return; } if ([[aurb]]->bulk_packet.endpoint != bulk_packet->endpoint || [[aurb]]->bulk_packet.stream_id != bulk_packet->stream_id) { ERROR("return bulk packet mismatch, please report this!\n"); len = USB_RET_NAK; } if ([[aurb]]->packet) { len = usbredir_handle_status(dev, bulk_packet->status, len); if (len > 0) { usbredir_log_data(dev, "bulk data in:", data, data_len); if (data_len <= [[aurb]]->packet->len) { memcpy([[aurb]]->packet->data, data, data_len); } else { ERROR("bulk buffer too small (%d > %d)\n", data_len, [[aurb]]->packet->len); len = USB_RET_STALL; } } [[aurb]]->packet->len = len; usb_packet_complete(&dev->dev, [[aurb]]->packet); } async_free(dev, [[aurb]]); free(data); }

[[[[Adv]]]]: static void usbredir_bulk_packet(void *priv, uint32_t id, struct usb_redir_bulk_packet_header *bulk_packet, uint8_t *data, int data_len) { USBRedirDevice *dev = priv; uint8_t ep = bulk_packet->endpoint; int len = bulk_packet->length; AsyncURB *[[disposition]]; DPRINTF("bulk-in status %d ep %02X len %d id %u\n", bulk_packet->status, ep, len, id); [[disposition]] = async_find(dev, id); if (![[disposition]]) { free(data); return; } if ([[disposition]]->bulk_packet.endpoint != bulk_packet->endpoint || [[disposition]]->bulk_packet.stream_id != bulk_packet->stream_id) { ERROR("return bulk packet mismatch, please report this!\n"); len = USB_RET_NAK; } if ([[disposition]]->packet) { len = usbredir_handle_status(dev, bulk_packet->status, len); if (len > 0) { usbredir_log_data(dev, "bulk data in:", data, data_len); if (data_len <= [[disposition]]->packet->len) { memcpy([[disposition]]->packet->data, data, data_len); } else { ERROR("bulk buffer too small (%d > %d)\n", data_len, [[disposition]]->packet->len); len = USB_RET_STALL; } } [[disposition]]->packet->len = len; usb_packet_complete(&dev->dev, [[disposition]]->packet); } async_free(dev, [[disposition]]); free(data); }


--------------------------------------------- Result 24 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 7 / 7 / 10 / 24:   1%|          | 24/2690 [00:07<14:36,  3.04it/s][Succeeded / Failed / Skipped / Total] 7 / 7 / 10 / 24:   1%|          | 25/2690 [00:08<15:37,  2.84it/s][Succeeded / Failed / Skipped / Total] 7 / 8 / 10 / 25:   1%|          | 25/2690 [00:08<15:37,  2.84it/s][Succeeded / Failed / Skipped / Total] 7 / 8 / 11 / 26:   1%|          | 26/2690 [00:08<15:02,  2.95it/s][Succeeded / Failed / Skipped / Total] 7 / 9 / 11 / 27:   1%|          | 27/2690 [00:10<16:37,  2.67it/s][Succeeded / Failed / Skipped / Total] 7 / 9 / 12 / 28:   1%|          | 28/2690 [00:10<16:01,  2.77it/s][Succeeded / Failed / Skipped / Total] 7 / 9 / 12 / 28:   1%|          | 29/2690 [00:10<15:52,  2.79it/s][[0 (51%)]] --> [[0 (46%)]] --> Socre: 0.5410475432872772

[[[[Adv]]]]: static av_cold int hevc_init_context(AVCodecContext *avctx) { HEVCContext *[[s]] = avctx->priv_data; int i; [[s]]->avctx = avctx; [[s]]->HEVClc = av_mallocz(sizeof(HEVCLocalContext)); if (![[s]]->HEVClc) goto fail; [[s]]->HEVClcList[0] = [[s]]->HEVClc; [[s]]->sList[0] = [[s]]; [[s]]->cabac_state = av_malloc(HEVC_CONTEXTS); if (![[s]]->cabac_state) goto fail; [[s]]->output_frame = av_frame_alloc(); if (![[s]]->output_frame) goto fail; for (i = 0; i < FF_ARRAY_ELEMS([[s]]->DPB); i++) { [[s]]->DPB[i].frame = av_frame_alloc(); if (![[s]]->DPB[i].frame) goto fail; [[s]]->DPB[i].tf.f = [[s]]->DPB[i].frame; } [[s]]->max_ra = INT_MAX; [[s]]->md5_ctx = av_md5_alloc(); if (![[s]]->md5_ctx) goto fail; ff_bswapdsp_init(&[[s]]->bdsp); [[s]]->context_initialized = 1; [[s]]->eos = 0; return 0; fail: hevc_decode_free(avctx); return AVERROR(ENOMEM); }

[[[[Adv]]]]: static av_cold int hevc_init_context(AVCodecContext *avctx) { HEVCContext *[[science]] = avctx->priv_data; int i; [[science]]->avctx = avctx; [[science]]->HEVClc = av_mallocz(sizeof(HEVCLocalContext)); if (![[science]]->HEVClc) goto fail; [[science]]->HEVClcList[0] = [[science]]->HEVClc; [[science]]->sList[0] = [[science]]; [[science]]->cabac_state = av_malloc(HEVC_CONTEXTS); if (![[science]]->cabac_state) goto fail; [[science]]->output_frame = av_frame_alloc(); if (![[science]]->output_frame) goto fail; for (i = 0; i < FF_ARRAY_ELEMS([[science]]->DPB); i++) { [[science]]->DPB[i].frame = av_frame_alloc(); if (![[science]]->DPB[i].frame) goto fail; [[science]]->DPB[i].tf.f = [[science]]->DPB[i].frame; } [[science]]->max_ra = INT_MAX; [[science]]->md5_ctx = av_md5_alloc(); if (![[science]]->md5_ctx) goto fail; ff_bswapdsp_init(&[[science]]->bdsp); [[science]]->context_initialized = 1; [[science]]->eos = 0; return 0; fail: hevc_decode_free(avctx); return AVERROR(ENOMEM); }


--------------------------------------------- Result 25 ---------------------------------------------
[[0 (78%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static int decode_plte_chunk(AVCodecContext *[[avctx]], PNGDecContext *[[s]], uint32_t [[length]]) { int [[n]], i, r, g, b; if (([[length]] % 3) != 0 || [[length]] > 256 * 3) return AVERROR_INVALIDDATA; [[n]] = [[length]] / 3; for (i = 0; i < [[n]]; i++) { r = bytestream2_get_byte(&[[s]]->gb); g = bytestream2_get_byte(&[[s]]->gb); b = bytestream2_get_byte(&[[s]]->gb); [[s]]->palette[i] = (0xFFU << 24) | (r << 16) | (g << 8) | b; } for (; i < 256; i++) [[s]]->palette[i] = (0xFFU << 24); [[s]]->state |= PNG_PLTE; bytestream2_skip(&[[s]]->gb, 4); return 0; }

[[[[Adv]]]]: static int decode_plte_chunk(AVCodecContext *[[geek]], PNGDecContext *[[secs]], uint32_t [[protracted]]) { int [[page]], i, r, g, b; if (([[protracted]] % 3) != 0 || [[protracted]] > 256 * 3) return AVERROR_INVALIDDATA; [[page]] = [[protracted]] / 3; for (i = 0; i < [[page]]; i++) { r = bytestream2_get_byte(&[[secs]]->gb); g = bytestream2_get_byte(&[[secs]]->gb); b = bytestream2_get_byte(&[[secs]]->gb); [[secs]]->palette[i] = (0xFFU << 24) | (r << 16) | (g << 8) | b; } for (; i < 256; i++) [[secs]]->palette[i] = (0xFFU << 24); [[secs]]->state |= PNG_PLTE; bytestream2_skip(&[[secs]]->gb, 4); return 0; }


--------------------------------------------- Result 26 ---------------------------------------------
[[0 (9%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static MemTxResult vtd_mem_ir_write(void *opaque, hwaddr addr, uint64_t value, unsigned size, MemTxAttrs attrs) { int ret = 0; MSIMessage from = {0}, to = {0}; from.address = (uint64_t) addr + VTD_INTERRUPT_ADDR_FIRST; from.data = (uint32_t) value; ret = vtd_interrupt_remap_msi(opaque, &from, &to); if (ret) { VTD_DPRINTF(GENERAL, "int remap fail for addr 0x%"PRIx64 " data 0x%"PRIx32, from.address, from.data); return MEMTX_ERROR; } VTD_DPRINTF(IR, "delivering MSI 0x%"PRIx64":0x%"PRIx32 " for device sid 0x%04x", to.address, to.data, sid); if (dma_memory_write(&address_space_memory, to.address, &to.data, size)) { VTD_DPRINTF(GENERAL, "error: fail to write 0x%"PRIx64 " value 0x%"PRIx32, to.address, to.data); } return MEMTX_OK; }


--------------------------------------------- Result 27 ---------------------------------------------
[[0 (27%)]] --> [[[FAILED]]]

[[[[Adv]]]]: VirtIODevice *virtio_blk_init(DeviceState *dev, BlockConf *[[conf]], char **[[serial]]) { VirtIOBlock *[[s]]; int [[cylinders]], heads, secs; static int virtio_blk_id; DriveInfo *[[dinfo]]; if (![[conf]]->bs) { error_report("virtio-blk-pci: drive property not set"); return NULL; } if (!bdrv_is_inserted([[conf]]->bs)) { error_report("Device needs media, but drive is empty"); return NULL; } if (!*[[serial]]) { [[dinfo]] = drive_get_by_blockdev([[conf]]->bs); if (*[[dinfo]]->serial) { *[[serial]] = strdup([[dinfo]]->serial); } } [[s]] = (VirtIOBlock *)virtio_common_init("virtio-blk", VIRTIO_ID_BLOCK, sizeof(struct virtio_blk_config), sizeof(VirtIOBlock)); [[s]]->vdev.get_config = virtio_blk_update_config; [[s]]->vdev.get_features = virtio_blk_get_features; [[s]]->vdev.reset = virtio_blk_reset; [[s]]->bs = [[conf]]->bs; [[s]]->conf = [[conf]]; [[s]]->serial = *[[serial]]; [[s]]->rq = NULL; [[s]]->sector_mask = ([[s]]->conf->logical_block_size / BDRV_SECTOR_SIZE) - 1; bdrv_guess_geometry([[s]]->bs, &[[cylinders]], &heads, &secs); [[s]]->vq = virtio_add_queue(&[[s]]->vdev, 128, virtio_blk_handle_output); qemu_add_vm_change_state_handler(virtio_blk_dma_restart_cb, [[s]]); [[s]]->qdev = dev; register_savevm(dev, "virtio-blk", virtio_blk_id++, 2, virtio_blk_save, virtio_blk_load, [[s]]); bdrv_set_dev_ops([[s]]->bs, &virtio_block_ops, [[s]]); bdrv_set_buffer_alignment([[s]]->bs, [[conf]]->logical_block_size); bdrv_iostatus_enable([[s]]->bs); add_boot_device_path([[conf]]->bootindex, dev, "/disk@0,0"); return &[[s]]->vdev; }

[[[[Adv]]]]: VirtIODevice *virtio_blk_init(DeviceState *dev, BlockConf *[[div]], char **[[ensemble]]) { VirtIOBlock *[[avec]]; int [[gallons]], heads, secs; static int virtio_blk_id; DriveInfo *[[orm]]; if (![[div]]->bs) { error_report("virtio-blk-pci: drive property not set"); return NULL; } if (!bdrv_is_inserted([[div]]->bs)) { error_report("Device needs media, but drive is empty"); return NULL; } if (!*[[ensemble]]) { [[orm]] = drive_get_by_blockdev([[div]]->bs); if (*[[orm]]->serial) { *[[ensemble]] = strdup([[orm]]->serial); } } [[avec]] = (VirtIOBlock *)virtio_common_init("virtio-blk", VIRTIO_ID_BLOCK, sizeof(struct virtio_blk_config), sizeof(VirtIOBlock)); [[avec]]->vdev.get_config = virtio_blk_update_config; [[avec]]->vdev.get_features = virtio_blk_get_features; [[avec]]->vdev.reset = virtio_blk_reset; [[avec]]->bs = [[div]]->bs; [[avec]]->conf = [[div]]; [[avec]]->serial = *[[ensemble]]; [[avec]]->rq = NULL; [[avec]]->sector_mask = ([[avec]]->conf->logical_block_size / BDRV_SECTOR_SIZE) - 1; bdrv_guess_geometry([[avec]]->bs, &[[gallons]], &heads, &secs); [[avec]]->vq = virtio_add_queue(&[[avec]]->vdev, 128, virtio_blk_handle_output); qemu_add_vm_change_state_handler(virtio_blk_dma_restart_cb, [[avec]]); [[avec]]->qdev = dev; register_savevm(dev, "virtio-blk", virtio_blk_id++, 2, virtio_blk_save, virtio_blk_load, [[avec]]); bdrv_set_dev_ops([[avec]]->bs, &virtio_block_ops, [[avec]]); bdrv_set_buffer_alignment([[avec]]->bs, [[div]]->logical_block_size); bdrv_iostatus_enable([[avec]]->bs); add_boot_device_path([[div]]->bootindex, dev, "/disk@0,0"); return &[[avec]]->vdev; }


--------------------------------------------- Result 28 ---------------------------------------------
[[0 (29%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static size_t header_ext_add(char *buf, uint32_t magic, const void *s, size_t len, size_t buflen) { QCowExtension *ext_backing_fmt = (QCowExtension*) buf; size_t ext_len = sizeof(QCowExtension) + ((len + 7) & ~7); if (buflen < ext_len) { return -ENOSPC; } *ext_backing_fmt = (QCowExtension) { .magic = cpu_to_be32(magic), .len = cpu_to_be32(len), }; memcpy(buf + sizeof(QCowExtension), s, len); return ext_len; }


--------------------------------------------- Result 29 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 8 / 9 / 12 / 29:   1%|          | 29/2690 [00:10<15:52,  2.79it/s][Succeeded / Failed / Skipped / Total] 8 / 10 / 12 / 30:   1%|          | 30/2690 [00:10<15:58,  2.78it/s][Succeeded / Failed / Skipped / Total] 8 / 10 / 13 / 31:   1%|          | 31/2690 [00:10<15:27,  2.87it/s][Succeeded / Failed / Skipped / Total] 8 / 10 / 14 / 32:   1%|          | 32/2690 [00:10<14:59,  2.96it/s][Succeeded / Failed / Skipped / Total] 8 / 10 / 14 / 32:   1%|          | 33/2690 [00:10<14:32,  3.05it/s][Succeeded / Failed / Skipped / Total] 8 / 10 / 15 / 33:   1%|          | 33/2690 [00:10<14:32,  3.05it/s][[0 (52%)]] --> [[0 (47%)]] --> Socre: 0.5295627117156982

[[[[Adv]]]]: static int mov_read_strf(MOVContext *c, AVIOContext *pb, MOVAtom atom) { AVStream *[[st]]; if (c->fc->nb_streams < 1) return 0; if (atom.size <= 40) return 0; [[st]] = c->fc->streams[c->fc->nb_streams-1]; if ((uint64_t)atom.size > (1<<30)) return AVERROR_INVALIDDATA; av_free([[st]]->codec->extradata); [[st]]->codec->extradata = av_mallocz(atom.size - 40 + FF_INPUT_BUFFER_PADDING_SIZE); if (![[st]]->codec->extradata) return AVERROR(ENOMEM); [[st]]->codec->extradata_size = atom.size - 40; avio_skip(pb, 40); avio_read(pb, [[st]]->codec->extradata, atom.size - 40); return 0; }

[[[[Adv]]]]: static int mov_read_strf(MOVContext *c, AVIOContext *pb, MOVAtom atom) { AVStream *[[albans]]; if (c->fc->nb_streams < 1) return 0; if (atom.size <= 40) return 0; [[albans]] = c->fc->streams[c->fc->nb_streams-1]; if ((uint64_t)atom.size > (1<<30)) return AVERROR_INVALIDDATA; av_free([[albans]]->codec->extradata); [[albans]]->codec->extradata = av_mallocz(atom.size - 40 + FF_INPUT_BUFFER_PADDING_SIZE); if (![[albans]]->codec->extradata) return AVERROR(ENOMEM); [[albans]]->codec->extradata_size = atom.size - 40; avio_skip(pb, 40); avio_read(pb, [[albans]]->codec->extradata, atom.size - 40); return 0; }


--------------------------------------------- Result 30 ---------------------------------------------
[[0 (2%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static void mem_begin(MemoryListener *[[listener]]) { AddressSpaceDispatch *[[d]] = container_of([[listener]], AddressSpaceDispatch, [[listener]]); [[d]]->phys_map.ptr = PHYS_MAP_NODE_NIL; }

[[[[Adv]]]]: static void mem_begin(MemoryListener *[[bugging]]) { AddressSpaceDispatch *[[di]] = container_of([[bugging]], AddressSpaceDispatch, [[bugging]]); [[di]]->phys_map.ptr = PHYS_MAP_NODE_NIL; }


--------------------------------------------- Result 31 ---------------------------------------------
[[0 (55%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static uint32_t tight_palette_buf2rgb(int bpp, const uint8_t *buf) { uint32_t rgb = 0; if (bpp == 32) { rgb |= ((buf[0] & ~1) | !((buf[4] >> 3) & 1)) << 24; rgb |= ((buf[1] & ~1) | !((buf[4] >> 2) & 1)) << 16; rgb |= ((buf[2] & ~1) | !((buf[4] >> 1) & 1)) << 8; rgb |= ((buf[3] & ~1) | !((buf[4] >> 0) & 1)) << 0; } if (bpp == 16) { rgb |= ((buf[0] & ~1) | !((buf[2] >> 1) & 1)) << 8; rgb |= ((buf[1] & ~1) | !((buf[2] >> 0) & 1)) << 0; } return rgb; }


--------------------------------------------- Result 32 ---------------------------------------------
[[0 (38%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: int net_init_tap(const Netdev *netdev, const char *name, NetClientState *peer, Error **errp) { const NetdevTapOptions *tap; int fd, vnet_hdr = 0, i = 0, queues; const char *script = NULL; const char *downscript = NULL; Error *err = NULL; const char *vhostfdname; char ifname[128]; assert(netdev->type == NET_CLIENT_DRIVER_TAP); tap = &netdev->u.tap; queues = tap->has_queues ? tap->queues : 1; vhostfdname = tap->has_vhostfd ? tap->vhostfd : NULL; if (peer && (tap->has_queues || tap->has_fds || tap->has_vhostfds)) { error_setg(errp, "Multiqueue tap cannot be used with QEMU vlans"); return -1; } if (tap->has_fd) { if (tap->has_ifname || tap->has_script || tap->has_downscript || tap->has_vnet_hdr || tap->has_helper || tap->has_queues || tap->has_fds || tap->has_vhostfds) { error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, " "helper=, queues=, fds=, and vhostfds= " "are invalid with fd="); return -1; } fd = monitor_fd_param(cur_mon, tap->fd, &err); if (fd == -1) { error_propagate(errp, err); return -1; } fcntl(fd, F_SETFL, O_NONBLOCK); vnet_hdr = tap_probe_vnet_hdr(fd); net_init_tap_one(tap, peer, "tap", name, NULL, script, downscript, vhostfdname, vnet_hdr, fd, &err); if (err) { error_propagate(errp, err); return -1; } } else if (tap->has_fds) { char **fds = g_new0(char *, MAX_TAP_QUEUES); char **vhost_fds = g_new0(char *, MAX_TAP_QUEUES); int nfds, nvhosts; if (tap->has_ifname || tap->has_script || tap->has_downscript || tap->has_vnet_hdr || tap->has_helper || tap->has_queues || tap->has_vhostfd) { error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, " "helper=, queues=, and vhostfd= " "are invalid with fds="); return -1; } nfds = get_fds(tap->fds, fds, MAX_TAP_QUEUES); if (tap->has_vhostfds) { nvhosts = get_fds(tap->vhostfds, vhost_fds, MAX_TAP_QUEUES); if (nfds != nvhosts) { error_setg(errp, "The number of fds passed does not match " "the number of vhostfds passed"); goto free_fail; } } for (i = 0; i < nfds; i++) { fd = monitor_fd_param(cur_mon, fds[i], &err); if (fd == -1) { error_propagate(errp, err); goto free_fail; } fcntl(fd, F_SETFL, O_NONBLOCK); if (i == 0) { vnet_hdr = tap_probe_vnet_hdr(fd); } else if (vnet_hdr != tap_probe_vnet_hdr(fd)) { error_setg(errp, "vnet_hdr not consistent across given tap fds"); goto free_fail; } net_init_tap_one(tap, peer, "tap", name, ifname, script, downscript, tap->has_vhostfds ? vhost_fds[i] : NULL, vnet_hdr, fd, &err); if (err) { error_propagate(errp, err); goto free_fail; } } g_free(fds); g_free(vhost_fds); return 0; free_fail: for (i = 0; i < nfds; i++) { g_free(fds[i]); g_free(vhost_fds[i]); } g_free(fds); g_free(vhost_fds); return -1; } else if (tap->has_helper) { if (tap->has_ifname || tap->has_script || tap->has_downscript || tap->has_vnet_hdr || tap->has_queues || tap->has_vhostfds) { error_setg(errp, "ifname=, script=, downscript=, vnet_hdr=, " "queues=, and vhostfds= are invalid with helper="); return -1; } fd = net_bridge_run_helper(tap->helper, tap->has_br ? tap->br : DEFAULT_BRIDGE_INTERFACE, errp); if (fd == -1) { return -1; } fcntl(fd, F_SETFL, O_NONBLOCK); vnet_hdr = tap_probe_vnet_hdr(fd); net_init_tap_one(tap, peer, "bridge", name, ifname, script, downscript, vhostfdname, vnet_hdr, fd, &err); if (err) { error_propagate(errp, err); close(fd); return -1; } } else { if (tap->has_vhostfds) { error_setg(errp, "vhostfds= is invalid if fds= wasn't specified"); return -1; } script = tap->has_script ? tap->script : DEFAULT_NETWORK_SCRIPT; downscript = tap->has_downscript ? tap->downscript : DEFAULT_NETWORK_DOWN_SCRIPT; if (tap->has_ifname) { pstrcpy(ifname, sizeof ifname, tap->ifname); } else { ifname[0] = '\0'; } for (i = 0; i < queues; i++) { fd = net_tap_init(tap, &vnet_hdr, i >= 1 ? "no" : script, ifname, sizeof ifname, queues > 1, errp); if (fd == -1) { return -1; } if (queues > 1 && i == 0 && !tap->has_ifname) { if (tap_fd_get_ifname(fd, ifname)) { error_setg(errp, "Fail to get ifname"); close(fd); return -1; } } net_init_tap_one(tap, peer, "tap", name, ifname, i >= 1 ? "no" : script, i >= 1 ? "no" : downscript, vhostfdname, vnet_hdr, fd, &err); if (err) { error_propagate(errp, err); close(fd); return -1; } } } return 0; }


--------------------------------------------- Result 33 ---------------------------------------------
[[0 (49%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: void stream_start(const char *job_id, BlockDriverState *bs, BlockDriverState *base, const char *backing_file_str, int64_t speed, BlockdevOnError on_error, BlockCompletionFunc *cb, void *opaque, Error **errp) { StreamBlockJob *s; s = block_job_create(job_id, &stream_job_driver, bs, speed, cb, opaque, errp); if (!s) { return; } s->base = base; s->backing_file_str = g_strdup(backing_file_str); s->on_error = on_error; s->common.co = qemu_coroutine_create(stream_run); trace_stream_start(bs, base, s, s->common.co, opaque); qemu_coroutine_enter(s->common.co, s); }


--------------------------------------------- Result 34 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 8 / 11 / 15 / 34:   1%|         | 34/2690 [00:12<15:46,  2.81it/s][Succeeded / Failed / Skipped / Total] 9 / 11 / 15 / 35:   1%|         | 35/2690 [00:12<15:38,  2.83it/s][Succeeded / Failed / Skipped / Total] 9 / 11 / 16 / 36:   1%|         | 36/2690 [00:12<15:12,  2.91it/s][Succeeded / Failed / Skipped / Total] 9 / 11 / 16 / 36:   1%|         | 37/2690 [00:13<15:37,  2.83it/s][Succeeded / Failed / Skipped / Total] 9 / 12 / 16 / 37:   1%|         | 37/2690 [00:13<15:37,  2.83it/s][Succeeded / Failed / Skipped / Total] 9 / 13 / 16 / 38:   1%|         | 38/2690 [00:13<15:43,  2.81it/s][Succeeded / Failed / Skipped / Total] 9 / 14 / 16 / 39:   1%|         | 39/2690 [00:14<16:45,  2.64it/s][[0 (67%)]] --> [[[FAILED]]]

[[[[Adv]]]]: int attribute_align_arg avcodec_decode_video2(AVCodecContext *[[avctx]], AVFrame *[[picture]], int *got_picture_ptr, AVPacket *[[avpkt]]) { int [[ret]]; *got_picture_ptr = 0; if (([[avctx]]->coded_width || [[avctx]]->coded_height) && av_image_check_size([[avctx]]->coded_width, [[avctx]]->coded_height, 0, [[avctx]])) return -1; [[avctx]]->pkt = [[avpkt]]; apply_param_change([[avctx]], [[avpkt]]); if (([[avctx]]->codec->capabilities & CODEC_CAP_DELAY) || [[avpkt]]->size || ([[avctx]]->active_thread_type & FF_THREAD_FRAME)) { if (HAVE_THREADS && [[avctx]]->active_thread_type & FF_THREAD_FRAME) [[ret]] = ff_thread_decode_frame([[avctx]], [[picture]], got_picture_ptr, [[avpkt]]); else { [[ret]] = [[avctx]]->codec->decode([[avctx]], [[picture]], got_picture_ptr, [[avpkt]]); [[picture]]->pkt_dts = [[avpkt]]->dts; [[picture]]->sample_aspect_ratio = [[avctx]]->sample_aspect_ratio; [[picture]]->width = [[avctx]]->width; [[picture]]->height = [[avctx]]->height; [[picture]]->format = [[avctx]]->pix_fmt; } emms_c(); if (*got_picture_ptr) [[avctx]]->frame_number++; } else [[ret]] = 0; [[picture]]->extended_data = [[picture]]->data; return [[ret]]; }

[[[[Adv]]]]: int attribute_align_arg avcodec_decode_video2(AVCodecContext *[[forecasting]], AVFrame *[[archives]], int *got_picture_ptr, AVPacket *[[tibby]]) { int [[dodd]]; *got_picture_ptr = 0; if (([[forecasting]]->coded_width || [[forecasting]]->coded_height) && av_image_check_size([[forecasting]]->coded_width, [[forecasting]]->coded_height, 0, [[forecasting]])) return -1; [[forecasting]]->pkt = [[tibby]]; apply_param_change([[forecasting]], [[tibby]]); if (([[forecasting]]->codec->capabilities & CODEC_CAP_DELAY) || [[tibby]]->size || ([[forecasting]]->active_thread_type & FF_THREAD_FRAME)) { if (HAVE_THREADS && [[forecasting]]->active_thread_type & FF_THREAD_FRAME) [[dodd]] = ff_thread_decode_frame([[forecasting]], [[archives]], got_picture_ptr, [[tibby]]); else { [[dodd]] = [[forecasting]]->codec->decode([[forecasting]], [[archives]], got_picture_ptr, [[tibby]]); [[archives]]->pkt_dts = [[tibby]]->dts; [[archives]]->sample_aspect_ratio = [[forecasting]]->sample_aspect_ratio; [[archives]]->width = [[forecasting]]->width; [[archives]]->height = [[forecasting]]->height; [[archives]]->format = [[forecasting]]->pix_fmt; } emms_c(); if (*got_picture_ptr) [[forecasting]]->frame_number++; } else [[dodd]] = 0; [[archives]]->extended_data = [[archives]]->data; return [[dodd]]; }


--------------------------------------------- Result 35 ---------------------------------------------
[[0 (51%)]] --> [[0 (22%)]] --> Socre: 0.7757752686738968

[[[[Adv]]]]: static int omap_gpio_init(SysBusDevice *sbd) { DeviceState *[[dev]] = DEVICE(sbd); struct omap_gpif_s *s = OMAP1_GPIO([[dev]]); if (!s->clk) { hw_error("omap-gpio: clk not connected\n"); } qdev_init_gpio_in([[dev]], omap_gpio_set, 16); qdev_init_gpio_out([[dev]], s->omap1.handler, 16); sysbus_init_irq(sbd, &s->omap1.irq); memory_region_init_io(&s->iomem, OBJECT(s), &omap_gpio_ops, &s->omap1, "omap.gpio", 0x1000); sysbus_init_mmio(sbd, &s->iomem); return 0; }

[[[[Adv]]]]: static int omap_gpio_init(SysBusDevice *sbd) { DeviceState *[[ashok]] = DEVICE(sbd); struct omap_gpif_s *s = OMAP1_GPIO([[ashok]]); if (!s->clk) { hw_error("omap-gpio: clk not connected\n"); } qdev_init_gpio_in([[ashok]], omap_gpio_set, 16); qdev_init_gpio_out([[ashok]], s->omap1.handler, 16); sysbus_init_irq(sbd, &s->omap1.irq); memory_region_init_io(&s->iomem, OBJECT(s), &omap_gpio_ops, &s->omap1, "omap.gpio", 0x1000); sysbus_init_mmio(sbd, &s->iomem); return 0; }


--------------------------------------------- Result 36 ---------------------------------------------
[[0 (6%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: void omap_mcbsp_i2s_attach(struct omap_mcbsp_s *s, I2SCodec *slave) { s->codec = slave; slave->rx_swallow = qemu_allocate_irqs(omap_mcbsp_i2s_swallow, s, 1)[0]; slave->tx_start = qemu_allocate_irqs(omap_mcbsp_i2s_start, s, 1)[0]; }


--------------------------------------------- Result 37 ---------------------------------------------
[[0 (2%)]] --> [[[FAILED]]]

[[[[Adv]]]]: int floatx80_eq(floatx80 [[a]], floatx80 [[b]], float_status *[[status]]) { if ( ( ( extractFloatx80Exp( [[a]] ) == 0x7FFF ) && (uint64_t) ( extractFloatx80Frac( [[a]] )<<1 ) ) || ( ( extractFloatx80Exp( [[b]] ) == 0x7FFF ) && (uint64_t) ( extractFloatx80Frac( [[b]] )<<1 ) ) ) { float_raise(float_flag_invalid, [[status]]); return 0; } return ( [[a]].low == [[b]].low ) && ( ( [[a]].high == [[b]].high ) || ( ( [[a]].low == 0 ) && ( (uint16_t) ( ( [[a]].high | [[b]].high )<<1 ) == 0 ) ) ); }

[[[[Adv]]]]: int floatx80_eq(floatx80 [[avec]], floatx80 [[a]], float_status *[[diseases]]) { if ( ( ( extractFloatx80Exp( [[avec]] ) == 0x7FFF ) && (uint64_t) ( extractFloatx80Frac( [[avec]] )<<1 ) ) || ( ( extractFloatx80Exp( [[a]] ) == 0x7FFF ) && (uint64_t) ( extractFloatx80Frac( [[a]] )<<1 ) ) ) { float_raise(float_flag_invalid, [[diseases]]); return 0; } return ( [[avec]].low == [[a]].low ) && ( ( [[avec]].high == [[a]].high ) || ( ( [[avec]].low == 0 ) && ( (uint16_t) ( ( [[avec]].high | [[a]].high )<<1 ) == 0 ) ) ); }


--------------------------------------------- Result 38 ---------------------------------------------
[[0 (3%)]] --> [[[FAILED]]]

[[[[Adv]]]]: void json_lexer_init(JSONLexer *[[lexer]], JSONLexerEmitter [[func]]) { [[lexer]]->emit = [[func]]; [[lexer]]->state = IN_START; [[lexer]]->token = qstring_new(); [[lexer]]->x = [[lexer]]->y = 0; }

[[[[Adv]]]]: void json_lexer_init(JSONLexer *[[tinka]], JSONLexerEmitter [[embrace]]) { [[tinka]]->emit = [[embrace]]; [[tinka]]->state = IN_START; [[tinka]]->token = qstring_new(); [[tinka]]->x = [[tinka]]->y = 0; }


--------------------------------------------- Result 39 ---------------------------------------------
[[0 (17%)]] --> [[[FAILED]]]

[[[[Adv]]]]: BlockDriverAIOCB *paio_submit(BlockDriverState *bs, int [[fd]], int64_t [[sector_num]], QEMUIOVector *[[qiov]], int nb_sectors, BlockDriverCompletionFunc *cb, void *[[opaque]], int [[type]]) { struct qemu_paiocb *acb; acb = qemu_aio_get(&raw_aio_pool, bs, cb, [[opaque]]); if (!acb) return NULL; acb->aio_type = [[type]]; acb->aio_fildes = [[fd]]; acb->ev_signo = SIGUSR2; acb->async_context_id = get_async_context_id(); if ([[qiov]]) { acb->aio_iov = [[qiov]]->iov; acb->aio_niov = [[qiov]]->niov; } acb->aio_nbytes = nb_sectors * 512; acb->aio_offset = [[sector_num]] * 512; acb->next = posix_aio_state->first_aio; posix_aio_state->first_aio = acb; trace_paio_submit(acb, [[opaque]], [[sector_num]], nb_sectors, [[type]]); qemu_paio_submit(acb); return &acb->common; }

[[[[Adv]]]]: BlockDriverAIOCB *paio_submit(BlockDriverState *bs, int [[strip]], int64_t [[netherworld]], QEMUIOVector *[[diwali]], int nb_sectors, BlockDriverCompletionFunc *cb, void *[[bewildering]], int [[gaillard]]) { struct qemu_paiocb *acb; acb = qemu_aio_get(&raw_aio_pool, bs, cb, [[bewildering]]); if (!acb) return NULL; acb->aio_type = [[gaillard]]; acb->aio_fildes = [[strip]]; acb->ev_signo = SIGUSR2; acb->async_context_id = get_async_context_id(); if ([[diwali]]) { acb->aio_iov = [[diwali]]->iov; acb->aio_niov = [[diwali]]->niov; } acb->aio_nbytes = nb_sectors * 512; acb->aio_offset = [[netherworld]] * 512; acb->next = posix_aio_state->first_aio; posix_aio_state->first_aio = acb; trace_paio_submit(acb, [[bewildering]], [[netherworld]], nb_sectors, [[gaillard]]); qemu_paio_submit(acb); return &acb->common; }


--------------------------------------------- Result 40 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 9 / 14 / 17 / 40:   1%|         | 40/2690 [00:14<16:20,  2.70it/s][Succeeded / Failed / Skipped / Total] 9 / 14 / 17 / 40:   2%|         | 41/2690 [00:15<16:28,  2.68it/s][Succeeded / Failed / Skipped / Total] 10 / 14 / 17 / 41:   2%|         | 41/2690 [00:15<16:28,  2.68it/s][Succeeded / Failed / Skipped / Total] 10 / 14 / 18 / 42:   2%|         | 42/2690 [00:15<16:04,  2.74it/s][[0 (35%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int crypto_open(URLContext *h, const char *uri, int flags) { const char *nested_url; int ret; CryptoContext *c = h->priv_data; if (!av_strstart(uri, "crypto+", &nested_url) && !av_strstart(uri, "crypto:", &nested_url)) { av_log(h, AV_LOG_ERROR, "Unsupported url %s\n", uri); ret = AVERROR(EINVAL); goto err; } if (c->keylen < BLOCKSIZE || c->ivlen < BLOCKSIZE) { av_log(h, AV_LOG_ERROR, "Key or IV not set\n"); ret = AVERROR(EINVAL); goto err; } if (flags & AVIO_FLAG_WRITE) { av_log(h, AV_LOG_ERROR, "Only decryption is supported currently\n"); ret = AVERROR(ENOSYS); goto err; } if ((ret = ffurl_open(&c->hd, nested_url, AVIO_FLAG_READ)) < 0) { av_log(h, AV_LOG_ERROR, "Unable to open input\n"); goto err; } c->aes = av_mallocz(av_aes_size); if (!c->aes) { ret = AVERROR(ENOMEM); goto err; } av_aes_init(c->aes, c->key, 128, 1); h->is_streamed = 1; return 0; err: av_free(c->key); av_free(c->iv); return ret; }


--------------------------------------------- Result 41 ---------------------------------------------
[[0 (56%)]] --> [[0 (47%)]] --> Socre: 0.5269769430160522

[[[[Adv]]]]: int ff_alloc_entries(AVCodecContext *avctx, int [[count]]) { int [[i]]; if (avctx->active_thread_type & FF_THREAD_SLICE) { SliceThreadContext *p = avctx->internal->thread_ctx; p->thread_count = avctx->thread_count; p->entries = av_mallocz_array([[count]], sizeof(int)); if (!p->entries) { return AVERROR(ENOMEM); } p->entries_count = [[count]]; p->progress_mutex = av_malloc_array(p->thread_count, sizeof(pthread_mutex_t)); p->progress_cond = av_malloc_array(p->thread_count, sizeof(pthread_cond_t)); for ([[i]] = 0; [[i]] < p->thread_count; [[i]]++) { pthread_mutex_init(&p->progress_mutex[[[i]]], NULL); pthread_cond_init(&p->progress_cond[[[i]]], NULL); } } return 0; }

[[[[Adv]]]]: int ff_alloc_entries(AVCodecContext *avctx, int [[instructs]]) { int [[lai]]; if (avctx->active_thread_type & FF_THREAD_SLICE) { SliceThreadContext *p = avctx->internal->thread_ctx; p->thread_count = avctx->thread_count; p->entries = av_mallocz_array([[instructs]], sizeof(int)); if (!p->entries) { return AVERROR(ENOMEM); } p->entries_count = [[instructs]]; p->progress_mutex = av_malloc_array(p->thread_count, sizeof(pthread_mutex_t)); p->progress_cond = av_malloc_array(p->thread_count, sizeof(pthread_cond_t)); for ([[lai]] = 0; [[lai]] < p->thread_count; [[lai]]++) { pthread_mutex_init(&p->progress_mutex[[[lai]]], NULL); pthread_cond_init(&p->progress_cond[[[lai]]], NULL); } } return 0; }


--------------------------------------------- Result 42 ---------------------------------------------
[[0 (13%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int floppy_probe_device(const char *filename) { int fd, ret; int prio = 0; struct floppy_struct fdparam; struct stat st; if (strstart(filename, "/dev/fd", NULL) && !strstart(filename, "/dev/fdset/", NULL)) { prio = 50; } fd = qemu_open(filename, O_RDONLY | O_NONBLOCK); if (fd < 0) { goto out; } ret = fstat(fd, &st); if (ret == -1 || !S_ISBLK(st.st_mode)) { goto outc; } ret = ioctl(fd, FDGETPRM, &fdparam); if (ret >= 0) prio = 100; outc: qemu_close(fd); out: return prio; }


--------------------------------------------- Result 43 ---------------------------------------------
[[0 (33%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static void sun4uv_init(ram_addr_t RAM_size, const char *boot_devices, const char *[[kernel_filename]], const char *kernel_cmdline, const char *[[initrd_filename]], const char *[[cpu_model]], const struct hwdef *[[hwdef]]) { CPUState *env; char *filename; m48t59_t *nvram; int ret, linux_boot; unsigned int i; ram_addr_t ram_offset, prom_offset; long initrd_size, kernel_size; PCIBus *pci_bus, *pci_bus2, *pci_bus3; QEMUBH *[[bh]]; qemu_irq *irq; int drive_index; BlockDriverState *hd[MAX_IDE_BUS * MAX_IDE_DEVS]; BlockDriverState *fd[MAX_FD]; void *fw_cfg; ResetData *reset_info; linux_boot = ([[kernel_filename]] != NULL); if (![[cpu_model]]) [[cpu_model]] = [[hwdef]]->default_cpu_model; env = cpu_init([[cpu_model]]); if (!env) { fprintf(stderr, "Unable to find Sparc CPU definition\n"); exit(1); } [[bh]] = qemu_bh_new(tick_irq, env); env->tick = ptimer_init([[bh]]); ptimer_set_period(env->tick, 1ULL); [[bh]] = qemu_bh_new(stick_irq, env); env->stick = ptimer_init([[bh]]); ptimer_set_period(env->stick, 1ULL); [[bh]] = qemu_bh_new(hstick_irq, env); env->hstick = ptimer_init([[bh]]); ptimer_set_period(env->hstick, 1ULL); reset_info = qemu_mallocz(sizeof(ResetData)); reset_info->env = env; reset_info->reset_addr = [[hwdef]]->prom_addr + 0x40ULL; qemu_register_reset(main_cpu_reset, reset_info); main_cpu_reset(reset_info); env->pc = [[hwdef]]->prom_addr + 0x20ULL; env->npc = env->pc + 4; ram_offset = qemu_ram_alloc(RAM_size); cpu_register_physical_memory(0, RAM_size, ram_offset); prom_offset = qemu_ram_alloc(PROM_SIZE_MAX); cpu_register_physical_memory([[hwdef]]->prom_addr, (PROM_SIZE_MAX + TARGET_PAGE_SIZE) & TARGET_PAGE_MASK, prom_offset | IO_MEM_ROM); if (bios_name == NULL) bios_name = PROM_FILENAME; filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, bios_name); if (filename) { ret = load_elf(filename, [[hwdef]]->prom_addr - PROM_VADDR, NULL, NULL, NULL); if (ret < 0) { ret = load_image_targphys(filename, [[hwdef]]->prom_addr, (PROM_SIZE_MAX + TARGET_PAGE_SIZE) & TARGET_PAGE_MASK); } qemu_free(filename); } else { ret = -1; } if (ret < 0) { fprintf(stderr, "qemu: could not load prom '%s'\n", bios_name); exit(1); } kernel_size = 0; initrd_size = 0; if (linux_boot) { kernel_size = load_elf([[kernel_filename]], 0, NULL, NULL, NULL); if (kernel_size < 0) kernel_size = load_aout([[kernel_filename]], KERNEL_LOAD_ADDR, ram_size - KERNEL_LOAD_ADDR); if (kernel_size < 0) kernel_size = load_image_targphys([[kernel_filename]], KERNEL_LOAD_ADDR, ram_size - KERNEL_LOAD_ADDR); if (kernel_size < 0) { fprintf(stderr, "qemu: could not load kernel '%s'\n", [[kernel_filename]]); exit(1); } if ([[initrd_filename]]) { initrd_size = load_image_targphys([[initrd_filename]], INITRD_LOAD_ADDR, ram_size - INITRD_LOAD_ADDR); if (initrd_size < 0) { fprintf(stderr, "qemu: could not load initial ram disk '%s'\n", [[initrd_filename]]); exit(1); } } if (initrd_size > 0) { for (i = 0; i < 64 * TARGET_PAGE_SIZE; i += TARGET_PAGE_SIZE) { if (ldl_phys(KERNEL_LOAD_ADDR + i) == 0x48647253) { stl_phys(KERNEL_LOAD_ADDR + i + 16, INITRD_LOAD_ADDR); stl_phys(KERNEL_LOAD_ADDR + i + 20, initrd_size); break; } } } } pci_bus = pci_apb_init(APB_SPECIAL_BASE, APB_MEM_BASE, NULL, &pci_bus2, &pci_bus3); isa_mem_base = VGA_BASE; pci_vga_init(pci_bus, 0, 0); pci_ebus_init(pci_bus, -1); i = 0; if ([[hwdef]]->console_serial_base) { serial_mm_init([[hwdef]]->console_serial_base, 0, NULL, 115200, serial_hds[i], 1); i++; } for(; i < MAX_SERIAL_PORTS; i++) { if (serial_hds[i]) { serial_init(serial_io[i], NULL , 115200, serial_hds[i]); } } for(i = 0; i < MAX_PARALLEL_PORTS; i++) { if (parallel_hds[i]) { parallel_init(parallel_io[i], NULL , parallel_hds[i]); } } for(i = 0; i < nb_nics; i++) pci_nic_init(&nd_table[i], "ne2k_pci", NULL); irq = qemu_allocate_irqs(cpu_set_irq, env, MAX_PILS); if (drive_get_max_bus(IF_IDE) >= MAX_IDE_BUS) { fprintf(stderr, "qemu: too many IDE bus\n"); exit(1); } for(i = 0; i < MAX_IDE_BUS * MAX_IDE_DEVS; i++) { drive_index = drive_get_index(IF_IDE, i / MAX_IDE_DEVS, i % MAX_IDE_DEVS); if (drive_index != -1) hd[i] = drives_table[drive_index].bdrv; else hd[i] = NULL; } pci_cmd646_ide_init(pci_bus, hd, 1); i8042_init(NULL , NULL , 0x60); for(i = 0; i < MAX_FD; i++) { drive_index = drive_get_index(IF_FLOPPY, 0, i); if (drive_index != -1) fd[i] = drives_table[drive_index].bdrv; else fd[i] = NULL; } floppy_controller = fdctrl_init(NULL , 2, 0, 0x3f0, fd); nvram = m48t59_init(NULL , 0, 0x0074, NVRAM_SIZE, 59); sun4u_NVRAM_set_params(nvram, NVRAM_SIZE, "Sun4u", RAM_size, boot_devices, KERNEL_LOAD_ADDR, kernel_size, kernel_cmdline, INITRD_LOAD_ADDR, initrd_size, 0, graphic_width, graphic_height, graphic_depth, (uint8_t *)&nd_table[0].macaddr); fw_cfg = fw_cfg_init(BIOS_CFG_IOPORT, BIOS_CFG_IOPORT + 1, 0, 0); fw_cfg_add_i32(fw_cfg, FW_CFG_ID, 1); fw_cfg_add_i64(fw_cfg, FW_CFG_RAM_SIZE, (uint64_t)ram_size); fw_cfg_add_i16(fw_cfg, FW_CFG_MACHINE_ID, [[hwdef]]->machine_id); fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_ADDR, KERNEL_LOAD_ADDR); fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_SIZE, kernel_size); if (kernel_cmdline) { fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_CMDLINE, CMDLINE_ADDR); pstrcpy_targphys(CMDLINE_ADDR, TARGET_PAGE_SIZE, kernel_cmdline); } else { fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_CMDLINE, 0); } fw_cfg_add_i32(fw_cfg, FW_CFG_INITRD_ADDR, INITRD_LOAD_ADDR); fw_cfg_add_i32(fw_cfg, FW_CFG_INITRD_SIZE, initrd_size); fw_cfg_add_i16(fw_cfg, FW_CFG_BOOT_DEVICE, boot_devices[0]); qemu_register_boot_set(fw_cfg_boot_set, fw_cfg); }

[[[[Adv]]]]: static void sun4uv_init(ram_addr_t RAM_size, const char *boot_devices, const char *[[rodrick]], const char *kernel_cmdline, const char *[[britney]], const char *[[bat]], const struct hwdef *[[appetizers]]) { CPUState *env; char *filename; m48t59_t *nvram; int ret, linux_boot; unsigned int i; ram_addr_t ram_offset, prom_offset; long initrd_size, kernel_size; PCIBus *pci_bus, *pci_bus2, *pci_bus3; QEMUBH *[[stemmed]]; qemu_irq *irq; int drive_index; BlockDriverState *hd[MAX_IDE_BUS * MAX_IDE_DEVS]; BlockDriverState *fd[MAX_FD]; void *fw_cfg; ResetData *reset_info; linux_boot = ([[rodrick]] != NULL); if (![[bat]]) [[bat]] = [[appetizers]]->default_cpu_model; env = cpu_init([[bat]]); if (!env) { fprintf(stderr, "Unable to find Sparc CPU definition\n"); exit(1); } [[stemmed]] = qemu_bh_new(tick_irq, env); env->tick = ptimer_init([[stemmed]]); ptimer_set_period(env->tick, 1ULL); [[stemmed]] = qemu_bh_new(stick_irq, env); env->stick = ptimer_init([[stemmed]]); ptimer_set_period(env->stick, 1ULL); [[stemmed]] = qemu_bh_new(hstick_irq, env); env->hstick = ptimer_init([[stemmed]]); ptimer_set_period(env->hstick, 1ULL); reset_info = qemu_mallocz(sizeof(ResetData)); reset_info->env = env; reset_info->reset_addr = [[appetizers]]->prom_addr + 0x40ULL; qemu_register_reset(main_cpu_reset, reset_info); main_cpu_reset(reset_info); env->pc = [[appetizers]]->prom_addr + 0x20ULL; env->npc = env->pc + 4; ram_offset = qemu_ram_alloc(RAM_size); cpu_register_physical_memory(0, RAM_size, ram_offset); prom_offset = qemu_ram_alloc(PROM_SIZE_MAX); cpu_register_physical_memory([[appetizers]]->prom_addr, (PROM_SIZE_MAX + TARGET_PAGE_SIZE) & TARGET_PAGE_MASK, prom_offset | IO_MEM_ROM); if (bios_name == NULL) bios_name = PROM_FILENAME; filename = qemu_find_file(QEMU_FILE_TYPE_BIOS, bios_name); if (filename) { ret = load_elf(filename, [[appetizers]]->prom_addr - PROM_VADDR, NULL, NULL, NULL); if (ret < 0) { ret = load_image_targphys(filename, [[appetizers]]->prom_addr, (PROM_SIZE_MAX + TARGET_PAGE_SIZE) & TARGET_PAGE_MASK); } qemu_free(filename); } else { ret = -1; } if (ret < 0) { fprintf(stderr, "qemu: could not load prom '%s'\n", bios_name); exit(1); } kernel_size = 0; initrd_size = 0; if (linux_boot) { kernel_size = load_elf([[rodrick]], 0, NULL, NULL, NULL); if (kernel_size < 0) kernel_size = load_aout([[rodrick]], KERNEL_LOAD_ADDR, ram_size - KERNEL_LOAD_ADDR); if (kernel_size < 0) kernel_size = load_image_targphys([[rodrick]], KERNEL_LOAD_ADDR, ram_size - KERNEL_LOAD_ADDR); if (kernel_size < 0) { fprintf(stderr, "qemu: could not load kernel '%s'\n", [[rodrick]]); exit(1); } if ([[britney]]) { initrd_size = load_image_targphys([[britney]], INITRD_LOAD_ADDR, ram_size - INITRD_LOAD_ADDR); if (initrd_size < 0) { fprintf(stderr, "qemu: could not load initial ram disk '%s'\n", [[britney]]); exit(1); } } if (initrd_size > 0) { for (i = 0; i < 64 * TARGET_PAGE_SIZE; i += TARGET_PAGE_SIZE) { if (ldl_phys(KERNEL_LOAD_ADDR + i) == 0x48647253) { stl_phys(KERNEL_LOAD_ADDR + i + 16, INITRD_LOAD_ADDR); stl_phys(KERNEL_LOAD_ADDR + i + 20, initrd_size); break; } } } } pci_bus = pci_apb_init(APB_SPECIAL_BASE, APB_MEM_BASE, NULL, &pci_bus2, &pci_bus3); isa_mem_base = VGA_BASE; pci_vga_init(pci_bus, 0, 0); pci_ebus_init(pci_bus, -1); i = 0; if ([[appetizers]]->console_serial_base) { serial_mm_init([[appetizers]]->console_serial_base, 0, NULL, 115200, serial_hds[i], 1); i++; } for(; i < MAX_SERIAL_PORTS; i++) { if (serial_hds[i]) { serial_init(serial_io[i], NULL , 115200, serial_hds[i]); } } for(i = 0; i < MAX_PARALLEL_PORTS; i++) { if (parallel_hds[i]) { parallel_init(parallel_io[i], NULL , parallel_hds[i]); } } for(i = 0; i < nb_nics; i++) pci_nic_init(&nd_table[i], "ne2k_pci", NULL); irq = qemu_allocate_irqs(cpu_set_irq, env, MAX_PILS); if (drive_get_max_bus(IF_IDE) >= MAX_IDE_BUS) { fprintf(stderr, "qemu: too many IDE bus\n"); exit(1); } for(i = 0; i < MAX_IDE_BUS * MAX_IDE_DEVS; i++) { drive_index = drive_get_index(IF_IDE, i / MAX_IDE_DEVS, i % MAX_IDE_DEVS); if (drive_index != -1) hd[i] = drives_table[drive_index].bdrv; else hd[i] = NULL; } pci_cmd646_ide_init(pci_bus, hd, 1); i8042_init(NULL , NULL , 0x60); for(i = 0; i < MAX_FD; i++) { drive_index = drive_get_index(IF_FLOPPY, 0, i); if (drive_index != -1) fd[i] = drives_table[drive_index].bdrv; else fd[i] = NULL; } floppy_controller = fdctrl_init(NULL , 2, 0, 0x3f0, fd); nvram = m48t59_init(NULL , 0, 0x0074, NVRAM_SIZE, 59); sun4u_NVRAM_set_params(nvram, NVRAM_SIZE, "Sun4u", RAM_size, boot_devices, KERNEL_LOAD_ADDR, kernel_size, kernel_cmdline, INITRD_LOAD_ADDR, initrd_size, 0, graphic_width, graphic_height, graphic_depth, (uint8_t *)&nd_table[0].macaddr); fw_cfg = fw_cfg_init(BIOS_CFG_IOPORT, BIOS_CFG_IOPORT + 1, 0, 0); fw_cfg_add_i32(fw_cfg, FW_CFG_ID, 1); fw_cfg_add_i64(fw_cfg, FW_CFG_RAM_SIZE, (uint64_t)ram_size); fw_cfg_add_i16(fw_cfg, FW_CFG_MACHINE_ID, [[appetizers]]->machine_id); fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_ADDR, KERNEL_LOAD_ADDR); fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_SIZE, kernel_size); if (kernel_cmdline) { fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_CMDLINE, CMDLINE_ADDR); pstrcpy_targphys(CMDLINE_ADDR, TARGET_PAGE_SIZE, kernel_cmdline); } else { fw_cfg_add_i32(fw_cfg, FW_CFG_KERNEL_CMDLINE, 0); } fw_cfg_add_i32(fw_cfg, FW_CFG_INITRD_ADDR, INITRD_LOAD_ADDR); fw_cfg_add_i32(fw_cfg, FW_CFG_INITRD_SIZE, initrd_size); fw_cfg_add_i16(fw_cfg, FW_CFG_BOOT_DEVICE, boot_devices[0]); qemu_register_boot_set(fw_cfg_boot_set, fw_cfg); }[Succeeded / Failed / Skipped / Total] 10 / 15 / 18 / 43:   2%|         | 43/2690 [00:17<18:00,  2.45it/s][Succeeded / Failed / Skipped / Total] 11 / 15 / 18 / 44:   2%|         | 44/2690 [00:18<18:18,  2.41it/s][Succeeded / Failed / Skipped / Total] 11 / 15 / 18 / 44:   2%|         | 45/2690 [00:20<20:15,  2.18it/s][Succeeded / Failed / Skipped / Total] 12 / 15 / 18 / 45:   2%|         | 45/2690 [00:20<20:15,  2.18it/s]


--------------------------------------------- Result 44 ---------------------------------------------
[[0 (19%)]] --> [[0 (54%)]] --> Socre: 0.5392295122146606

[[[[Adv]]]]: static void fpu_init (CPUMIPSState *[[env]], const mips_def_t *[[def]]) { int [[i]]; for ([[i]] = 0; [[i]] < MIPS_FPU_MAX; [[i]]++) [[env]]->fpus[[[i]]].fcr0 = [[def]]->CP1_fcr0; memcpy(&[[env]]->active_fpu, &[[env]]->fpus[0], sizeof([[env]]->active_fpu)); if ([[env]]->user_mode_only) { if ([[env]]->CP0_Config1 & (1 << CP0C1_FP)) [[env]]->hflags |= MIPS_HFLAG_FPU; #ifdef TARGET_MIPS64 if ([[env]]->active_fpu.fcr0 & (1 << FCR0_F64)) [[env]]->hflags |= MIPS_HFLAG_F64; #endif } }

[[[[Adv]]]]: static void fpu_init (CPUMIPSState *[[cheltenham]], const mips_def_t *[[div]]) { int [[johnson]]; for ([[johnson]] = 0; [[johnson]] < MIPS_FPU_MAX; [[johnson]]++) [[cheltenham]]->fpus[[[johnson]]].fcr0 = [[div]]->CP1_fcr0; memcpy(&[[cheltenham]]->active_fpu, &[[cheltenham]]->fpus[0], sizeof([[cheltenham]]->active_fpu)); if ([[cheltenham]]->user_mode_only) { if ([[cheltenham]]->CP0_Config1 & (1 << CP0C1_FP)) [[cheltenham]]->hflags |= MIPS_HFLAG_FPU; #ifdef TARGET_MIPS64 if ([[cheltenham]]->active_fpu.fcr0 & (1 << FCR0_F64)) [[cheltenham]]->hflags |= MIPS_HFLAG_F64; #endif } }


--------------------------------------------- Result 45 ---------------------------------------------
[[0 (69%)]] --> [[0 (46%)]] --> Socre: 0.538634330034256

[[[[Adv]]]]: static int bfi_decode_frame(AVCodecContext *avctx, void *[[data]], int *data_size, AVPacket *avpkt) { const uint8_t *buf = avpkt->data, *buf_end = avpkt->data + avpkt->size; int buf_size = avpkt->size; BFIContext *[[bfi]] = avctx->priv_data; uint8_t *dst = [[bfi]]->dst; uint8_t *src, *dst_offset, colour1, colour2; uint8_t *frame_end = [[bfi]]->dst + avctx->width * avctx->height; uint32_t *pal; int [[i]], j, height = avctx->height; if ([[bfi]]->frame.data[0]) avctx->release_buffer(avctx, &[[bfi]]->frame); [[bfi]]->frame.reference = 1; if (avctx->get_buffer(avctx, &[[bfi]]->frame) < 0) { av_log(avctx, AV_LOG_ERROR, "get_buffer() failed\n"); return -1; } if (!avctx->frame_number) { [[bfi]]->frame.pict_type = AV_PICTURE_TYPE_I; [[bfi]]->frame.key_frame = 1; if (avctx->extradata_size > 768) { av_log(NULL, AV_LOG_ERROR, "Palette is too large.\n"); return -1; } pal = (uint32_t *)[[bfi]]->frame.data[1]; for ([[i]] = 0; [[i]] < avctx->extradata_size / 3; [[i]]++) { int [[shift]] = 16; *pal = 0; for (j = 0; j < 3; j++, [[shift]] -= 8) *pal += ((avctx->extradata[[[i]] * 3 + j] << 2) | (avctx->extradata[[[i]] * 3 + j] >> 4)) << [[shift]]; pal++; } [[bfi]]->frame.palette_has_changed = 1; } else { [[bfi]]->frame.pict_type = AV_PICTURE_TYPE_P; [[bfi]]->frame.key_frame = 0; } buf += 4; while (dst != frame_end) { static const uint8_t lentab[4] = { 0, 2, 0, 1 }; unsigned int byte = *buf++, av_uninit(offset); unsigned int code = byte >> 6; unsigned int length = byte & ~0xC0; if (buf >= buf_end) { av_log(avctx, AV_LOG_ERROR, "Input resolution larger than actual frame.\n"); return -1; } if (length == 0) { if (code == 1) { length = bytestream_get_byte(&buf); offset = bytestream_get_le16(&buf); } else { length = bytestream_get_le16(&buf); if (code == 2 && length == 0) break; } } else { if (code == 1) offset = bytestream_get_byte(&buf); } if (dst + (length << lentab[code]) > frame_end) break; switch (code) { case 0: if (length >= buf_end - buf) { av_log(avctx, AV_LOG_ERROR, "Frame larger than buffer.\n"); return -1; } bytestream_get_buffer(&buf, dst, length); dst += length; break; case 1: dst_offset = dst - offset; length *= 4; if (dst_offset < [[bfi]]->dst) break; while (length--) *dst++ = *dst_offset++; break; case 2: dst += length; break; case 3: colour1 = bytestream_get_byte(&buf); colour2 = bytestream_get_byte(&buf); while (length--) { *dst++ = colour1; *dst++ = colour2; } break; } } src = [[bfi]]->dst; dst = [[bfi]]->frame.data[0]; while (height--) { memcpy(dst, src, avctx->width); src += avctx->width; dst += [[bfi]]->frame.linesize[0]; } *data_size = sizeof(AVFrame); *(AVFrame *)[[data]] = [[bfi]]->frame; return buf_size; }

[[[[Adv]]]]: static int bfi_decode_frame(AVCodecContext *avctx, void *[[clarification]], int *data_size, AVPacket *avpkt) { const uint8_t *buf = avpkt->data, *buf_end = avpkt->data + avpkt->size; int buf_size = avpkt->size; BFIContext *[[tock]] = avctx->priv_data; uint8_t *dst = [[tock]]->dst; uint8_t *src, *dst_offset, colour1, colour2; uint8_t *frame_end = [[tock]]->dst + avctx->width * avctx->height; uint32_t *pal; int [[you]], j, height = avctx->height; if ([[tock]]->frame.data[0]) avctx->release_buffer(avctx, &[[tock]]->frame); [[tock]]->frame.reference = 1; if (avctx->get_buffer(avctx, &[[tock]]->frame) < 0) { av_log(avctx, AV_LOG_ERROR, "get_buffer() failed\n"); return -1; } if (!avctx->frame_number) { [[tock]]->frame.pict_type = AV_PICTURE_TYPE_I; [[tock]]->frame.key_frame = 1; if (avctx->extradata_size > 768) { av_log(NULL, AV_LOG_ERROR, "Palette is too large.\n"); return -1; } pal = (uint32_t *)[[tock]]->frame.data[1]; for ([[you]] = 0; [[you]] < avctx->extradata_size / 3; [[you]]++) { int [[transmutation]] = 16; *pal = 0; for (j = 0; j < 3; j++, [[transmutation]] -= 8) *pal += ((avctx->extradata[[[you]] * 3 + j] << 2) | (avctx->extradata[[[you]] * 3 + j] >> 4)) << [[transmutation]]; pal++; } [[tock]]->frame.palette_has_changed = 1; } else { [[tock]]->frame.pict_type = AV_PICTURE_TYPE_P; [[tock]]->frame.key_frame = 0; } buf += 4; while (dst != frame_end) { static const uint8_t lentab[4] = { 0, 2, 0, 1 }; unsigned int byte = *buf++, av_uninit(offset); unsigned int code = byte >> 6; unsigned int length = byte & ~0xC0; if (buf >= buf_end) { av_log(avctx, AV_LOG_ERROR, "Input resolution larger than actual frame.\n"); return -1; } if (length == 0) { if (code == 1) { length = bytestream_get_byte(&buf); offset = bytestream_get_le16(&buf); } else { length = bytestream_get_le16(&buf); if (code == 2 && length == 0) break; } } else { if (code == 1) offset = bytestream_get_byte(&buf); } if (dst + (length << lentab[code]) > frame_end) break; switch (code) { case 0: if (length >= buf_end - buf) { av_log(avctx, AV_LOG_ERROR, "Frame larger than buffer.\n"); return -1; } bytestream_get_buffer(&buf, dst, length); dst += length; break; case 1: dst_offset = dst - offset; length *= 4; if (dst_offset < [[tock]]->dst) break; while (length--) *dst++ = *dst_offset++; break; case 2: dst += length; break; case 3: colour1 = bytestream_get_byte(&buf); colour2 = bytestream_get_byte(&buf); while (length--) { *dst++ = colour1; *dst++ = colour2; } break; } } src = [[tock]]->dst; dst = [[tock]]->frame.data[0]; while (height--) { memcpy(dst, src, avctx->width); src += avctx->width; dst += [[tock]]->frame.linesize[0]; } *data_size = sizeof(AVFrame); *(AVFrame *)[[clarification]] = [[tock]]->frame; return buf_size; }


--------------------------------------------- Result 46 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 12 / 15 / 19 / 46:   2%|         | 46/2690 [00:20<19:49,  2.22it/s][Succeeded / Failed / Skipped / Total] 12 / 16 / 19 / 47:   2%|         | 47/2690 [00:21<19:48,  2.22it/s][Succeeded / Failed / Skipped / Total] 13 / 16 / 19 / 48:   2%|         | 48/2690 [00:21<19:39,  2.24it/s][Succeeded / Failed / Skipped / Total] 13 / 16 / 19 / 48:   2%|         | 49/2690 [00:22<20:24,  2.16it/s][Succeeded / Failed / Skipped / Total] 14 / 16 / 19 / 49:   2%|         | 49/2690 [00:22<20:24,  2.16it/s][[0 (46%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: DeviceState *qdev_device_add(QemuOpts *opts) { ObjectClass *oc; DeviceClass *dc; const char *driver, *path, *id; DeviceState *dev; BusState *bus = NULL; Error *err = NULL; driver = qemu_opt_get(opts, "driver"); if (!driver) { qerror_report(QERR_MISSING_PARAMETER, "driver"); return NULL; } oc = object_class_by_name(driver); if (!oc) { const char *typename = find_typename_by_alias(driver); if (typename) { driver = typename; oc = object_class_by_name(driver); } } if (!object_class_dynamic_cast(oc, TYPE_DEVICE)) { qerror_report(ERROR_CLASS_GENERIC_ERROR, "'%s' is not a valid device model name", driver); return NULL; } if (object_class_is_abstract(oc)) { qerror_report(QERR_INVALID_PARAMETER_VALUE, "driver", "non-abstract device type"); return NULL; } dc = DEVICE_CLASS(oc); if (dc->cannot_instantiate_with_device_add_yet) { qerror_report(QERR_INVALID_PARAMETER_VALUE, "driver", "pluggable device type"); return NULL; } path = qemu_opt_get(opts, "bus"); if (path != NULL) { bus = qbus_find(path); if (!bus) { return NULL; } if (!object_dynamic_cast(OBJECT(bus), dc->bus_type)) { qerror_report(QERR_BAD_BUS_FOR_DEVICE, driver, object_get_typename(OBJECT(bus))); return NULL; } } else if (dc->bus_type != NULL) { bus = qbus_find_recursive(sysbus_get_default(), NULL, dc->bus_type); if (!bus) { qerror_report(QERR_NO_BUS_FOR_DEVICE, dc->bus_type, driver); return NULL; } } if (qdev_hotplug && bus && !bus->allow_hotplug) { qerror_report(QERR_BUS_NO_HOTPLUG, bus->name); return NULL; } dev = DEVICE(object_new(driver)); if (bus) { qdev_set_parent_bus(dev, bus); } id = qemu_opts_id(opts); if (id) { dev->id = id; } if (qemu_opt_foreach(opts, set_property, dev, 1) != 0) { object_unparent(OBJECT(dev)); object_unref(OBJECT(dev)); return NULL; } if (dev->id) { object_property_add_child(qdev_get_peripheral(), dev->id, OBJECT(dev), NULL); } else { static int anon_count; gchar *name = g_strdup_printf("device[%d]", anon_count++); object_property_add_child(qdev_get_peripheral_anon(), name, OBJECT(dev), NULL); g_free(name); } dev->opts = opts; object_property_set_bool(OBJECT(dev), True, "realized", &err); if (err != NULL) { qerror_report_err(err); error_free(err); dev->opts = NULL; object_unparent(OBJECT(dev)); object_unref(OBJECT(dev)); qerror_report(QERR_DEVICE_INIT_FAILED, driver); return NULL; } return dev; }


--------------------------------------------- Result 47 ---------------------------------------------
[[0 (2%)]] --> [[[FAILED]]]

[[[[Adv]]]]: void thread_pool_submit(ThreadPoolFunc *[[func]], void *[[arg]]) { thread_pool_submit_aio([[func]], [[arg]], NULL, NULL); }

[[[[Adv]]]]: void thread_pool_submit(ThreadPoolFunc *[[chechens]], void *[[chedda]]) { thread_pool_submit_aio([[chechens]], [[chedda]], NULL, NULL); }


--------------------------------------------- Result 48 ---------------------------------------------
[[0 (58%)]] --> [[0 (43%)]] --> Socre: 0.566627025604248

[[[[Adv]]]]: int cpu_exec(CPUState *[[cpu]]) { CPUClass *cc = CPU_GET_CLASS([[cpu]]); int ret; SyncClocks sc; current_cpu = [[cpu]]; if (cpu_handle_halt([[cpu]])) { return EXCP_HALTED; } rcu_read_lock(); cc->cpu_exec_enter([[cpu]]); init_delay_params(&sc, [[cpu]]); if (sigsetjmp([[cpu]]->jmp_env, 0) != 0) { #if defined(__clang__) || !QEMU_GNUC_PREREQ(4, 6) [[cpu]] = current_cpu; cc = CPU_GET_CLASS([[cpu]]); #else g_assert([[cpu]] == current_cpu); g_assert(cc == CPU_GET_CLASS([[cpu]])); #endif [[cpu]]->can_do_io = 1; tb_lock_reset(); if (qemu_mutex_iothread_locked()) { qemu_mutex_unlock_iothread(); } } while (!cpu_handle_exception([[cpu]], &ret)) { TranslationBlock *last_tb = NULL; int tb_exit = 0; while (!cpu_handle_interrupt([[cpu]], &last_tb)) { TranslationBlock *tb = tb_find([[cpu]], last_tb, tb_exit); cpu_loop_exec_tb([[cpu]], tb, &last_tb, &tb_exit, &sc); align_clocks(&sc, [[cpu]]); } } cc->cpu_exec_exit([[cpu]]); rcu_read_unlock(); current_cpu = NULL; return ret; }

[[[[Adv]]]]: int cpu_exec(CPUState *[[arithmetic]]) { CPUClass *cc = CPU_GET_CLASS([[arithmetic]]); int ret; SyncClocks sc; current_cpu = [[arithmetic]]; if (cpu_handle_halt([[arithmetic]])) { return EXCP_HALTED; } rcu_read_lock(); cc->cpu_exec_enter([[arithmetic]]); init_delay_params(&sc, [[arithmetic]]); if (sigsetjmp([[arithmetic]]->jmp_env, 0) != 0) { #if defined(__clang__) || !QEMU_GNUC_PREREQ(4, 6) [[arithmetic]] = current_cpu; cc = CPU_GET_CLASS([[arithmetic]]); #else g_assert([[arithmetic]] == current_cpu); g_assert(cc == CPU_GET_CLASS([[arithmetic]])); #endif [[arithmetic]]->can_do_io = 1; tb_lock_reset(); if (qemu_mutex_iothread_locked()) { qemu_mutex_unlock_iothread(); } } while (!cpu_handle_exception([[arithmetic]], &ret)) { TranslationBlock *last_tb = NULL; int tb_exit = 0; while (!cpu_handle_interrupt([[arithmetic]], &last_tb)) { TranslationBlock *tb = tb_find([[arithmetic]], last_tb, tb_exit); cpu_loop_exec_tb([[arithmetic]], tb, &last_tb, &tb_exit, &sc); align_clocks(&sc, [[arithmetic]]); } } cc->cpu_exec_exit([[arithmetic]]); rcu_read_unlock(); current_cpu = NULL; return ret; }


--------------------------------------------- Result 49 ---------------------------------------------
[[0 (21%)]] --> [[0 (51%)]] --> Socre: 0.512165904045105

[[[[Adv]]]]: static void copy_irb_to_guest(IRB *[[dest]], const IRB *[[src]], PMCW *[[pmcw]]) { int [[i]]; uint16_t stctl = [[src]]->scsw.ctrl & SCSW_CTRL_MASK_STCTL; uint16_t [[actl]] = [[src]]->scsw.ctrl & SCSW_CTRL_MASK_ACTL; copy_scsw_to_guest(&[[dest]]->scsw, &[[src]]->scsw); for ([[i]] = 0; [[i]] < ARRAY_SIZE([[dest]]->esw); [[i]]++) { [[dest]]->esw[[[i]]] = cpu_to_be32([[src]]->esw[[[i]]]); } for ([[i]] = 0; [[i]] < ARRAY_SIZE([[dest]]->ecw); [[i]]++) { [[dest]]->ecw[[[i]]] = cpu_to_be32([[src]]->ecw[[[i]]]); } if (([[src]]->scsw.flags & SCSW_FLAGS_MASK_ESWF) || !([[pmcw]]->flags & PMCW_FLAGS_MASK_TF) || !([[pmcw]]->chars & PMCW_CHARS_MASK_XMWME)) { return; } if (!(stctl & SCSW_STCTL_STATUS_PEND)) { return; } if ((stctl & SCSW_STCTL_PRIMARY) || (stctl == SCSW_STCTL_SECONDARY) || ((stctl & SCSW_STCTL_INTERMEDIATE) && ([[actl]] & SCSW_ACTL_SUSP))) { for ([[i]] = 0; [[i]] < ARRAY_SIZE([[dest]]->emw); [[i]]++) { [[dest]]->emw[[[i]]] = cpu_to_be32([[src]]->emw[[[i]]]); } } }

[[[[Adv]]]]: static void copy_irb_to_guest(IRB *[[hussies]], const IRB *[[gallops]], PMCW *[[dominici]]) { int [[uh]]; uint16_t stctl = [[gallops]]->scsw.ctrl & SCSW_CTRL_MASK_STCTL; uint16_t [[clashed]] = [[gallops]]->scsw.ctrl & SCSW_CTRL_MASK_ACTL; copy_scsw_to_guest(&[[hussies]]->scsw, &[[gallops]]->scsw); for ([[uh]] = 0; [[uh]] < ARRAY_SIZE([[hussies]]->esw); [[uh]]++) { [[hussies]]->esw[[[uh]]] = cpu_to_be32([[gallops]]->esw[[[uh]]]); } for ([[uh]] = 0; [[uh]] < ARRAY_SIZE([[hussies]]->ecw); [[uh]]++) { [[hussies]]->ecw[[[uh]]] = cpu_to_be32([[gallops]]->ecw[[[uh]]]); } if (([[gallops]]->scsw.flags & SCSW_FLAGS_MASK_ESWF) || !([[dominici]]->flags & PMCW_FLAGS_MASK_TF) || !([[dominici]]->chars & PMCW_CHARS_MASK_XMWME)) { return; } if (!(stctl & SCSW_STCTL_STATUS_PEND)) { return; } if ((stctl & SCSW_STCTL_PRIMARY) || (stctl == SCSW_STCTL_SECONDARY) || ((stctl & SCSW_STCTL_INTERMEDIATE) && ([[clashed]] & SCSW_ACTL_SUSP))) { for ([[uh]] = 0; [[uh]] < ARRAY_SIZE([[hussies]]->emw); [[uh]]++) { [[hussies]]->emw[[[uh]]] = cpu_to_be32([[gallops]]->emw[[[uh]]]); } } }


--------------------------------------------- Result 50 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 14 / 17 / 19 / 50:   2%|         | 50/2690 [00:24<21:47,  2.02it/s][[0 (37%)]] --> [[[FAILED]]]

[[[[Adv]]]]: static int process_input_packet(InputStream *ist, const AVPacket *[[pkt]]) { int [[i]]; int [[got_output]]; AVPacket [[avpkt]]; if (ist->next_dts == AV_NOPTS_VALUE) ist->next_dts = ist->last_dts; if ([[pkt]] == NULL) { av_init_packet(&[[avpkt]]); [[avpkt]].data = NULL; [[avpkt]].size = 0; goto handle_eof; } else { [[avpkt]] = *[[pkt]]; } if ([[pkt]]->dts != AV_NOPTS_VALUE) ist->next_dts = ist->last_dts = av_rescale_q([[pkt]]->dts, ist->st->time_base, AV_TIME_BASE_Q); while (ist->decoding_needed && ([[avpkt]].size > 0 || (![[pkt]] && [[got_output]]))) { int [[ret]] = 0; handle_eof: ist->last_dts = ist->next_dts; if ([[avpkt]].size && [[avpkt]].size != [[pkt]]->size && !(ist->dec->capabilities & CODEC_CAP_SUBFRAMES)) { av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING, "Multiple frames in a packet from stream %d\n", [[pkt]]->stream_index); ist->showed_multi_packet_warning = 1; } switch (ist->dec_ctx->codec_type) { case AVMEDIA_TYPE_AUDIO: [[ret]] = decode_audio (ist, &[[avpkt]], &[[got_output]]); break; case AVMEDIA_TYPE_VIDEO: [[ret]] = decode_video (ist, &[[avpkt]], &[[got_output]]); if ([[avpkt]].duration) ist->next_dts += av_rescale_q([[avpkt]].duration, ist->st->time_base, AV_TIME_BASE_Q); else if (ist->st->avg_frame_rate.num) ist->next_dts += av_rescale_q(1, av_inv_q(ist->st->avg_frame_rate), AV_TIME_BASE_Q); else if (ist->dec_ctx->time_base.num != 0) { int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame; ist->next_dts += av_rescale_q(ticks, ist->dec_ctx->time_base, AV_TIME_BASE_Q); } break; case AVMEDIA_TYPE_SUBTITLE: [[ret]] = transcode_subtitles(ist, &[[avpkt]], &[[got_output]]); break; default: return -1; } if ([[ret]] < 0) return [[ret]]; if ([[pkt]]) { [[avpkt]].data += [[ret]]; [[avpkt]].size -= [[ret]]; } if (![[got_output]]) { continue; } } if (!ist->decoding_needed) { ist->last_dts = ist->next_dts; switch (ist->dec_ctx->codec_type) { case AVMEDIA_TYPE_AUDIO: ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->frame_size) / ist->dec_ctx->sample_rate; break; case AVMEDIA_TYPE_VIDEO: if (ist->dec_ctx->time_base.num != 0) { int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame; ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->time_base.num * ticks) / ist->dec_ctx->time_base.den; } break; } } for ([[i]] = 0; [[pkt]] && [[i]] < nb_output_streams; [[i]]++) { OutputStream *ost = output_streams[[[i]]]; if (!check_output_constraints(ist, ost) || ost->encoding_needed) continue; do_streamcopy(ist, ost, [[pkt]]); } return 0; }

[[[[Adv]]]]: static int process_input_packet(InputStream *ist, const AVPacket *[[aid]]) { int [[rhee]]; int [[object]]; AVPacket [[fixing]]; if (ist->next_dts == AV_NOPTS_VALUE) ist->next_dts = ist->last_dts; if ([[aid]] == NULL) { av_init_packet(&[[fixing]]); [[fixing]].data = NULL; [[fixing]].size = 0; goto handle_eof; } else { [[fixing]] = *[[aid]]; } if ([[aid]]->dts != AV_NOPTS_VALUE) ist->next_dts = ist->last_dts = av_rescale_q([[aid]]->dts, ist->st->time_base, AV_TIME_BASE_Q); while (ist->decoding_needed && ([[fixing]].size > 0 || (![[aid]] && [[object]]))) { int [[boomers]] = 0; handle_eof: ist->last_dts = ist->next_dts; if ([[fixing]].size && [[fixing]].size != [[aid]]->size && !(ist->dec->capabilities & CODEC_CAP_SUBFRAMES)) { av_log(NULL, ist->showed_multi_packet_warning ? AV_LOG_VERBOSE : AV_LOG_WARNING, "Multiple frames in a packet from stream %d\n", [[aid]]->stream_index); ist->showed_multi_packet_warning = 1; } switch (ist->dec_ctx->codec_type) { case AVMEDIA_TYPE_AUDIO: [[boomers]] = decode_audio (ist, &[[fixing]], &[[object]]); break; case AVMEDIA_TYPE_VIDEO: [[boomers]] = decode_video (ist, &[[fixing]], &[[object]]); if ([[fixing]].duration) ist->next_dts += av_rescale_q([[fixing]].duration, ist->st->time_base, AV_TIME_BASE_Q); else if (ist->st->avg_frame_rate.num) ist->next_dts += av_rescale_q(1, av_inv_q(ist->st->avg_frame_rate), AV_TIME_BASE_Q); else if (ist->dec_ctx->time_base.num != 0) { int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame; ist->next_dts += av_rescale_q(ticks, ist->dec_ctx->time_base, AV_TIME_BASE_Q); } break; case AVMEDIA_TYPE_SUBTITLE: [[boomers]] = transcode_subtitles(ist, &[[fixing]], &[[object]]); break; default: return -1; } if ([[boomers]] < 0) return [[boomers]]; if ([[aid]]) { [[fixing]].data += [[boomers]]; [[fixing]].size -= [[boomers]]; } if (![[object]]) { continue; } } if (!ist->decoding_needed) { ist->last_dts = ist->next_dts; switch (ist->dec_ctx->codec_type) { case AVMEDIA_TYPE_AUDIO: ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->frame_size) / ist->dec_ctx->sample_rate; break; case AVMEDIA_TYPE_VIDEO: if (ist->dec_ctx->time_base.num != 0) { int ticks = ist->st->parser ? ist->st->parser->repeat_pict + 1 : ist->dec_ctx->ticks_per_frame; ist->next_dts += ((int64_t)AV_TIME_BASE * ist->dec_ctx->time_base.num * ticks) / ist->dec_ctx->time_base.den; } break; } } for ([[rhee]] = 0; [[aid]] && [[rhee]] < nb_output_streams; [[rhee]]++) { OutputStream *ost = output_streams[[[rhee]]]; if (!check_output_constraints(ist, ost) || ost->encoding_needed) continue; do_streamcopy(ist, ost, [[aid]]); } return 0; }


--------------------------------------------- Result 51 ---------------------------------------------
[[0 (17%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static target_ulong disas_insn(DisasContext *s, CPUState *cpu) { CPUX86State *env = cpu->env_ptr; int b, prefixes; int shift; TCGMemOp ot, aflag, dflag; int modrm, reg, rm, mod, op, opreg, val; target_ulong next_eip, tval; int rex_w, rex_r; target_ulong pc_start = s->base.pc_next; s->pc_start = s->pc = pc_start; prefixes = 0; s->override = -1; rex_w = -1; rex_r = 0; #ifdef TARGET_X86_64 s->rex_x = 0; s->rex_b = 0; x86_64_hregs = 0; #endif s->rip_offset = 0; s->vex_l = 0; s->vex_v = 0; if (sigsetjmp(s->jmpbuf, 0) != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); return s->pc; } next_byte: b = x86_ldub_code(env, s); switch (b) { case 0xf3: prefixes |= PREFIX_REPZ; goto next_byte; case 0xf2: prefixes |= PREFIX_REPNZ; goto next_byte; case 0xf0: prefixes |= PREFIX_LOCK; goto next_byte; case 0x2e: s->override = R_CS; goto next_byte; case 0x36: s->override = R_SS; goto next_byte; case 0x3e: s->override = R_DS; goto next_byte; case 0x26: s->override = R_ES; goto next_byte; case 0x64: s->override = R_FS; goto next_byte; case 0x65: s->override = R_GS; goto next_byte; case 0x66: prefixes |= PREFIX_DATA; goto next_byte; case 0x67: prefixes |= PREFIX_ADR; goto next_byte; #ifdef TARGET_X86_64 case 0x40 ... 0x4f: if (CODE64(s)) { rex_w = (b >> 3) & 1; rex_r = (b & 0x4) << 1; s->rex_x = (b & 0x2) << 2; REX_B(s) = (b & 0x1) << 3; x86_64_hregs = 1; goto next_byte; } break; #endif case 0xc5: case 0xc4: if (s->code32 && !s->vm86) { static const int pp_prefix[4] = { 0, PREFIX_DATA, PREFIX_REPZ, PREFIX_REPNZ }; int vex3, vex2 = x86_ldub_code(env, s); if (!CODE64(s) && (vex2 & 0xc0) != 0xc0) { break; } s->pc++; if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ | PREFIX_LOCK | PREFIX_DATA)) { goto illegal_op; } #ifdef TARGET_X86_64 if (x86_64_hregs) { goto illegal_op; } #endif rex_r = (~vex2 >> 4) & 8; if (b == 0xc5) { vex3 = vex2; b = x86_ldub_code(env, s); } else { #ifdef TARGET_X86_64 s->rex_x = (~vex2 >> 3) & 8; s->rex_b = (~vex2 >> 2) & 8; #endif vex3 = x86_ldub_code(env, s); rex_w = (vex3 >> 7) & 1; switch (vex2 & 0x1f) { case 0x01: b = x86_ldub_code(env, s) | 0x100; break; case 0x02: b = 0x138; break; case 0x03: b = 0x13a; break; default: goto unknown_op; } } s->vex_v = (~vex3 >> 3) & 0xf; s->vex_l = (vex3 >> 2) & 1; prefixes |= pp_prefix[vex3 & 3] | PREFIX_VEX; } break; } if (CODE64(s)) { dflag = (rex_w > 0 ? MO_64 : prefixes & PREFIX_DATA ? MO_16 : MO_32); aflag = (prefixes & PREFIX_ADR ? MO_32 : MO_64); } else { if (s->code32 ^ ((prefixes & PREFIX_DATA) != 0)) { dflag = MO_32; } else { dflag = MO_16; } if (s->code32 ^ ((prefixes & PREFIX_ADR) != 0)) { aflag = MO_32; } else { aflag = MO_16; } } s->prefix = prefixes; s->aflag = aflag; s->dflag = dflag; reswitch: switch(b) { case 0x0f: b = x86_ldub_code(env, s) | 0x100; goto reswitch; case 0x00 ... 0x05: case 0x08 ... 0x0d: case 0x10 ... 0x15: case 0x18 ... 0x1d: case 0x20 ... 0x25: case 0x28 ... 0x2d: case 0x30 ... 0x35: case 0x38 ... 0x3d: { int op, f, val; op = (b >> 3) & 7; f = (b >> 1) & 3; ot = mo_b_d(b, dflag); switch(f) { case 0: modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); if (mod != 3) { gen_lea_modrm(env, s, modrm); opreg = OR_TMP0; } else if (op == OP_XORL && rm == reg) { xor_zero: set_cc_op(s, CC_OP_CLR); tcg_gen_movi_tl(cpu_T0, 0); gen_op_mov_reg_v(ot, reg, cpu_T0); break; } else { opreg = rm; } gen_op_mov_v_reg(ot, cpu_T1, reg); gen_op(s, op, ot, opreg); break; case 1: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; reg = ((modrm >> 3) & 7) | rex_r; rm = (modrm & 7) | REX_B(s); if (mod != 3) { gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, ot, cpu_T1, cpu_A0); } else if (op == OP_XORL && rm == reg) { goto xor_zero; } else { gen_op_mov_v_reg(ot, cpu_T1, rm); } gen_op(s, op, ot, reg); break; case 2: val = insn_get(env, s, ot); tcg_gen_movi_tl(cpu_T1, val); gen_op(s, op, ot, OR_EAX); break; } } break; case 0x82: if (CODE64(s)) goto illegal_op; case 0x80: case 0x81: case 0x83: { int val; ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); op = (modrm >> 3) & 7; if (mod != 3) { if (b == 0x83) s->rip_offset = 1; else s->rip_offset = insn_const_size(ot); gen_lea_modrm(env, s, modrm); opreg = OR_TMP0; } else { opreg = rm; } switch(b) { default: case 0x80: case 0x81: case 0x82: val = insn_get(env, s, ot); break; case 0x83: val = (int8_t)insn_get(env, s, MO_8); break; } tcg_gen_movi_tl(cpu_T1, val); gen_op(s, op, ot, opreg); } break; case 0x40 ... 0x47: ot = dflag; gen_inc(s, ot, OR_EAX + (b & 7), 1); break; case 0x48 ... 0x4f: ot = dflag; gen_inc(s, ot, OR_EAX + (b & 7), -1); break; case 0xf6: case 0xf7: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); op = (modrm >> 3) & 7; if (mod != 3) { if (op == 0) { s->rip_offset = insn_const_size(ot); } gen_lea_modrm(env, s, modrm); if (!(s->prefix & PREFIX_LOCK) || op != 2) { gen_op_ld_v(s, ot, cpu_T0, cpu_A0); } } else { gen_op_mov_v_reg(ot, cpu_T0, rm); } switch(op) { case 0: val = insn_get(env, s, ot); tcg_gen_movi_tl(cpu_T1, val); gen_op_testl_T0_T1_cc(); set_cc_op(s, CC_OP_LOGICB + ot); break; case 2: if (s->prefix & PREFIX_LOCK) { if (mod == 3) { goto illegal_op; } tcg_gen_movi_tl(cpu_T0, ~0); tcg_gen_atomic_xor_fetch_tl(cpu_T0, cpu_A0, cpu_T0, s->mem_index, ot | MO_LE); } else { tcg_gen_not_tl(cpu_T0, cpu_T0); if (mod != 3) { gen_op_st_v(s, ot, cpu_T0, cpu_A0); } else { gen_op_mov_reg_v(ot, rm, cpu_T0); } } break; case 3: if (s->prefix & PREFIX_LOCK) { TCGLabel *label1; TCGv a0, t0, t1, t2; if (mod == 3) { goto illegal_op; } a0 = tcg_temp_local_new(); t0 = tcg_temp_local_new(); label1 = gen_new_label(); tcg_gen_mov_tl(a0, cpu_A0); tcg_gen_mov_tl(t0, cpu_T0); gen_set_label(label1); t1 = tcg_temp_new(); t2 = tcg_temp_new(); tcg_gen_mov_tl(t2, t0); tcg_gen_neg_tl(t1, t0); tcg_gen_atomic_cmpxchg_tl(t0, a0, t0, t1, s->mem_index, ot | MO_LE); tcg_temp_free(t1); tcg_gen_brcond_tl(TCG_COND_NE, t0, t2, label1); tcg_temp_free(t2); tcg_temp_free(a0); tcg_gen_mov_tl(cpu_T0, t0); tcg_temp_free(t0); } else { tcg_gen_neg_tl(cpu_T0, cpu_T0); if (mod != 3) { gen_op_st_v(s, ot, cpu_T0, cpu_A0); } else { gen_op_mov_reg_v(ot, rm, cpu_T0); } } gen_op_update_neg_cc(); set_cc_op(s, CC_OP_SUBB + ot); break; case 4: switch(ot) { case MO_8: gen_op_mov_v_reg(MO_8, cpu_T1, R_EAX); tcg_gen_ext8u_tl(cpu_T0, cpu_T0); tcg_gen_ext8u_tl(cpu_T1, cpu_T1); tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); tcg_gen_andi_tl(cpu_cc_src, cpu_T0, 0xff00); set_cc_op(s, CC_OP_MULB); break; case MO_16: gen_op_mov_v_reg(MO_16, cpu_T1, R_EAX); tcg_gen_ext16u_tl(cpu_T0, cpu_T0); tcg_gen_ext16u_tl(cpu_T1, cpu_T1); tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); tcg_gen_shri_tl(cpu_T0, cpu_T0, 16); gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0); tcg_gen_mov_tl(cpu_cc_src, cpu_T0); set_cc_op(s, CC_OP_MULW); break; default: case MO_32: tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_regs[R_EAX]); tcg_gen_mulu2_i32(cpu_tmp2_i32, cpu_tmp3_i32, cpu_tmp2_i32, cpu_tmp3_i32); tcg_gen_extu_i32_tl(cpu_regs[R_EAX], cpu_tmp2_i32); tcg_gen_extu_i32_tl(cpu_regs[R_EDX], cpu_tmp3_i32); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]); tcg_gen_mov_tl(cpu_cc_src, cpu_regs[R_EDX]); set_cc_op(s, CC_OP_MULL); break; #ifdef TARGET_X86_64 case MO_64: tcg_gen_mulu2_i64(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_T0, cpu_regs[R_EAX]); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]); tcg_gen_mov_tl(cpu_cc_src, cpu_regs[R_EDX]); set_cc_op(s, CC_OP_MULQ); break; #endif } break; case 5: switch(ot) { case MO_8: gen_op_mov_v_reg(MO_8, cpu_T1, R_EAX); tcg_gen_ext8s_tl(cpu_T0, cpu_T0); tcg_gen_ext8s_tl(cpu_T1, cpu_T1); tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); tcg_gen_ext8s_tl(cpu_tmp0, cpu_T0); tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0); set_cc_op(s, CC_OP_MULB); break; case MO_16: gen_op_mov_v_reg(MO_16, cpu_T1, R_EAX); tcg_gen_ext16s_tl(cpu_T0, cpu_T0); tcg_gen_ext16s_tl(cpu_T1, cpu_T1); tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); tcg_gen_ext16s_tl(cpu_tmp0, cpu_T0); tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0); tcg_gen_shri_tl(cpu_T0, cpu_T0, 16); gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0); set_cc_op(s, CC_OP_MULW); break; default: case MO_32: tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_regs[R_EAX]); tcg_gen_muls2_i32(cpu_tmp2_i32, cpu_tmp3_i32, cpu_tmp2_i32, cpu_tmp3_i32); tcg_gen_extu_i32_tl(cpu_regs[R_EAX], cpu_tmp2_i32); tcg_gen_extu_i32_tl(cpu_regs[R_EDX], cpu_tmp3_i32); tcg_gen_sari_i32(cpu_tmp2_i32, cpu_tmp2_i32, 31); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]); tcg_gen_sub_i32(cpu_tmp2_i32, cpu_tmp2_i32, cpu_tmp3_i32); tcg_gen_extu_i32_tl(cpu_cc_src, cpu_tmp2_i32); set_cc_op(s, CC_OP_MULL); break; #ifdef TARGET_X86_64 case MO_64: tcg_gen_muls2_i64(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_T0, cpu_regs[R_EAX]); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[R_EAX]); tcg_gen_sari_tl(cpu_cc_src, cpu_regs[R_EAX], 63); tcg_gen_sub_tl(cpu_cc_src, cpu_cc_src, cpu_regs[R_EDX]); set_cc_op(s, CC_OP_MULQ); break; #endif } break; case 6: switch(ot) { case MO_8: gen_helper_divb_AL(cpu_env, cpu_T0); break; case MO_16: gen_helper_divw_AX(cpu_env, cpu_T0); break; default: case MO_32: gen_helper_divl_EAX(cpu_env, cpu_T0); break; #ifdef TARGET_X86_64 case MO_64: gen_helper_divq_EAX(cpu_env, cpu_T0); break; #endif } break; case 7: switch(ot) { case MO_8: gen_helper_idivb_AL(cpu_env, cpu_T0); break; case MO_16: gen_helper_idivw_AX(cpu_env, cpu_T0); break; default: case MO_32: gen_helper_idivl_EAX(cpu_env, cpu_T0); break; #ifdef TARGET_X86_64 case MO_64: gen_helper_idivq_EAX(cpu_env, cpu_T0); break; #endif } break; default: goto unknown_op; } break; case 0xfe: case 0xff: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); op = (modrm >> 3) & 7; if (op >= 2 && b == 0xfe) { goto unknown_op; } if (CODE64(s)) { if (op == 2 || op == 4) { ot = MO_64; } else if (op == 3 || op == 5) { ot = dflag != MO_16 ? MO_32 + (rex_w == 1) : MO_16; } else if (op == 6) { ot = mo_pushpop(s, dflag); } } if (mod != 3) { gen_lea_modrm(env, s, modrm); if (op >= 2 && op != 3 && op != 5) gen_op_ld_v(s, ot, cpu_T0, cpu_A0); } else { gen_op_mov_v_reg(ot, cpu_T0, rm); } switch(op) { case 0: if (mod != 3) opreg = OR_TMP0; else opreg = rm; gen_inc(s, ot, opreg, 1); break; case 1: if (mod != 3) opreg = OR_TMP0; else opreg = rm; gen_inc(s, ot, opreg, -1); break; case 2: if (dflag == MO_16) { tcg_gen_ext16u_tl(cpu_T0, cpu_T0); } next_eip = s->pc - s->cs_base; tcg_gen_movi_tl(cpu_T1, next_eip); gen_push_v(s, cpu_T1); gen_op_jmp_v(cpu_T0); gen_bnd_jmp(s); gen_jr(s, cpu_T0); break; case 3: gen_op_ld_v(s, ot, cpu_T1, cpu_A0); gen_add_A0_im(s, 1 << ot); gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0); do_lcall: if (s->pe && !s->vm86) { tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_lcall_protected(cpu_env, cpu_tmp2_i32, cpu_T1, tcg_const_i32(dflag - 1), tcg_const_tl(s->pc - s->cs_base)); } else { tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_lcall_real(cpu_env, cpu_tmp2_i32, cpu_T1, tcg_const_i32(dflag - 1), tcg_const_i32(s->pc - s->cs_base)); } tcg_gen_ld_tl(cpu_tmp4, cpu_env, offsetof(CPUX86State, eip)); gen_jr(s, cpu_tmp4); break; case 4: if (dflag == MO_16) { tcg_gen_ext16u_tl(cpu_T0, cpu_T0); } gen_op_jmp_v(cpu_T0); gen_bnd_jmp(s); gen_jr(s, cpu_T0); break; case 5: gen_op_ld_v(s, ot, cpu_T1, cpu_A0); gen_add_A0_im(s, 1 << ot); gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0); do_ljmp: if (s->pe && !s->vm86) { tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_ljmp_protected(cpu_env, cpu_tmp2_i32, cpu_T1, tcg_const_tl(s->pc - s->cs_base)); } else { gen_op_movl_seg_T0_vm(R_CS); gen_op_jmp_v(cpu_T1); } tcg_gen_ld_tl(cpu_tmp4, cpu_env, offsetof(CPUX86State, eip)); gen_jr(s, cpu_tmp4); break; case 6: gen_push_v(s, cpu_T0); break; default: goto unknown_op; } break; case 0x84: case 0x85: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0); gen_op_mov_v_reg(ot, cpu_T1, reg); gen_op_testl_T0_T1_cc(); set_cc_op(s, CC_OP_LOGICB + ot); break; case 0xa8: case 0xa9: ot = mo_b_d(b, dflag); val = insn_get(env, s, ot); gen_op_mov_v_reg(ot, cpu_T0, OR_EAX); tcg_gen_movi_tl(cpu_T1, val); gen_op_testl_T0_T1_cc(); set_cc_op(s, CC_OP_LOGICB + ot); break; case 0x98: switch (dflag) { #ifdef TARGET_X86_64 case MO_64: gen_op_mov_v_reg(MO_32, cpu_T0, R_EAX); tcg_gen_ext32s_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_64, R_EAX, cpu_T0); break; #endif case MO_32: gen_op_mov_v_reg(MO_16, cpu_T0, R_EAX); tcg_gen_ext16s_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_32, R_EAX, cpu_T0); break; case MO_16: gen_op_mov_v_reg(MO_8, cpu_T0, R_EAX); tcg_gen_ext8s_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); break; default: tcg_abort(); } break; case 0x99: switch (dflag) { #ifdef TARGET_X86_64 case MO_64: gen_op_mov_v_reg(MO_64, cpu_T0, R_EAX); tcg_gen_sari_tl(cpu_T0, cpu_T0, 63); gen_op_mov_reg_v(MO_64, R_EDX, cpu_T0); break; #endif case MO_32: gen_op_mov_v_reg(MO_32, cpu_T0, R_EAX); tcg_gen_ext32s_tl(cpu_T0, cpu_T0); tcg_gen_sari_tl(cpu_T0, cpu_T0, 31); gen_op_mov_reg_v(MO_32, R_EDX, cpu_T0); break; case MO_16: gen_op_mov_v_reg(MO_16, cpu_T0, R_EAX); tcg_gen_ext16s_tl(cpu_T0, cpu_T0); tcg_gen_sari_tl(cpu_T0, cpu_T0, 15); gen_op_mov_reg_v(MO_16, R_EDX, cpu_T0); break; default: tcg_abort(); } break; case 0x1af: case 0x69: case 0x6b: ot = dflag; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; if (b == 0x69) s->rip_offset = insn_const_size(ot); else if (b == 0x6b) s->rip_offset = 1; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0); if (b == 0x69) { val = insn_get(env, s, ot); tcg_gen_movi_tl(cpu_T1, val); } else if (b == 0x6b) { val = (int8_t)insn_get(env, s, MO_8); tcg_gen_movi_tl(cpu_T1, val); } else { gen_op_mov_v_reg(ot, cpu_T1, reg); } switch (ot) { #ifdef TARGET_X86_64 case MO_64: tcg_gen_muls2_i64(cpu_regs[reg], cpu_T1, cpu_T0, cpu_T1); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[reg]); tcg_gen_sari_tl(cpu_cc_src, cpu_cc_dst, 63); tcg_gen_sub_tl(cpu_cc_src, cpu_cc_src, cpu_T1); break; #endif case MO_32: tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1); tcg_gen_muls2_i32(cpu_tmp2_i32, cpu_tmp3_i32, cpu_tmp2_i32, cpu_tmp3_i32); tcg_gen_extu_i32_tl(cpu_regs[reg], cpu_tmp2_i32); tcg_gen_sari_i32(cpu_tmp2_i32, cpu_tmp2_i32, 31); tcg_gen_mov_tl(cpu_cc_dst, cpu_regs[reg]); tcg_gen_sub_i32(cpu_tmp2_i32, cpu_tmp2_i32, cpu_tmp3_i32); tcg_gen_extu_i32_tl(cpu_cc_src, cpu_tmp2_i32); break; default: tcg_gen_ext16s_tl(cpu_T0, cpu_T0); tcg_gen_ext16s_tl(cpu_T1, cpu_T1); tcg_gen_mul_tl(cpu_T0, cpu_T0, cpu_T1); tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); tcg_gen_ext16s_tl(cpu_tmp0, cpu_T0); tcg_gen_sub_tl(cpu_cc_src, cpu_T0, cpu_tmp0); gen_op_mov_reg_v(ot, reg, cpu_T0); break; } set_cc_op(s, CC_OP_MULB + ot); break; case 0x1c0: case 0x1c1: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; gen_op_mov_v_reg(ot, cpu_T0, reg); if (mod == 3) { rm = (modrm & 7) | REX_B(s); gen_op_mov_v_reg(ot, cpu_T1, rm); tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_mov_reg_v(ot, reg, cpu_T1); gen_op_mov_reg_v(ot, rm, cpu_T0); } else { gen_lea_modrm(env, s, modrm); if (s->prefix & PREFIX_LOCK) { tcg_gen_atomic_fetch_add_tl(cpu_T1, cpu_A0, cpu_T0, s->mem_index, ot | MO_LE); tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1); } else { gen_op_ld_v(s, ot, cpu_T1, cpu_A0); tcg_gen_add_tl(cpu_T0, cpu_T0, cpu_T1); gen_op_st_v(s, ot, cpu_T0, cpu_A0); } gen_op_mov_reg_v(ot, reg, cpu_T1); } gen_op_update2_cc(); set_cc_op(s, CC_OP_ADDB + ot); break; case 0x1b0: case 0x1b1: { TCGv oldv, newv, cmpv; ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; oldv = tcg_temp_new(); newv = tcg_temp_new(); cmpv = tcg_temp_new(); gen_op_mov_v_reg(ot, newv, reg); tcg_gen_mov_tl(cmpv, cpu_regs[R_EAX]); if (s->prefix & PREFIX_LOCK) { if (mod == 3) { goto illegal_op; } gen_lea_modrm(env, s, modrm); tcg_gen_atomic_cmpxchg_tl(oldv, cpu_A0, cmpv, newv, s->mem_index, ot | MO_LE); gen_op_mov_reg_v(ot, R_EAX, oldv); } else { if (mod == 3) { rm = (modrm & 7) | REX_B(s); gen_op_mov_v_reg(ot, oldv, rm); } else { gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, ot, oldv, cpu_A0); rm = 0; } gen_extu(ot, oldv); gen_extu(ot, cmpv); tcg_gen_movcond_tl(TCG_COND_EQ, newv, oldv, cmpv, newv, oldv); if (mod == 3) { gen_op_mov_reg_v(ot, R_EAX, oldv); gen_op_mov_reg_v(ot, rm, newv); } else { gen_op_st_v(s, ot, newv, cpu_A0); gen_op_mov_reg_v(ot, R_EAX, oldv); } } tcg_gen_mov_tl(cpu_cc_src, oldv); tcg_gen_mov_tl(cpu_cc_srcT, cmpv); tcg_gen_sub_tl(cpu_cc_dst, cmpv, oldv); set_cc_op(s, CC_OP_SUBB + ot); tcg_temp_free(oldv); tcg_temp_free(newv); tcg_temp_free(cmpv); } break; case 0x1c7: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; if ((mod == 3) || ((modrm & 0x38) != 0x8)) goto illegal_op; #ifdef TARGET_X86_64 if (dflag == MO_64) { if (!(s->cpuid_ext_features & CPUID_EXT_CX16)) goto illegal_op; gen_lea_modrm(env, s, modrm); if ((s->prefix & PREFIX_LOCK) && parallel_cpus) { gen_helper_cmpxchg16b(cpu_env, cpu_A0); } else { gen_helper_cmpxchg16b_unlocked(cpu_env, cpu_A0); } } else #endif { if (!(s->cpuid_features & CPUID_CX8)) goto illegal_op; gen_lea_modrm(env, s, modrm); if ((s->prefix & PREFIX_LOCK) && parallel_cpus) { gen_helper_cmpxchg8b(cpu_env, cpu_A0); } else { gen_helper_cmpxchg8b_unlocked(cpu_env, cpu_A0); } } set_cc_op(s, CC_OP_EFLAGS); break; case 0x50 ... 0x57: gen_op_mov_v_reg(MO_32, cpu_T0, (b & 7) | REX_B(s)); gen_push_v(s, cpu_T0); break; case 0x58 ... 0x5f: ot = gen_pop_T0(s); gen_pop_update(s, ot); gen_op_mov_reg_v(ot, (b & 7) | REX_B(s), cpu_T0); break; case 0x60: if (CODE64(s)) goto illegal_op; gen_pusha(s); break; case 0x61: if (CODE64(s)) goto illegal_op; gen_popa(s); break; case 0x68: case 0x6a: ot = mo_pushpop(s, dflag); if (b == 0x68) val = insn_get(env, s, ot); else val = (int8_t)insn_get(env, s, MO_8); tcg_gen_movi_tl(cpu_T0, val); gen_push_v(s, cpu_T0); break; case 0x8f: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; ot = gen_pop_T0(s); if (mod == 3) { gen_pop_update(s, ot); rm = (modrm & 7) | REX_B(s); gen_op_mov_reg_v(ot, rm, cpu_T0); } else { s->popl_esp_hack = 1 << ot; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1); s->popl_esp_hack = 0; gen_pop_update(s, ot); } break; case 0xc8: { int level; val = x86_lduw_code(env, s); level = x86_ldub_code(env, s); gen_enter(s, val, level); } break; case 0xc9: gen_leave(s); break; case 0x06: case 0x0e: case 0x16: case 0x1e: if (CODE64(s)) goto illegal_op; gen_op_movl_T0_seg(b >> 3); gen_push_v(s, cpu_T0); break; case 0x1a0: case 0x1a8: gen_op_movl_T0_seg((b >> 3) & 7); gen_push_v(s, cpu_T0); break; case 0x07: case 0x17: case 0x1f: if (CODE64(s)) goto illegal_op; reg = b >> 3; ot = gen_pop_T0(s); gen_movl_seg_T0(s, reg); gen_pop_update(s, ot); if (s->base.is_jmp) { gen_jmp_im(s->pc - s->cs_base); if (reg == R_SS) { s->tf = 0; gen_eob_inhibit_irq(s, True); } else { gen_eob(s); } } break; case 0x1a1: case 0x1a9: ot = gen_pop_T0(s); gen_movl_seg_T0(s, (b >> 3) & 7); gen_pop_update(s, ot); if (s->base.is_jmp) { gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } break; case 0x88: case 0x89: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, ot, reg, 1); break; case 0xc6: case 0xc7: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; if (mod != 3) { s->rip_offset = insn_const_size(ot); gen_lea_modrm(env, s, modrm); } val = insn_get(env, s, ot); tcg_gen_movi_tl(cpu_T0, val); if (mod != 3) { gen_op_st_v(s, ot, cpu_T0, cpu_A0); } else { gen_op_mov_reg_v(ot, (modrm & 7) | REX_B(s), cpu_T0); } break; case 0x8a: case 0x8b: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0); gen_op_mov_reg_v(ot, reg, cpu_T0); break; case 0x8e: modrm = x86_ldub_code(env, s); reg = (modrm >> 3) & 7; if (reg >= 6 || reg == R_CS) goto illegal_op; gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); gen_movl_seg_T0(s, reg); if (s->base.is_jmp) { gen_jmp_im(s->pc - s->cs_base); if (reg == R_SS) { s->tf = 0; gen_eob_inhibit_irq(s, True); } else { gen_eob(s); } } break; case 0x8c: modrm = x86_ldub_code(env, s); reg = (modrm >> 3) & 7; mod = (modrm >> 6) & 3; if (reg >= 6) goto illegal_op; gen_op_movl_T0_seg(reg); ot = mod == 3 ? dflag : MO_16; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1); break; case 0x1b6: case 0x1b7: case 0x1be: case 0x1bf: { TCGMemOp d_ot; TCGMemOp s_ot; d_ot = dflag; ot = (b & 1) + MO_8; s_ot = b & 8 ? MO_SIGN | ot : ot; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); if (mod == 3) { if (s_ot == MO_SB && byte_reg_is_xH(rm)) { tcg_gen_sextract_tl(cpu_T0, cpu_regs[rm - 4], 8, 8); } else { gen_op_mov_v_reg(ot, cpu_T0, rm); switch (s_ot) { case MO_UB: tcg_gen_ext8u_tl(cpu_T0, cpu_T0); break; case MO_SB: tcg_gen_ext8s_tl(cpu_T0, cpu_T0); break; case MO_UW: tcg_gen_ext16u_tl(cpu_T0, cpu_T0); break; default: case MO_SW: tcg_gen_ext16s_tl(cpu_T0, cpu_T0); break; } } gen_op_mov_reg_v(d_ot, reg, cpu_T0); } else { gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, s_ot, cpu_T0, cpu_A0); gen_op_mov_reg_v(d_ot, reg, cpu_T0); } } break; case 0x8d: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; if (mod == 3) goto illegal_op; reg = ((modrm >> 3) & 7) | rex_r; { AddressParts a = gen_lea_modrm_0(env, s, modrm); TCGv ea = gen_lea_modrm_1(a); gen_lea_v_seg(s, s->aflag, ea, -1, -1); gen_op_mov_reg_v(dflag, reg, cpu_A0); } break; case 0xa0: case 0xa1: case 0xa2: case 0xa3: { target_ulong offset_addr; ot = mo_b_d(b, dflag); switch (s->aflag) { #ifdef TARGET_X86_64 case MO_64: offset_addr = x86_ldq_code(env, s); break; #endif default: offset_addr = insn_get(env, s, s->aflag); break; } tcg_gen_movi_tl(cpu_A0, offset_addr); gen_add_A0_ds_seg(s); if ((b & 2) == 0) { gen_op_ld_v(s, ot, cpu_T0, cpu_A0); gen_op_mov_reg_v(ot, R_EAX, cpu_T0); } else { gen_op_mov_v_reg(ot, cpu_T0, R_EAX); gen_op_st_v(s, ot, cpu_T0, cpu_A0); } } break; case 0xd7: tcg_gen_mov_tl(cpu_A0, cpu_regs[R_EBX]); tcg_gen_ext8u_tl(cpu_T0, cpu_regs[R_EAX]); tcg_gen_add_tl(cpu_A0, cpu_A0, cpu_T0); gen_extu(s->aflag, cpu_A0); gen_add_A0_ds_seg(s); gen_op_ld_v(s, MO_8, cpu_T0, cpu_A0); gen_op_mov_reg_v(MO_8, R_EAX, cpu_T0); break; case 0xb0 ... 0xb7: val = insn_get(env, s, MO_8); tcg_gen_movi_tl(cpu_T0, val); gen_op_mov_reg_v(MO_8, (b & 7) | REX_B(s), cpu_T0); break; case 0xb8 ... 0xbf: #ifdef TARGET_X86_64 if (dflag == MO_64) { uint64_t tmp; tmp = x86_ldq_code(env, s); reg = (b & 7) | REX_B(s); tcg_gen_movi_tl(cpu_T0, tmp); gen_op_mov_reg_v(MO_64, reg, cpu_T0); } else #endif { ot = dflag; val = insn_get(env, s, ot); reg = (b & 7) | REX_B(s); tcg_gen_movi_tl(cpu_T0, val); gen_op_mov_reg_v(ot, reg, cpu_T0); } break; case 0x91 ... 0x97: do_xchg_reg_eax: ot = dflag; reg = (b & 7) | REX_B(s); rm = R_EAX; goto do_xchg_reg; case 0x86: case 0x87: ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; if (mod == 3) { rm = (modrm & 7) | REX_B(s); do_xchg_reg: gen_op_mov_v_reg(ot, cpu_T0, reg); gen_op_mov_v_reg(ot, cpu_T1, rm); gen_op_mov_reg_v(ot, rm, cpu_T0); gen_op_mov_reg_v(ot, reg, cpu_T1); } else { gen_lea_modrm(env, s, modrm); gen_op_mov_v_reg(ot, cpu_T0, reg); tcg_gen_atomic_xchg_tl(cpu_T1, cpu_A0, cpu_T0, s->mem_index, ot | MO_LE); gen_op_mov_reg_v(ot, reg, cpu_T1); } break; case 0xc4: op = R_ES; goto do_lxx; case 0xc5: op = R_DS; goto do_lxx; case 0x1b2: op = R_SS; goto do_lxx; case 0x1b4: op = R_FS; goto do_lxx; case 0x1b5: op = R_GS; do_lxx: ot = dflag != MO_16 ? MO_32 : MO_16; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; if (mod == 3) goto illegal_op; gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, ot, cpu_T1, cpu_A0); gen_add_A0_im(s, 1 << ot); gen_op_ld_v(s, MO_16, cpu_T0, cpu_A0); gen_movl_seg_T0(s, op); gen_op_mov_reg_v(ot, reg, cpu_T1); if (s->base.is_jmp) { gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } break; case 0xc0: case 0xc1: shift = 2; grp2: { ot = mo_b_d(b, dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; op = (modrm >> 3) & 7; if (mod != 3) { if (shift == 2) { s->rip_offset = 1; } gen_lea_modrm(env, s, modrm); opreg = OR_TMP0; } else { opreg = (modrm & 7) | REX_B(s); } if (shift == 0) { gen_shift(s, op, ot, opreg, OR_ECX); } else { if (shift == 2) { shift = x86_ldub_code(env, s); } gen_shifti(s, op, ot, opreg, shift); } } break; case 0xd0: case 0xd1: shift = 1; goto grp2; case 0xd2: case 0xd3: shift = 0; goto grp2; case 0x1a4: op = 0; shift = 1; goto do_shiftd; case 0x1a5: op = 0; shift = 0; goto do_shiftd; case 0x1ac: op = 1; shift = 1; goto do_shiftd; case 0x1ad: op = 1; shift = 0; do_shiftd: ot = dflag; modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); reg = ((modrm >> 3) & 7) | rex_r; if (mod != 3) { gen_lea_modrm(env, s, modrm); opreg = OR_TMP0; } else { opreg = rm; } gen_op_mov_v_reg(ot, cpu_T1, reg); if (shift) { TCGv imm = tcg_const_tl(x86_ldub_code(env, s)); gen_shiftd_rm_T1(s, ot, opreg, op, imm); tcg_temp_free(imm); } else { gen_shiftd_rm_T1(s, ot, opreg, op, cpu_regs[R_ECX]); } break; case 0xd8 ... 0xdf: if (s->flags & (HF_EM_MASK | HF_TS_MASK)) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); break; } modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; rm = modrm & 7; op = ((b & 7) << 3) | ((modrm >> 3) & 7); if (mod != 3) { gen_lea_modrm(env, s, modrm); switch(op) { case 0x00 ... 0x07: case 0x10 ... 0x17: case 0x20 ... 0x27: case 0x30 ... 0x37: { int op1; op1 = op & 7; switch(op >> 4) { case 0: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); gen_helper_flds_FT0(cpu_env, cpu_tmp2_i32); break; case 1: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); gen_helper_fildl_FT0(cpu_env, cpu_tmp2_i32); break; case 2: tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); gen_helper_fldl_FT0(cpu_env, cpu_tmp1_i64); break; case 3: default: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LESW); gen_helper_fildl_FT0(cpu_env, cpu_tmp2_i32); break; } gen_helper_fp_arith_ST0_FT0(op1); if (op1 == 3) { gen_helper_fpop(cpu_env); } } break; case 0x08: case 0x0a: case 0x0b: case 0x18 ... 0x1b: case 0x28 ... 0x2b: case 0x38 ... 0x3b: switch(op & 7) { case 0: switch(op >> 4) { case 0: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); gen_helper_flds_ST0(cpu_env, cpu_tmp2_i32); break; case 1: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); gen_helper_fildl_ST0(cpu_env, cpu_tmp2_i32); break; case 2: tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); gen_helper_fldl_ST0(cpu_env, cpu_tmp1_i64); break; case 3: default: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LESW); gen_helper_fildl_ST0(cpu_env, cpu_tmp2_i32); break; } break; case 1: switch(op >> 4) { case 1: gen_helper_fisttl_ST0(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); break; case 2: gen_helper_fisttll_ST0(cpu_tmp1_i64, cpu_env); tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); break; case 3: default: gen_helper_fistt_ST0(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUW); break; } gen_helper_fpop(cpu_env); break; default: switch(op >> 4) { case 0: gen_helper_fsts_ST0(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); break; case 1: gen_helper_fistl_ST0(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); break; case 2: gen_helper_fstl_ST0(cpu_tmp1_i64, cpu_env); tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); break; case 3: default: gen_helper_fist_ST0(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUW); break; } if ((op & 7) == 3) gen_helper_fpop(cpu_env); break; } break; case 0x0c: gen_helper_fldenv(cpu_env, cpu_A0, tcg_const_i32(dflag - 1)); break; case 0x0d: tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUW); gen_helper_fldcw(cpu_env, cpu_tmp2_i32); break; case 0x0e: gen_helper_fstenv(cpu_env, cpu_A0, tcg_const_i32(dflag - 1)); break; case 0x0f: gen_helper_fnstcw(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUW); break; case 0x1d: gen_helper_fldt_ST0(cpu_env, cpu_A0); break; case 0x1f: gen_helper_fstt_ST0(cpu_env, cpu_A0); gen_helper_fpop(cpu_env); break; case 0x2c: gen_helper_frstor(cpu_env, cpu_A0, tcg_const_i32(dflag - 1)); break; case 0x2e: gen_helper_fsave(cpu_env, cpu_A0, tcg_const_i32(dflag - 1)); break; case 0x2f: gen_helper_fnstsw(cpu_tmp2_i32, cpu_env); tcg_gen_qemu_st_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUW); break; case 0x3c: gen_helper_fbld_ST0(cpu_env, cpu_A0); break; case 0x3e: gen_helper_fbst_ST0(cpu_env, cpu_A0); gen_helper_fpop(cpu_env); break; case 0x3d: tcg_gen_qemu_ld_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); gen_helper_fildll_ST0(cpu_env, cpu_tmp1_i64); break; case 0x3f: gen_helper_fistll_ST0(cpu_tmp1_i64, cpu_env); tcg_gen_qemu_st_i64(cpu_tmp1_i64, cpu_A0, s->mem_index, MO_LEQ); gen_helper_fpop(cpu_env); break; default: goto unknown_op; } } else { opreg = rm; switch(op) { case 0x08: gen_helper_fpush(cpu_env); gen_helper_fmov_ST0_STN(cpu_env, tcg_const_i32((opreg + 1) & 7)); break; case 0x09: case 0x29: case 0x39: gen_helper_fxchg_ST0_STN(cpu_env, tcg_const_i32(opreg)); break; case 0x0a: switch(rm) { case 0: gen_helper_fwait(cpu_env); break; default: goto unknown_op; } break; case 0x0c: switch(rm) { case 0: gen_helper_fchs_ST0(cpu_env); break; case 1: gen_helper_fabs_ST0(cpu_env); break; case 4: gen_helper_fldz_FT0(cpu_env); gen_helper_fcom_ST0_FT0(cpu_env); break; case 5: gen_helper_fxam_ST0(cpu_env); break; default: goto unknown_op; } break; case 0x0d: { switch(rm) { case 0: gen_helper_fpush(cpu_env); gen_helper_fld1_ST0(cpu_env); break; case 1: gen_helper_fpush(cpu_env); gen_helper_fldl2t_ST0(cpu_env); break; case 2: gen_helper_fpush(cpu_env); gen_helper_fldl2e_ST0(cpu_env); break; case 3: gen_helper_fpush(cpu_env); gen_helper_fldpi_ST0(cpu_env); break; case 4: gen_helper_fpush(cpu_env); gen_helper_fldlg2_ST0(cpu_env); break; case 5: gen_helper_fpush(cpu_env); gen_helper_fldln2_ST0(cpu_env); break; case 6: gen_helper_fpush(cpu_env); gen_helper_fldz_ST0(cpu_env); break; default: goto unknown_op; } } break; case 0x0e: switch(rm) { case 0: gen_helper_f2xm1(cpu_env); break; case 1: gen_helper_fyl2x(cpu_env); break; case 2: gen_helper_fptan(cpu_env); break; case 3: gen_helper_fpatan(cpu_env); break; case 4: gen_helper_fxtract(cpu_env); break; case 5: gen_helper_fprem1(cpu_env); break; case 6: gen_helper_fdecstp(cpu_env); break; default: case 7: gen_helper_fincstp(cpu_env); break; } break; case 0x0f: switch(rm) { case 0: gen_helper_fprem(cpu_env); break; case 1: gen_helper_fyl2xp1(cpu_env); break; case 2: gen_helper_fsqrt(cpu_env); break; case 3: gen_helper_fsincos(cpu_env); break; case 5: gen_helper_fscale(cpu_env); break; case 4: gen_helper_frndint(cpu_env); break; case 6: gen_helper_fsin(cpu_env); break; default: case 7: gen_helper_fcos(cpu_env); break; } break; case 0x00: case 0x01: case 0x04 ... 0x07: case 0x20: case 0x21: case 0x24 ... 0x27: case 0x30: case 0x31: case 0x34 ... 0x37: { int op1; op1 = op & 7; if (op >= 0x20) { gen_helper_fp_arith_STN_ST0(op1, opreg); if (op >= 0x30) gen_helper_fpop(cpu_env); } else { gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fp_arith_ST0_FT0(op1); } } break; case 0x02: case 0x22: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fcom_ST0_FT0(cpu_env); break; case 0x03: case 0x23: case 0x32: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fcom_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); break; case 0x15: switch(rm) { case 1: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(1)); gen_helper_fucom_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); gen_helper_fpop(cpu_env); break; default: goto unknown_op; } break; case 0x1c: switch(rm) { case 0: break; case 1: break; case 2: gen_helper_fclex(cpu_env); break; case 3: gen_helper_fninit(cpu_env); break; case 4: break; default: goto unknown_op; } break; case 0x1d: if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } gen_update_cc_op(s); gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fucomi_ST0_FT0(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x1e: if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } gen_update_cc_op(s); gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fcomi_ST0_FT0(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x28: gen_helper_ffree_STN(cpu_env, tcg_const_i32(opreg)); break; case 0x2a: gen_helper_fmov_STN_ST0(cpu_env, tcg_const_i32(opreg)); break; case 0x2b: case 0x0b: case 0x3a: case 0x3b: gen_helper_fmov_STN_ST0(cpu_env, tcg_const_i32(opreg)); gen_helper_fpop(cpu_env); break; case 0x2c: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fucom_ST0_FT0(cpu_env); break; case 0x2d: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fucom_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); break; case 0x33: switch(rm) { case 1: gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(1)); gen_helper_fcom_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); gen_helper_fpop(cpu_env); break; default: goto unknown_op; } break; case 0x38: gen_helper_ffree_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fpop(cpu_env); break; case 0x3c: switch(rm) { case 0: gen_helper_fnstsw(cpu_tmp2_i32, cpu_env); tcg_gen_extu_i32_tl(cpu_T0, cpu_tmp2_i32); gen_op_mov_reg_v(MO_16, R_EAX, cpu_T0); break; default: goto unknown_op; } break; case 0x3d: if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } gen_update_cc_op(s); gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fucomi_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x3e: if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } gen_update_cc_op(s); gen_helper_fmov_FT0_STN(cpu_env, tcg_const_i32(opreg)); gen_helper_fcomi_ST0_FT0(cpu_env); gen_helper_fpop(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x10 ... 0x13: case 0x18 ... 0x1b: { int op1; TCGLabel *l1; static const uint8_t fcmov_cc[8] = { (JCC_B << 1), (JCC_Z << 1), (JCC_BE << 1), (JCC_P << 1), }; if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } op1 = fcmov_cc[op & 3] | (((op >> 3) & 1) ^ 1); l1 = gen_new_label(); gen_jcc1_noeob(s, op1, l1); gen_helper_fmov_ST0_STN(cpu_env, tcg_const_i32(opreg)); gen_set_label(l1); } break; default: goto unknown_op; } } break; case 0xa4: case 0xa5: ot = mo_b_d(b, dflag); if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) { gen_repz_movs(s, ot, pc_start - s->cs_base, s->pc - s->cs_base); } else { gen_movs(s, ot); } break; case 0xaa: case 0xab: ot = mo_b_d(b, dflag); if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) { gen_repz_stos(s, ot, pc_start - s->cs_base, s->pc - s->cs_base); } else { gen_stos(s, ot); } break; case 0xac: case 0xad: ot = mo_b_d(b, dflag); if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) { gen_repz_lods(s, ot, pc_start - s->cs_base, s->pc - s->cs_base); } else { gen_lods(s, ot); } break; case 0xae: case 0xaf: ot = mo_b_d(b, dflag); if (prefixes & PREFIX_REPNZ) { gen_repz_scas(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 1); } else if (prefixes & PREFIX_REPZ) { gen_repz_scas(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 0); } else { gen_scas(s, ot); } break; case 0xa6: case 0xa7: ot = mo_b_d(b, dflag); if (prefixes & PREFIX_REPNZ) { gen_repz_cmps(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 1); } else if (prefixes & PREFIX_REPZ) { gen_repz_cmps(s, ot, pc_start - s->cs_base, s->pc - s->cs_base, 0); } else { gen_cmps(s, ot); } break; case 0x6c: case 0x6d: ot = mo_b_d32(b, dflag); tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]); gen_check_io(s, ot, pc_start - s->cs_base, SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes) | 4); if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) { gen_repz_ins(s, ot, pc_start - s->cs_base, s->pc - s->cs_base); } else { gen_ins(s, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_jmp(s, s->pc - s->cs_base); } } break; case 0x6e: case 0x6f: ot = mo_b_d32(b, dflag); tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]); gen_check_io(s, ot, pc_start - s->cs_base, svm_is_rep(prefixes) | 4); if (prefixes & (PREFIX_REPZ | PREFIX_REPNZ)) { gen_repz_outs(s, ot, pc_start - s->cs_base, s->pc - s->cs_base); } else { gen_outs(s, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_jmp(s, s->pc - s->cs_base); } } break; case 0xe4: case 0xe5: ot = mo_b_d32(b, dflag); val = x86_ldub_code(env, s); tcg_gen_movi_tl(cpu_T0, val); gen_check_io(s, ot, pc_start - s->cs_base, SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes)); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } tcg_gen_movi_i32(cpu_tmp2_i32, val); gen_helper_in_func(ot, cpu_T1, cpu_tmp2_i32); gen_op_mov_reg_v(ot, R_EAX, cpu_T1); gen_bpt_io(s, cpu_tmp2_i32, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; case 0xe6: case 0xe7: ot = mo_b_d32(b, dflag); val = x86_ldub_code(env, s); tcg_gen_movi_tl(cpu_T0, val); gen_check_io(s, ot, pc_start - s->cs_base, svm_is_rep(prefixes)); gen_op_mov_v_reg(ot, cpu_T1, R_EAX); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } tcg_gen_movi_i32(cpu_tmp2_i32, val); tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1); gen_helper_out_func(ot, cpu_tmp2_i32, cpu_tmp3_i32); gen_bpt_io(s, cpu_tmp2_i32, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; case 0xec: case 0xed: ot = mo_b_d32(b, dflag); tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]); gen_check_io(s, ot, pc_start - s->cs_base, SVM_IOIO_TYPE_MASK | svm_is_rep(prefixes)); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_in_func(ot, cpu_T1, cpu_tmp2_i32); gen_op_mov_reg_v(ot, R_EAX, cpu_T1); gen_bpt_io(s, cpu_tmp2_i32, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; case 0xee: case 0xef: ot = mo_b_d32(b, dflag); tcg_gen_ext16u_tl(cpu_T0, cpu_regs[R_EDX]); gen_check_io(s, ot, pc_start - s->cs_base, svm_is_rep(prefixes)); gen_op_mov_v_reg(ot, cpu_T1, R_EAX); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); tcg_gen_trunc_tl_i32(cpu_tmp3_i32, cpu_T1); gen_helper_out_func(ot, cpu_tmp2_i32, cpu_tmp3_i32); gen_bpt_io(s, cpu_tmp2_i32, ot); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; case 0xc2: val = x86_ldsw_code(env, s); ot = gen_pop_T0(s); gen_stack_update(s, val + (1 << ot)); gen_op_jmp_v(cpu_T0); gen_bnd_jmp(s); gen_jr(s, cpu_T0); break; case 0xc3: ot = gen_pop_T0(s); gen_pop_update(s, ot); gen_op_jmp_v(cpu_T0); gen_bnd_jmp(s); gen_jr(s, cpu_T0); break; case 0xca: val = x86_ldsw_code(env, s); do_lret: if (s->pe && !s->vm86) { gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_lret_protected(cpu_env, tcg_const_i32(dflag - 1), tcg_const_i32(val)); } else { gen_stack_A0(s); gen_op_ld_v(s, dflag, cpu_T0, cpu_A0); gen_op_jmp_v(cpu_T0); gen_add_A0_im(s, 1 << dflag); gen_op_ld_v(s, dflag, cpu_T0, cpu_A0); gen_op_movl_seg_T0_vm(R_CS); gen_stack_update(s, val + (2 << dflag)); } gen_eob(s); break; case 0xcb: val = 0; goto do_lret; case 0xcf: gen_svm_check_intercept(s, pc_start, SVM_EXIT_IRET); if (!s->pe) { gen_helper_iret_real(cpu_env, tcg_const_i32(dflag - 1)); set_cc_op(s, CC_OP_EFLAGS); } else if (s->vm86) { if (s->iopl != 3) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_helper_iret_real(cpu_env, tcg_const_i32(dflag - 1)); set_cc_op(s, CC_OP_EFLAGS); } } else { gen_helper_iret_protected(cpu_env, tcg_const_i32(dflag - 1), tcg_const_i32(s->pc - s->cs_base)); set_cc_op(s, CC_OP_EFLAGS); } gen_eob(s); break; case 0xe8: { if (dflag != MO_16) { tval = (int32_t)insn_get(env, s, MO_32); } else { tval = (int16_t)insn_get(env, s, MO_16); } next_eip = s->pc - s->cs_base; tval += next_eip; if (dflag == MO_16) { tval &= 0xffff; } else if (!CODE64(s)) { tval &= 0xffffffff; } tcg_gen_movi_tl(cpu_T0, next_eip); gen_push_v(s, cpu_T0); gen_bnd_jmp(s); gen_jmp(s, tval); } break; case 0x9a: { unsigned int selector, offset; if (CODE64(s)) goto illegal_op; ot = dflag; offset = insn_get(env, s, ot); selector = insn_get(env, s, MO_16); tcg_gen_movi_tl(cpu_T0, selector); tcg_gen_movi_tl(cpu_T1, offset); } goto do_lcall; case 0xe9: if (dflag != MO_16) { tval = (int32_t)insn_get(env, s, MO_32); } else { tval = (int16_t)insn_get(env, s, MO_16); } tval += s->pc - s->cs_base; if (dflag == MO_16) { tval &= 0xffff; } else if (!CODE64(s)) { tval &= 0xffffffff; } gen_bnd_jmp(s); gen_jmp(s, tval); break; case 0xea: { unsigned int selector, offset; if (CODE64(s)) goto illegal_op; ot = dflag; offset = insn_get(env, s, ot); selector = insn_get(env, s, MO_16); tcg_gen_movi_tl(cpu_T0, selector); tcg_gen_movi_tl(cpu_T1, offset); } goto do_ljmp; case 0xeb: tval = (int8_t)insn_get(env, s, MO_8); tval += s->pc - s->cs_base; if (dflag == MO_16) { tval &= 0xffff; } gen_jmp(s, tval); break; case 0x70 ... 0x7f: tval = (int8_t)insn_get(env, s, MO_8); goto do_jcc; case 0x180 ... 0x18f: if (dflag != MO_16) { tval = (int32_t)insn_get(env, s, MO_32); } else { tval = (int16_t)insn_get(env, s, MO_16); } do_jcc: next_eip = s->pc - s->cs_base; tval += next_eip; if (dflag == MO_16) { tval &= 0xffff; } gen_bnd_jmp(s); gen_jcc(s, b, tval, next_eip); break; case 0x190 ... 0x19f: modrm = x86_ldub_code(env, s); gen_setcc1(s, b, cpu_T0); gen_ldst_modrm(env, s, modrm, MO_8, OR_TMP0, 1); break; case 0x140 ... 0x14f: if (!(s->cpuid_features & CPUID_CMOV)) { goto illegal_op; } ot = dflag; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_cmovcc1(env, s, ot, b, modrm, reg); break; case 0x9c: gen_svm_check_intercept(s, pc_start, SVM_EXIT_PUSHF); if (s->vm86 && s->iopl != 3) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_update_cc_op(s); gen_helper_read_eflags(cpu_T0, cpu_env); gen_push_v(s, cpu_T0); } break; case 0x9d: gen_svm_check_intercept(s, pc_start, SVM_EXIT_POPF); if (s->vm86 && s->iopl != 3) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { ot = gen_pop_T0(s); if (s->cpl == 0) { if (dflag != MO_16) { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK | IF_MASK | IOPL_MASK))); } else { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK | IF_MASK | IOPL_MASK) & 0xffff)); } } else { if (s->cpl <= s->iopl) { if (dflag != MO_16) { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK | IF_MASK))); } else { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK | IF_MASK) & 0xffff)); } } else { if (dflag != MO_16) { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK))); } else { gen_helper_write_eflags(cpu_env, cpu_T0, tcg_const_i32((TF_MASK | AC_MASK | ID_MASK | NT_MASK) & 0xffff)); } } } gen_pop_update(s, ot); set_cc_op(s, CC_OP_EFLAGS); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } break; case 0x9e: if (CODE64(s) && !(s->cpuid_ext3_features & CPUID_EXT3_LAHF_LM)) goto illegal_op; gen_op_mov_v_reg(MO_8, cpu_T0, R_AH); gen_compute_eflags(s); tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, CC_O); tcg_gen_andi_tl(cpu_T0, cpu_T0, CC_S | CC_Z | CC_A | CC_P | CC_C); tcg_gen_or_tl(cpu_cc_src, cpu_cc_src, cpu_T0); break; case 0x9f: if (CODE64(s) && !(s->cpuid_ext3_features & CPUID_EXT3_LAHF_LM)) goto illegal_op; gen_compute_eflags(s); tcg_gen_ori_tl(cpu_T0, cpu_cc_src, 0x02); gen_op_mov_reg_v(MO_8, R_AH, cpu_T0); break; case 0xf5: gen_compute_eflags(s); tcg_gen_xori_tl(cpu_cc_src, cpu_cc_src, CC_C); break; case 0xf8: gen_compute_eflags(s); tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, ~CC_C); break; case 0xf9: gen_compute_eflags(s); tcg_gen_ori_tl(cpu_cc_src, cpu_cc_src, CC_C); break; case 0xfc: tcg_gen_movi_i32(cpu_tmp2_i32, 1); tcg_gen_st_i32(cpu_tmp2_i32, cpu_env, offsetof(CPUX86State, df)); break; case 0xfd: tcg_gen_movi_i32(cpu_tmp2_i32, -1); tcg_gen_st_i32(cpu_tmp2_i32, cpu_env, offsetof(CPUX86State, df)); break; case 0x1ba: ot = dflag; modrm = x86_ldub_code(env, s); op = (modrm >> 3) & 7; mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); if (mod != 3) { s->rip_offset = 1; gen_lea_modrm(env, s, modrm); if (!(s->prefix & PREFIX_LOCK)) { gen_op_ld_v(s, ot, cpu_T0, cpu_A0); } } else { gen_op_mov_v_reg(ot, cpu_T0, rm); } val = x86_ldub_code(env, s); tcg_gen_movi_tl(cpu_T1, val); if (op < 4) goto unknown_op; op -= 4; goto bt_op; case 0x1a3: op = 0; goto do_btx; case 0x1ab: op = 1; goto do_btx; case 0x1b3: op = 2; goto do_btx; case 0x1bb: op = 3; do_btx: ot = dflag; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); gen_op_mov_v_reg(MO_32, cpu_T1, reg); if (mod != 3) { AddressParts a = gen_lea_modrm_0(env, s, modrm); gen_exts(ot, cpu_T1); tcg_gen_sari_tl(cpu_tmp0, cpu_T1, 3 + ot); tcg_gen_shli_tl(cpu_tmp0, cpu_tmp0, ot); tcg_gen_add_tl(cpu_A0, gen_lea_modrm_1(a), cpu_tmp0); gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override); if (!(s->prefix & PREFIX_LOCK)) { gen_op_ld_v(s, ot, cpu_T0, cpu_A0); } } else { gen_op_mov_v_reg(ot, cpu_T0, rm); } bt_op: tcg_gen_andi_tl(cpu_T1, cpu_T1, (1 << (3 + ot)) - 1); tcg_gen_movi_tl(cpu_tmp0, 1); tcg_gen_shl_tl(cpu_tmp0, cpu_tmp0, cpu_T1); if (s->prefix & PREFIX_LOCK) { switch (op) { case 0: gen_op_ld_v(s, ot, cpu_T0, cpu_A0); break; case 1: tcg_gen_atomic_fetch_or_tl(cpu_T0, cpu_A0, cpu_tmp0, s->mem_index, ot | MO_LE); break; case 2: tcg_gen_not_tl(cpu_tmp0, cpu_tmp0); tcg_gen_atomic_fetch_and_tl(cpu_T0, cpu_A0, cpu_tmp0, s->mem_index, ot | MO_LE); break; default: case 3: tcg_gen_atomic_fetch_xor_tl(cpu_T0, cpu_A0, cpu_tmp0, s->mem_index, ot | MO_LE); break; } tcg_gen_shr_tl(cpu_tmp4, cpu_T0, cpu_T1); } else { tcg_gen_shr_tl(cpu_tmp4, cpu_T0, cpu_T1); switch (op) { case 0: break; case 1: tcg_gen_or_tl(cpu_T0, cpu_T0, cpu_tmp0); break; case 2: tcg_gen_andc_tl(cpu_T0, cpu_T0, cpu_tmp0); break; default: case 3: tcg_gen_xor_tl(cpu_T0, cpu_T0, cpu_tmp0); break; } if (op != 0) { if (mod != 3) { gen_op_st_v(s, ot, cpu_T0, cpu_A0); } else { gen_op_mov_reg_v(ot, rm, cpu_T0); } } } switch (s->cc_op) { case CC_OP_MULB ... CC_OP_MULQ: case CC_OP_ADDB ... CC_OP_ADDQ: case CC_OP_ADCB ... CC_OP_ADCQ: case CC_OP_SUBB ... CC_OP_SUBQ: case CC_OP_SBBB ... CC_OP_SBBQ: case CC_OP_LOGICB ... CC_OP_LOGICQ: case CC_OP_INCB ... CC_OP_INCQ: case CC_OP_DECB ... CC_OP_DECQ: case CC_OP_SHLB ... CC_OP_SHLQ: case CC_OP_SARB ... CC_OP_SARQ: case CC_OP_BMILGB ... CC_OP_BMILGQ: tcg_gen_mov_tl(cpu_cc_src, cpu_tmp4); set_cc_op(s, ((s->cc_op - CC_OP_MULB) & 3) + CC_OP_SARB); break; default: gen_compute_eflags(s); tcg_gen_deposit_tl(cpu_cc_src, cpu_cc_src, cpu_tmp4, ctz32(CC_C), 1); break; } break; case 0x1bc: case 0x1bd: ot = dflag; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0); gen_extu(ot, cpu_T0); if ((prefixes & PREFIX_REPZ) && (b & 1 ? s->cpuid_ext3_features & CPUID_EXT3_ABM : s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_BMI1)) { int size = 8 << ot; tcg_gen_mov_tl(cpu_cc_src, cpu_T0); if (b & 1) { tcg_gen_clzi_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS); tcg_gen_subi_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS - size); } else { tcg_gen_ctzi_tl(cpu_T0, cpu_T0, size); } gen_op_update1_cc(); set_cc_op(s, CC_OP_BMILGB + ot); } else { tcg_gen_mov_tl(cpu_cc_dst, cpu_T0); set_cc_op(s, CC_OP_LOGICB + ot); if (b & 1) { tcg_gen_xori_tl(cpu_T1, cpu_regs[reg], TARGET_LONG_BITS - 1); tcg_gen_clz_tl(cpu_T0, cpu_T0, cpu_T1); tcg_gen_xori_tl(cpu_T0, cpu_T0, TARGET_LONG_BITS - 1); } else { tcg_gen_ctz_tl(cpu_T0, cpu_T0, cpu_regs[reg]); } } gen_op_mov_reg_v(ot, reg, cpu_T0); break; case 0x27: if (CODE64(s)) goto illegal_op; gen_update_cc_op(s); gen_helper_daa(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x2f: if (CODE64(s)) goto illegal_op; gen_update_cc_op(s); gen_helper_das(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x37: if (CODE64(s)) goto illegal_op; gen_update_cc_op(s); gen_helper_aaa(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0x3f: if (CODE64(s)) goto illegal_op; gen_update_cc_op(s); gen_helper_aas(cpu_env); set_cc_op(s, CC_OP_EFLAGS); break; case 0xd4: if (CODE64(s)) goto illegal_op; val = x86_ldub_code(env, s); if (val == 0) { gen_exception(s, EXCP00_DIVZ, pc_start - s->cs_base); } else { gen_helper_aam(cpu_env, tcg_const_i32(val)); set_cc_op(s, CC_OP_LOGICB); } break; case 0xd5: if (CODE64(s)) goto illegal_op; val = x86_ldub_code(env, s); gen_helper_aad(cpu_env, tcg_const_i32(val)); set_cc_op(s, CC_OP_LOGICB); break; case 0x90: if (prefixes & PREFIX_LOCK) { goto illegal_op; } if (REX_B(s)) { goto do_xchg_reg_eax; } if (prefixes & PREFIX_REPZ) { gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_pause(cpu_env, tcg_const_i32(s->pc - pc_start)); s->base.is_jmp = DISAS_NORETURN; } break; case 0x9b: if ((s->flags & (HF_MP_MASK | HF_TS_MASK)) == (HF_MP_MASK | HF_TS_MASK)) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); } else { gen_helper_fwait(cpu_env); } break; case 0xcc: gen_interrupt(s, EXCP03_INT3, pc_start - s->cs_base, s->pc - s->cs_base); break; case 0xcd: val = x86_ldub_code(env, s); if (s->vm86 && s->iopl != 3) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_interrupt(s, val, pc_start - s->cs_base, s->pc - s->cs_base); } break; case 0xce: if (CODE64(s)) goto illegal_op; gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_into(cpu_env, tcg_const_i32(s->pc - pc_start)); break; #ifdef WANT_ICEBP case 0xf1: gen_svm_check_intercept(s, pc_start, SVM_EXIT_ICEBP); #if 1 gen_debug(s, pc_start - s->cs_base); #else tb_flush(CPU(x86_env_get_cpu(env))); qemu_set_log(CPU_LOG_INT | CPU_LOG_TB_IN_ASM); #endif break; #endif case 0xfa: if (!s->vm86) { if (s->cpl <= s->iopl) { gen_helper_cli(cpu_env); } else { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } } else { if (s->iopl == 3) { gen_helper_cli(cpu_env); } else { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } } break; case 0xfb: if (s->vm86 ? s->iopl == 3 : s->cpl <= s->iopl) { gen_helper_sti(cpu_env); gen_jmp_im(s->pc - s->cs_base); gen_eob_inhibit_irq(s, True); } else { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } break; case 0x62: if (CODE64(s)) goto illegal_op; ot = dflag; modrm = x86_ldub_code(env, s); reg = (modrm >> 3) & 7; mod = (modrm >> 6) & 3; if (mod == 3) goto illegal_op; gen_op_mov_v_reg(ot, cpu_T0, reg); gen_lea_modrm(env, s, modrm); tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); if (ot == MO_16) { gen_helper_boundw(cpu_env, cpu_A0, cpu_tmp2_i32); } else { gen_helper_boundl(cpu_env, cpu_A0, cpu_tmp2_i32); } break; case 0x1c8 ... 0x1cf: reg = (b & 7) | REX_B(s); #ifdef TARGET_X86_64 if (dflag == MO_64) { gen_op_mov_v_reg(MO_64, cpu_T0, reg); tcg_gen_bswap64_i64(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_64, reg, cpu_T0); } else #endif { gen_op_mov_v_reg(MO_32, cpu_T0, reg); tcg_gen_ext32u_tl(cpu_T0, cpu_T0); tcg_gen_bswap32_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_32, reg, cpu_T0); } break; case 0xd6: if (CODE64(s)) goto illegal_op; gen_compute_eflags_c(s, cpu_T0); tcg_gen_neg_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(MO_8, R_EAX, cpu_T0); break; case 0xe0: case 0xe1: case 0xe2: case 0xe3: { TCGLabel *l1, *l2, *l3; tval = (int8_t)insn_get(env, s, MO_8); next_eip = s->pc - s->cs_base; tval += next_eip; if (dflag == MO_16) { tval &= 0xffff; } l1 = gen_new_label(); l2 = gen_new_label(); l3 = gen_new_label(); b &= 3; switch(b) { case 0: case 1: gen_op_add_reg_im(s->aflag, R_ECX, -1); gen_op_jz_ecx(s->aflag, l3); gen_jcc1(s, (JCC_Z << 1) | (b ^ 1), l1); break; case 2: gen_op_add_reg_im(s->aflag, R_ECX, -1); gen_op_jnz_ecx(s->aflag, l1); break; default: case 3: gen_op_jz_ecx(s->aflag, l1); break; } gen_set_label(l3); gen_jmp_im(next_eip); tcg_gen_br(l2); gen_set_label(l1); gen_jmp_im(tval); gen_set_label(l2); gen_eob(s); } break; case 0x130: case 0x132: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); if (b & 2) { gen_helper_rdmsr(cpu_env); } else { gen_helper_wrmsr(cpu_env); } } break; case 0x131: gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } gen_helper_rdtsc(cpu_env); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; case 0x133: gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_rdpmc(cpu_env); break; case 0x134: if (CODE64(s) && env->cpuid_vendor1 != CPUID_VENDOR_INTEL_1) goto illegal_op; if (!s->pe) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_helper_sysenter(cpu_env); gen_eob(s); } break; case 0x135: if (CODE64(s) && env->cpuid_vendor1 != CPUID_VENDOR_INTEL_1) goto illegal_op; if (!s->pe) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_helper_sysexit(cpu_env, tcg_const_i32(dflag - 1)); gen_eob(s); } break; #ifdef TARGET_X86_64 case 0x105: gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_syscall(cpu_env, tcg_const_i32(s->pc - pc_start)); gen_eob_worker(s, False, True); break; case 0x107: if (!s->pe) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_helper_sysret(cpu_env, tcg_const_i32(dflag - 1)); if (s->lma) { set_cc_op(s, CC_OP_EFLAGS); } gen_eob_worker(s, False, True); } break; #endif case 0x1a2: gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_cpuid(cpu_env); break; case 0xf4: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_hlt(cpu_env, tcg_const_i32(s->pc - pc_start)); s->base.is_jmp = DISAS_NORETURN; } break; case 0x100: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; op = (modrm >> 3) & 7; switch(op) { case 0: if (!s->pe || s->vm86) goto illegal_op; gen_svm_check_intercept(s, pc_start, SVM_EXIT_LDTR_READ); tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, ldt.selector)); ot = mod == 3 ? dflag : MO_16; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1); break; case 2: if (!s->pe || s->vm86) goto illegal_op; if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_svm_check_intercept(s, pc_start, SVM_EXIT_LDTR_WRITE); gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_lldt(cpu_env, cpu_tmp2_i32); } break; case 1: if (!s->pe || s->vm86) goto illegal_op; gen_svm_check_intercept(s, pc_start, SVM_EXIT_TR_READ); tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, tr.selector)); ot = mod == 3 ? dflag : MO_16; gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1); break; case 3: if (!s->pe || s->vm86) goto illegal_op; if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_svm_check_intercept(s, pc_start, SVM_EXIT_TR_WRITE); gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_T0); gen_helper_ltr(cpu_env, cpu_tmp2_i32); } break; case 4: case 5: if (!s->pe || s->vm86) goto illegal_op; gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); gen_update_cc_op(s); if (op == 4) { gen_helper_verr(cpu_env, cpu_T0); } else { gen_helper_verw(cpu_env, cpu_T0); } set_cc_op(s, CC_OP_EFLAGS); break; default: goto unknown_op; } break; case 0x101: modrm = x86_ldub_code(env, s); switch (modrm) { CASE_MODRM_MEM_OP(0): gen_svm_check_intercept(s, pc_start, SVM_EXIT_GDTR_READ); gen_lea_modrm(env, s, modrm); tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, gdt.limit)); gen_op_st_v(s, MO_16, cpu_T0, cpu_A0); gen_add_A0_im(s, 2); tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, gdt.base)); if (dflag == MO_16) { tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff); } gen_op_st_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0); break; case 0xc8: if (!(s->cpuid_ext_features & CPUID_EXT_MONITOR) || s->cpl != 0) { goto illegal_op; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); tcg_gen_mov_tl(cpu_A0, cpu_regs[R_EAX]); gen_extu(s->aflag, cpu_A0); gen_add_A0_ds_seg(s); gen_helper_monitor(cpu_env, cpu_A0); break; case 0xc9: if (!(s->cpuid_ext_features & CPUID_EXT_MONITOR) || s->cpl != 0) { goto illegal_op; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_mwait(cpu_env, tcg_const_i32(s->pc - pc_start)); gen_eob(s); break; case 0xca: if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP) || s->cpl != 0) { goto illegal_op; } gen_helper_clac(cpu_env); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; case 0xcb: if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_SMAP) || s->cpl != 0) { goto illegal_op; } gen_helper_stac(cpu_env); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; CASE_MODRM_MEM_OP(1): gen_svm_check_intercept(s, pc_start, SVM_EXIT_IDTR_READ); gen_lea_modrm(env, s, modrm); tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.limit)); gen_op_st_v(s, MO_16, cpu_T0, cpu_A0); gen_add_A0_im(s, 2); tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.base)); if (dflag == MO_16) { tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff); } gen_op_st_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0); break; case 0xd0: if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0 || (s->prefix & (PREFIX_LOCK | PREFIX_DATA | PREFIX_REPZ | PREFIX_REPNZ))) { goto illegal_op; } tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]); gen_helper_xgetbv(cpu_tmp1_i64, cpu_env, cpu_tmp2_i32); tcg_gen_extr_i64_tl(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_tmp1_i64); break; case 0xd1: if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0 || (s->prefix & (PREFIX_LOCK | PREFIX_DATA | PREFIX_REPZ | PREFIX_REPNZ))) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX], cpu_regs[R_EDX]); tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]); gen_helper_xsetbv(cpu_env, cpu_tmp2_i32, cpu_tmp1_i64); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; case 0xd8: if (!(s->flags & HF_SVME_MASK) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_vmrun(cpu_env, tcg_const_i32(s->aflag - 1), tcg_const_i32(s->pc - pc_start)); tcg_gen_exit_tb(0); s->base.is_jmp = DISAS_NORETURN; break; case 0xd9: if (!(s->flags & HF_SVME_MASK)) { goto illegal_op; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_vmmcall(cpu_env); break; case 0xda: if (!(s->flags & HF_SVME_MASK) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_vmload(cpu_env, tcg_const_i32(s->aflag - 1)); break; case 0xdb: if (!(s->flags & HF_SVME_MASK) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_vmsave(cpu_env, tcg_const_i32(s->aflag - 1)); break; case 0xdc: if ((!(s->flags & HF_SVME_MASK) && !(s->cpuid_ext3_features & CPUID_EXT3_SKINIT)) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_stgi(cpu_env); break; case 0xdd: if (!(s->flags & HF_SVME_MASK) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_clgi(cpu_env); break; case 0xde: if ((!(s->flags & HF_SVME_MASK) && !(s->cpuid_ext3_features & CPUID_EXT3_SKINIT)) || !s->pe) { goto illegal_op; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_skinit(cpu_env); break; case 0xdf: if (!(s->flags & HF_SVME_MASK) || !s->pe) { goto illegal_op; } if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_helper_invlpga(cpu_env, tcg_const_i32(s->aflag - 1)); break; CASE_MODRM_MEM_OP(2): if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_svm_check_intercept(s, pc_start, SVM_EXIT_GDTR_WRITE); gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, MO_16, cpu_T1, cpu_A0); gen_add_A0_im(s, 2); gen_op_ld_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0); if (dflag == MO_16) { tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff); } tcg_gen_st_tl(cpu_T0, cpu_env, offsetof(CPUX86State, gdt.base)); tcg_gen_st32_tl(cpu_T1, cpu_env, offsetof(CPUX86State, gdt.limit)); break; CASE_MODRM_MEM_OP(3): if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_svm_check_intercept(s, pc_start, SVM_EXIT_IDTR_WRITE); gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, MO_16, cpu_T1, cpu_A0); gen_add_A0_im(s, 2); gen_op_ld_v(s, CODE64(s) + MO_32, cpu_T0, cpu_A0); if (dflag == MO_16) { tcg_gen_andi_tl(cpu_T0, cpu_T0, 0xffffff); } tcg_gen_st_tl(cpu_T0, cpu_env, offsetof(CPUX86State, idt.base)); tcg_gen_st32_tl(cpu_T1, cpu_env, offsetof(CPUX86State, idt.limit)); break; CASE_MODRM_OP(4): gen_svm_check_intercept(s, pc_start, SVM_EXIT_READ_CR0); tcg_gen_ld_tl(cpu_T0, cpu_env, offsetof(CPUX86State, cr[0])); if (CODE64(s)) { mod = (modrm >> 6) & 3; ot = (mod != 3 ? MO_16 : s->dflag); } else { ot = MO_16; } gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 1); break; case 0xee: if (prefixes & PREFIX_LOCK) { goto illegal_op; } tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]); gen_helper_rdpkru(cpu_tmp1_i64, cpu_env, cpu_tmp2_i32); tcg_gen_extr_i64_tl(cpu_regs[R_EAX], cpu_regs[R_EDX], cpu_tmp1_i64); break; case 0xef: if (prefixes & PREFIX_LOCK) { goto illegal_op; } tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX], cpu_regs[R_EDX]); tcg_gen_trunc_tl_i32(cpu_tmp2_i32, cpu_regs[R_ECX]); gen_helper_wrpkru(cpu_env, cpu_tmp2_i32, cpu_tmp1_i64); break; CASE_MODRM_OP(6): if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_CR0); gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); gen_helper_lmsw(cpu_env, cpu_T0); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; CASE_MODRM_MEM_OP(7): if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); break; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); gen_lea_modrm(env, s, modrm); gen_helper_invlpg(cpu_env, cpu_A0); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; case 0xf8: #ifdef TARGET_X86_64 if (CODE64(s)) { if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { tcg_gen_mov_tl(cpu_T0, cpu_seg_base[R_GS]); tcg_gen_ld_tl(cpu_seg_base[R_GS], cpu_env, offsetof(CPUX86State, kernelgsbase)); tcg_gen_st_tl(cpu_T0, cpu_env, offsetof(CPUX86State, kernelgsbase)); } break; } #endif goto illegal_op; case 0xf9: if (!(s->cpuid_ext2_features & CPUID_EXT2_RDTSCP)) { goto illegal_op; } gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } gen_helper_rdtscp(cpu_env); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); gen_jmp(s, s->pc - s->cs_base); } break; default: goto unknown_op; } break; case 0x108: case 0x109: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_svm_check_intercept(s, pc_start, (b & 2) ? SVM_EXIT_INVD : SVM_EXIT_WBINVD); } break; case 0x63: #ifdef TARGET_X86_64 if (CODE64(s)) { int d_ot; d_ot = dflag; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; mod = (modrm >> 6) & 3; rm = (modrm & 7) | REX_B(s); if (mod == 3) { gen_op_mov_v_reg(MO_32, cpu_T0, rm); if (d_ot == MO_64) { tcg_gen_ext32s_tl(cpu_T0, cpu_T0); } gen_op_mov_reg_v(d_ot, reg, cpu_T0); } else { gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, MO_32 | MO_SIGN, cpu_T0, cpu_A0); gen_op_mov_reg_v(d_ot, reg, cpu_T0); } } else #endif { TCGLabel *label1; TCGv t0, t1, t2, a0; if (!s->pe || s->vm86) goto illegal_op; t0 = tcg_temp_local_new(); t1 = tcg_temp_local_new(); t2 = tcg_temp_local_new(); ot = MO_16; modrm = x86_ldub_code(env, s); reg = (modrm >> 3) & 7; mod = (modrm >> 6) & 3; rm = modrm & 7; if (mod != 3) { gen_lea_modrm(env, s, modrm); gen_op_ld_v(s, ot, t0, cpu_A0); a0 = tcg_temp_local_new(); tcg_gen_mov_tl(a0, cpu_A0); } else { gen_op_mov_v_reg(ot, t0, rm); TCGV_UNUSED(a0); } gen_op_mov_v_reg(ot, t1, reg); tcg_gen_andi_tl(cpu_tmp0, t0, 3); tcg_gen_andi_tl(t1, t1, 3); tcg_gen_movi_tl(t2, 0); label1 = gen_new_label(); tcg_gen_brcond_tl(TCG_COND_GE, cpu_tmp0, t1, label1); tcg_gen_andi_tl(t0, t0, ~3); tcg_gen_or_tl(t0, t0, t1); tcg_gen_movi_tl(t2, CC_Z); gen_set_label(label1); if (mod != 3) { gen_op_st_v(s, ot, t0, a0); tcg_temp_free(a0); } else { gen_op_mov_reg_v(ot, rm, t0); } gen_compute_eflags(s); tcg_gen_andi_tl(cpu_cc_src, cpu_cc_src, ~CC_Z); tcg_gen_or_tl(cpu_cc_src, cpu_cc_src, t2); tcg_temp_free(t0); tcg_temp_free(t1); tcg_temp_free(t2); } break; case 0x102: case 0x103: { TCGLabel *label1; TCGv t0; if (!s->pe || s->vm86) goto illegal_op; ot = dflag != MO_16 ? MO_32 : MO_16; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, MO_16, OR_TMP0, 0); t0 = tcg_temp_local_new(); gen_update_cc_op(s); if (b == 0x102) { gen_helper_lar(t0, cpu_env, cpu_T0); } else { gen_helper_lsl(t0, cpu_env, cpu_T0); } tcg_gen_andi_tl(cpu_tmp0, cpu_cc_src, CC_Z); label1 = gen_new_label(); tcg_gen_brcondi_tl(TCG_COND_EQ, cpu_tmp0, 0, label1); gen_op_mov_reg_v(ot, reg, t0); gen_set_label(label1); set_cc_op(s, CC_OP_EFLAGS); tcg_temp_free(t0); } break; case 0x118: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; op = (modrm >> 3) & 7; switch(op) { case 0: case 1: case 2: case 3: if (mod == 3) goto illegal_op; gen_nop_modrm(env, s, modrm); break; default: gen_nop_modrm(env, s, modrm); break; } break; case 0x11a: modrm = x86_ldub_code(env, s); if (s->flags & HF_MPX_EN_MASK) { mod = (modrm >> 6) & 3; reg = ((modrm >> 3) & 7) | rex_r; if (prefixes & PREFIX_REPZ) { if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16) { goto illegal_op; } gen_bndck(env, s, modrm, TCG_COND_LTU, cpu_bndl[reg]); } else if (prefixes & PREFIX_REPNZ) { if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16) { goto illegal_op; } TCGv_i64 notu = tcg_temp_new_i64(); tcg_gen_not_i64(notu, cpu_bndu[reg]); gen_bndck(env, s, modrm, TCG_COND_GTU, notu); tcg_temp_free_i64(notu); } else if (prefixes & PREFIX_DATA) { if (reg >= 4 || s->aflag == MO_16) { goto illegal_op; } if (mod == 3) { int reg2 = (modrm & 7) | REX_B(s); if (reg2 >= 4 || (prefixes & PREFIX_LOCK)) { goto illegal_op; } if (s->flags & HF_MPX_IU_MASK) { tcg_gen_mov_i64(cpu_bndl[reg], cpu_bndl[reg2]); tcg_gen_mov_i64(cpu_bndu[reg], cpu_bndu[reg2]); } } else { gen_lea_modrm(env, s, modrm); if (CODE64(s)) { tcg_gen_qemu_ld_i64(cpu_bndl[reg], cpu_A0, s->mem_index, MO_LEQ); tcg_gen_addi_tl(cpu_A0, cpu_A0, 8); tcg_gen_qemu_ld_i64(cpu_bndu[reg], cpu_A0, s->mem_index, MO_LEQ); } else { tcg_gen_qemu_ld_i64(cpu_bndl[reg], cpu_A0, s->mem_index, MO_LEUL); tcg_gen_addi_tl(cpu_A0, cpu_A0, 4); tcg_gen_qemu_ld_i64(cpu_bndu[reg], cpu_A0, s->mem_index, MO_LEUL); } gen_set_hflag(s, HF_MPX_IU_MASK); } } else if (mod != 3) { AddressParts a = gen_lea_modrm_0(env, s, modrm); if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16 || a.base < -1) { goto illegal_op; } if (a.base >= 0) { tcg_gen_addi_tl(cpu_A0, cpu_regs[a.base], a.disp); } else { tcg_gen_movi_tl(cpu_A0, 0); } gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override); if (a.index >= 0) { tcg_gen_mov_tl(cpu_T0, cpu_regs[a.index]); } else { tcg_gen_movi_tl(cpu_T0, 0); } if (CODE64(s)) { gen_helper_bndldx64(cpu_bndl[reg], cpu_env, cpu_A0, cpu_T0); tcg_gen_ld_i64(cpu_bndu[reg], cpu_env, offsetof(CPUX86State, mmx_t0.MMX_Q(0))); } else { gen_helper_bndldx32(cpu_bndu[reg], cpu_env, cpu_A0, cpu_T0); tcg_gen_ext32u_i64(cpu_bndl[reg], cpu_bndu[reg]); tcg_gen_shri_i64(cpu_bndu[reg], cpu_bndu[reg], 32); } gen_set_hflag(s, HF_MPX_IU_MASK); } } gen_nop_modrm(env, s, modrm); break; case 0x11b: modrm = x86_ldub_code(env, s); if (s->flags & HF_MPX_EN_MASK) { mod = (modrm >> 6) & 3; reg = ((modrm >> 3) & 7) | rex_r; if (mod != 3 && (prefixes & PREFIX_REPZ)) { if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16) { goto illegal_op; } AddressParts a = gen_lea_modrm_0(env, s, modrm); if (a.base >= 0) { tcg_gen_extu_tl_i64(cpu_bndl[reg], cpu_regs[a.base]); if (!CODE64(s)) { tcg_gen_ext32u_i64(cpu_bndl[reg], cpu_bndl[reg]); } } else if (a.base == -1) { tcg_gen_movi_i64(cpu_bndl[reg], 0); } else { goto illegal_op; } tcg_gen_not_tl(cpu_A0, gen_lea_modrm_1(a)); if (!CODE64(s)) { tcg_gen_ext32u_tl(cpu_A0, cpu_A0); } tcg_gen_extu_tl_i64(cpu_bndu[reg], cpu_A0); gen_set_hflag(s, HF_MPX_IU_MASK); break; } else if (prefixes & PREFIX_REPNZ) { if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16) { goto illegal_op; } gen_bndck(env, s, modrm, TCG_COND_GTU, cpu_bndu[reg]); } else if (prefixes & PREFIX_DATA) { if (reg >= 4 || s->aflag == MO_16) { goto illegal_op; } if (mod == 3) { int reg2 = (modrm & 7) | REX_B(s); if (reg2 >= 4 || (prefixes & PREFIX_LOCK)) { goto illegal_op; } if (s->flags & HF_MPX_IU_MASK) { tcg_gen_mov_i64(cpu_bndl[reg2], cpu_bndl[reg]); tcg_gen_mov_i64(cpu_bndu[reg2], cpu_bndu[reg]); } } else { gen_lea_modrm(env, s, modrm); if (CODE64(s)) { tcg_gen_qemu_st_i64(cpu_bndl[reg], cpu_A0, s->mem_index, MO_LEQ); tcg_gen_addi_tl(cpu_A0, cpu_A0, 8); tcg_gen_qemu_st_i64(cpu_bndu[reg], cpu_A0, s->mem_index, MO_LEQ); } else { tcg_gen_qemu_st_i64(cpu_bndl[reg], cpu_A0, s->mem_index, MO_LEUL); tcg_gen_addi_tl(cpu_A0, cpu_A0, 4); tcg_gen_qemu_st_i64(cpu_bndu[reg], cpu_A0, s->mem_index, MO_LEUL); } } } else if (mod != 3) { AddressParts a = gen_lea_modrm_0(env, s, modrm); if (reg >= 4 || (prefixes & PREFIX_LOCK) || s->aflag == MO_16 || a.base < -1) { goto illegal_op; } if (a.base >= 0) { tcg_gen_addi_tl(cpu_A0, cpu_regs[a.base], a.disp); } else { tcg_gen_movi_tl(cpu_A0, 0); } gen_lea_v_seg(s, s->aflag, cpu_A0, a.def_seg, s->override); if (a.index >= 0) { tcg_gen_mov_tl(cpu_T0, cpu_regs[a.index]); } else { tcg_gen_movi_tl(cpu_T0, 0); } if (CODE64(s)) { gen_helper_bndstx64(cpu_env, cpu_A0, cpu_T0, cpu_bndl[reg], cpu_bndu[reg]); } else { gen_helper_bndstx32(cpu_env, cpu_A0, cpu_T0, cpu_bndl[reg], cpu_bndu[reg]); } } } gen_nop_modrm(env, s, modrm); break; case 0x119: case 0x11c ... 0x11f: modrm = x86_ldub_code(env, s); gen_nop_modrm(env, s, modrm); break; case 0x120: case 0x122: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { modrm = x86_ldub_code(env, s); rm = (modrm & 7) | REX_B(s); reg = ((modrm >> 3) & 7) | rex_r; if (CODE64(s)) ot = MO_64; else ot = MO_32; if ((prefixes & PREFIX_LOCK) && (reg == 0) && (s->cpuid_ext3_features & CPUID_EXT3_CR8LEG)) { reg = 8; } switch(reg) { case 0: case 2: case 3: case 4: case 8: gen_update_cc_op(s); gen_jmp_im(pc_start - s->cs_base); if (b & 2) { if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } gen_op_mov_v_reg(ot, cpu_T0, rm); gen_helper_write_crN(cpu_env, tcg_const_i32(reg), cpu_T0); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); } gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } else { if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_start(); } gen_helper_read_crN(cpu_T0, cpu_env, tcg_const_i32(reg)); gen_op_mov_reg_v(ot, rm, cpu_T0); if (s->base.tb->cflags & CF_USE_ICOUNT) { gen_io_end(); } } break; default: goto unknown_op; } } break; case 0x121: case 0x123: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { modrm = x86_ldub_code(env, s); rm = (modrm & 7) | REX_B(s); reg = ((modrm >> 3) & 7) | rex_r; if (CODE64(s)) ot = MO_64; else ot = MO_32; if (reg >= 8) { goto illegal_op; } if (b & 2) { gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_DR0 + reg); gen_op_mov_v_reg(ot, cpu_T0, rm); tcg_gen_movi_i32(cpu_tmp2_i32, reg); gen_helper_set_dr(cpu_env, cpu_tmp2_i32, cpu_T0); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } else { gen_svm_check_intercept(s, pc_start, SVM_EXIT_READ_DR0 + reg); tcg_gen_movi_i32(cpu_tmp2_i32, reg); gen_helper_get_dr(cpu_T0, cpu_env, cpu_tmp2_i32); gen_op_mov_reg_v(ot, rm, cpu_T0); } } break; case 0x106: if (s->cpl != 0) { gen_exception(s, EXCP0D_GPF, pc_start - s->cs_base); } else { gen_svm_check_intercept(s, pc_start, SVM_EXIT_WRITE_CR0); gen_helper_clts(cpu_env); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); } break; case 0x1c3: if (!(s->cpuid_features & CPUID_SSE2)) goto illegal_op; ot = mo_64_32(dflag); modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; if (mod == 3) goto illegal_op; reg = ((modrm >> 3) & 7) | rex_r; gen_ldst_modrm(env, s, modrm, ot, reg, 1); break; case 0x1ae: modrm = x86_ldub_code(env, s); switch (modrm) { CASE_MODRM_MEM_OP(0): if (!(s->cpuid_features & CPUID_FXSR) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } if ((s->flags & HF_EM_MASK) || (s->flags & HF_TS_MASK)) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); break; } gen_lea_modrm(env, s, modrm); gen_helper_fxsave(cpu_env, cpu_A0); break; CASE_MODRM_MEM_OP(1): if (!(s->cpuid_features & CPUID_FXSR) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } if ((s->flags & HF_EM_MASK) || (s->flags & HF_TS_MASK)) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); break; } gen_lea_modrm(env, s, modrm); gen_helper_fxrstor(cpu_env, cpu_A0); break; CASE_MODRM_MEM_OP(2): if ((s->flags & HF_EM_MASK) || !(s->flags & HF_OSFXSR_MASK)) { goto illegal_op; } if (s->flags & HF_TS_MASK) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); break; } gen_lea_modrm(env, s, modrm); tcg_gen_qemu_ld_i32(cpu_tmp2_i32, cpu_A0, s->mem_index, MO_LEUL); gen_helper_ldmxcsr(cpu_env, cpu_tmp2_i32); break; CASE_MODRM_MEM_OP(3): if ((s->flags & HF_EM_MASK) || !(s->flags & HF_OSFXSR_MASK)) { goto illegal_op; } if (s->flags & HF_TS_MASK) { gen_exception(s, EXCP07_PREX, pc_start - s->cs_base); break; } gen_lea_modrm(env, s, modrm); tcg_gen_ld32u_tl(cpu_T0, cpu_env, offsetof(CPUX86State, mxcsr)); gen_op_st_v(s, MO_32, cpu_T0, cpu_A0); break; CASE_MODRM_MEM_OP(4): if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0 || (prefixes & (PREFIX_LOCK | PREFIX_DATA | PREFIX_REPZ | PREFIX_REPNZ))) { goto illegal_op; } gen_lea_modrm(env, s, modrm); tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX], cpu_regs[R_EDX]); gen_helper_xsave(cpu_env, cpu_A0, cpu_tmp1_i64); break; CASE_MODRM_MEM_OP(5): if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0 || (prefixes & (PREFIX_LOCK | PREFIX_DATA | PREFIX_REPZ | PREFIX_REPNZ))) { goto illegal_op; } gen_lea_modrm(env, s, modrm); tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX], cpu_regs[R_EDX]); gen_helper_xrstor(cpu_env, cpu_A0, cpu_tmp1_i64); gen_update_cc_op(s); gen_jmp_im(s->pc - s->cs_base); gen_eob(s); break; CASE_MODRM_MEM_OP(6): if (prefixes & PREFIX_LOCK) { goto illegal_op; } if (prefixes & PREFIX_DATA) { if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLWB)) { goto illegal_op; } gen_nop_modrm(env, s, modrm); } else { if ((s->cpuid_ext_features & CPUID_EXT_XSAVE) == 0 || (s->cpuid_xsave_features & CPUID_XSAVE_XSAVEOPT) == 0 || (prefixes & (PREFIX_REPZ | PREFIX_REPNZ))) { goto illegal_op; } gen_lea_modrm(env, s, modrm); tcg_gen_concat_tl_i64(cpu_tmp1_i64, cpu_regs[R_EAX], cpu_regs[R_EDX]); gen_helper_xsaveopt(cpu_env, cpu_A0, cpu_tmp1_i64); } break; CASE_MODRM_MEM_OP(7): if (prefixes & PREFIX_LOCK) { goto illegal_op; } if (prefixes & PREFIX_DATA) { if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_CLFLUSHOPT)) { goto illegal_op; } } else { if ((s->prefix & (PREFIX_REPZ | PREFIX_REPNZ)) || !(s->cpuid_features & CPUID_CLFLUSH)) { goto illegal_op; } } gen_nop_modrm(env, s, modrm); break; case 0xc0 ... 0xc7: case 0xc8 ... 0xcf: case 0xd0 ... 0xd7: case 0xd8 ... 0xdf: if (CODE64(s) && (prefixes & PREFIX_REPZ) && !(prefixes & PREFIX_LOCK) && (s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_FSGSBASE)) { TCGv base, treg, src, dst; tcg_gen_movi_i32(cpu_tmp2_i32, CR4_FSGSBASE_MASK); gen_helper_cr4_testbit(cpu_env, cpu_tmp2_i32); base = cpu_seg_base[modrm & 8 ? R_GS : R_FS]; treg = cpu_regs[(modrm & 7) | REX_B(s)]; if (modrm & 0x10) { dst = base, src = treg; } else { dst = treg, src = base; } if (s->dflag == MO_32) { tcg_gen_ext32u_tl(dst, src); } else { tcg_gen_mov_tl(dst, src); } break; } goto unknown_op; case 0xf8: if (prefixes & PREFIX_DATA) { if (!(s->cpuid_7_0_ebx_features & CPUID_7_0_EBX_PCOMMIT) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } break; } case 0xf9 ... 0xff: if (!(s->cpuid_features & CPUID_SSE) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } tcg_gen_mb(TCG_MO_ST_ST | TCG_BAR_SC); break; case 0xe8 ... 0xef: if (!(s->cpuid_features & CPUID_SSE) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } tcg_gen_mb(TCG_MO_LD_LD | TCG_BAR_SC); break; case 0xf0 ... 0xf7: if (!(s->cpuid_features & CPUID_SSE2) || (prefixes & PREFIX_LOCK)) { goto illegal_op; } tcg_gen_mb(TCG_MO_ALL | TCG_BAR_SC); break; default: goto unknown_op; } break; case 0x10d: modrm = x86_ldub_code(env, s); mod = (modrm >> 6) & 3; if (mod == 3) goto illegal_op; gen_nop_modrm(env, s, modrm); break; case 0x1aa: gen_svm_check_intercept(s, pc_start, SVM_EXIT_RSM); if (!(s->flags & HF_SMM_MASK)) goto illegal_op; gen_update_cc_op(s); gen_jmp_im(s->pc - s->cs_base); gen_helper_rsm(cpu_env); gen_eob(s); break; case 0x1b8: if ((prefixes & (PREFIX_REPZ | PREFIX_LOCK | PREFIX_REPNZ)) != PREFIX_REPZ) goto illegal_op; if (!(s->cpuid_ext_features & CPUID_EXT_POPCNT)) goto illegal_op; modrm = x86_ldub_code(env, s); reg = ((modrm >> 3) & 7) | rex_r; if (s->prefix & PREFIX_DATA) { ot = MO_16; } else { ot = mo_64_32(dflag); } gen_ldst_modrm(env, s, modrm, ot, OR_TMP0, 0); gen_extu(ot, cpu_T0); tcg_gen_mov_tl(cpu_cc_src, cpu_T0); tcg_gen_ctpop_tl(cpu_T0, cpu_T0); gen_op_mov_reg_v(ot, reg, cpu_T0); set_cc_op(s, CC_OP_POPCNT); break; case 0x10e ... 0x10f: s->prefix &= ~(PREFIX_REPZ | PREFIX_REPNZ | PREFIX_DATA); case 0x110 ... 0x117: case 0x128 ... 0x12f: case 0x138 ... 0x13a: case 0x150 ... 0x179: case 0x17c ... 0x17f: case 0x1c2: case 0x1c4 ... 0x1c6: case 0x1d0 ... 0x1fe: gen_sse(env, s, b, pc_start, rex_r); break; default: goto unknown_op; } return s->pc; illegal_op: gen_illegal_opcode(s); return s->pc; unknown_op: gen_unknown_opcode(env, s); return s->pc; }[Succeeded / Failed / Skipped / Total] 14 / 17 / 20 / 51:   2%|         | 51/2690 [00:24<21:24,  2.05it/s][Succeeded / Failed / Skipped / Total] 14 / 17 / 21 / 52:   2%|         | 52/2690 [00:24<21:00,  2.09it/s][Succeeded / Failed / Skipped / Total] 14 / 17 / 21 / 52:   2%|         | 53/2690 [00:24<20:36,  2.13it/s][Succeeded / Failed / Skipped / Total] 14 / 17 / 22 / 53:   2%|         | 53/2690 [00:24<20:36,  2.13it/s][Succeeded / Failed / Skipped / Total] 14 / 17 / 23 / 54:   2%|         | 54/2690 [00:24<20:13,  2.17it/s]


--------------------------------------------- Result 52 ---------------------------------------------
[[0 (37%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static int iscsi_open(BlockDriverState *bs, const char *filename, int flags) { IscsiLun *iscsilun = bs->opaque; struct iscsi_context *iscsi = NULL; struct iscsi_url *iscsi_url = NULL; struct IscsiTask task; char *initiator_name = NULL; int ret; if ((BDRV_SECTOR_SIZE % 512) != 0) { error_report("iSCSI: Invalid BDRV_SECTOR_SIZE. " "BDRV_SECTOR_SIZE(%lld) is not a multiple " "of 512", BDRV_SECTOR_SIZE); return -EINVAL; } iscsi_url = iscsi_parse_full_url(iscsi, filename); if (iscsi_url == NULL) { error_report("Failed to parse URL : %s %s", filename, iscsi_get_error(iscsi)); ret = -EINVAL; goto failed; } memset(iscsilun, 0, sizeof(IscsiLun)); initiator_name = parse_initiator_name(iscsi_url->target); iscsi = iscsi_create_context(initiator_name); if (iscsi == NULL) { error_report("iSCSI: Failed to create iSCSI context."); ret = -ENOMEM; goto failed; } if (iscsi_set_targetname(iscsi, iscsi_url->target)) { error_report("iSCSI: Failed to set target name."); ret = -EINVAL; goto failed; } if (iscsi_url->user != NULL) { ret = iscsi_set_initiator_username_pwd(iscsi, iscsi_url->user, iscsi_url->passwd); if (ret != 0) { error_report("Failed to set initiator username and password"); ret = -EINVAL; goto failed; } } if (parse_chap(iscsi, iscsi_url->target) != 0) { error_report("iSCSI: Failed to set CHAP user/password"); ret = -EINVAL; goto failed; } if (iscsi_set_session_type(iscsi, ISCSI_SESSION_NORMAL) != 0) { error_report("iSCSI: Failed to set session type to normal."); ret = -EINVAL; goto failed; } iscsi_set_header_digest(iscsi, ISCSI_HEADER_DIGEST_NONE_CRC32C); parse_header_digest(iscsi, iscsi_url->target); task.iscsilun = iscsilun; task.status = 0; task.complete = 0; task.bs = bs; iscsilun->iscsi = iscsi; iscsilun->lun = iscsi_url->lun; if (iscsi_full_connect_async(iscsi, iscsi_url->portal, iscsi_url->lun, iscsi_connect_cb, &task) != 0) { error_report("iSCSI: Failed to start async connect."); ret = -EINVAL; goto failed; } while (!task.complete) { iscsi_set_events(iscsilun); qemu_aio_wait(); } if (task.status != 0) { error_report("iSCSI: Failed to connect to LUN : %s", iscsi_get_error(iscsi)); ret = -EINVAL; goto failed; } if (iscsi_url != NULL) { iscsi_destroy_url(iscsi_url); } if (iscsilun->type == TYPE_MEDIUM_CHANGER || iscsilun->type == TYPE_TAPE) { bs->sg = 1; } return 0; failed: if (initiator_name != NULL) { g_free(initiator_name); } if (iscsi_url != NULL) { iscsi_destroy_url(iscsi_url); } if (iscsi != NULL) { iscsi_destroy_context(iscsi); } memset(iscsilun, 0, sizeof(IscsiLun)); return ret; }


--------------------------------------------- Result 53 ---------------------------------------------
[[0 (37%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: static void vmxnet3_rx_need_csum_calculate(struct VmxnetRxPkt *pkt, const void *pkt_data, size_t pkt_len) { struct virtio_net_hdr *vhdr; bool isip4, isip6, istcp, isudp; uint8_t *data; int len; if (!vmxnet_rx_pkt_has_virt_hdr(pkt)) { return; } vhdr = vmxnet_rx_pkt_get_vhdr(pkt); if (!VMXNET_FLAG_IS_SET(vhdr->flags, VIRTIO_NET_HDR_F_NEEDS_CSUM)) { return; } vmxnet_rx_pkt_get_protocols(pkt, &isip4, &isip6, &isudp, &istcp); if (!(isip4 || isip6) || !(istcp || isudp)) { return; } vmxnet3_dump_virt_hdr(vhdr); if (pkt_len < (vhdr->csum_start + vhdr->csum_offset + 2)) { VMW_PKPRN("packet len:%d < csum_start(%d) + csum_offset(%d) + 2, " "cannot calculate checksum", len, vhdr->csum_start, vhdr->csum_offset); return; } data = (uint8_t *)pkt_data + vhdr->csum_start; len = pkt_len - vhdr->csum_start; stw_be_p(data + vhdr->csum_offset, net_raw_checksum(data, len)); vhdr->flags &= ~VIRTIO_NET_HDR_F_NEEDS_CSUM; vhdr->flags |= VIRTIO_NET_HDR_F_DATA_VALID; }


--------------------------------------------- Result 54 ---------------------------------------------
[[0 (9%)]] --> [[[SKIPPED]]]

[[[[Adv]]]]: CommandInfoList *qmp_query_commands(Error **errp) { CommandInfoList *list = NULL; qmp_for_each_command(&qmp_commands, query_commands_cb, &list); return list; }


--------------------------------------------- Result 55 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 15 / 17 / 23 / 55:   2%|         | 55/2690 [00:25<20:21,  2.16it/s][[0 (59%)]] --> [[0 (47%)]] --> Socre: 0.5271465182304382

[[[[Adv]]]]: static int decode_blocks(ALSDecContext *ctx, unsigned int ra_frame, unsigned int c, const unsigned int *div_blocks, unsigned int *js_blocks) { ALSSpecificConfig *sconf = &ctx->sconf; unsigned int offset = 0; unsigned int [[b]]; ALSBlockData [[bd]][2] = { { 0 } }; [[bd]][0].ra_block = ra_frame; [[bd]][0].const_block = ctx->const_block; [[bd]][0].shift_lsbs = ctx->shift_lsbs; [[bd]][0].opt_order = ctx->opt_order; [[bd]][0].store_prev_samples = ctx->store_prev_samples; [[bd]][0].use_ltp = ctx->use_ltp; [[bd]][0].ltp_lag = ctx->ltp_lag; [[bd]][0].ltp_gain = ctx->ltp_gain[0]; [[bd]][0].quant_cof = ctx->quant_cof[0]; [[bd]][0].lpc_cof = ctx->lpc_cof[0]; [[bd]][0].prev_raw_samples = ctx->prev_raw_samples; [[bd]][0].js_blocks = *js_blocks; [[bd]][1].ra_block = ra_frame; [[bd]][1].const_block = ctx->const_block; [[bd]][1].shift_lsbs = ctx->shift_lsbs; [[bd]][1].opt_order = ctx->opt_order; [[bd]][1].store_prev_samples = ctx->store_prev_samples; [[bd]][1].use_ltp = ctx->use_ltp; [[bd]][1].ltp_lag = ctx->ltp_lag; [[bd]][1].ltp_gain = ctx->ltp_gain[0]; [[bd]][1].quant_cof = ctx->quant_cof[0]; [[bd]][1].lpc_cof = ctx->lpc_cof[0]; [[bd]][1].prev_raw_samples = ctx->prev_raw_samples; [[bd]][1].js_blocks = *(js_blocks + 1); for ([[b]] = 0; [[b]] < ctx->num_blocks; [[b]]++) { unsigned int s; [[bd]][0].block_length = div_blocks[[[b]]]; [[bd]][1].block_length = div_blocks[[[b]]]; [[bd]][0].raw_samples = ctx->raw_samples[c ] + offset; [[bd]][1].raw_samples = ctx->raw_samples[c + 1] + offset; [[bd]][0].raw_other = [[bd]][1].raw_samples; [[bd]][1].raw_other = [[bd]][0].raw_samples; if(read_decode_block(ctx, &[[bd]][0]) || read_decode_block(ctx, &[[bd]][1])) { zero_remaining([[b]], ctx->num_blocks, div_blocks, [[bd]][0].raw_samples); zero_remaining([[b]], ctx->num_blocks, div_blocks, [[bd]][1].raw_samples); return -1; } if ([[bd]][0].js_blocks) { if ([[bd]][1].js_blocks) av_log(ctx->avctx, AV_LOG_WARNING, "Invalid channel pair!\n"); for (s = 0; s < div_blocks[[[b]]]; s++) [[bd]][0].raw_samples[s] = [[bd]][1].raw_samples[s] - [[bd]][0].raw_samples[s]; } else if ([[bd]][1].js_blocks) { for (s = 0; s < div_blocks[[[b]]]; s++) [[bd]][1].raw_samples[s] = [[bd]][1].raw_samples[s] + [[bd]][0].raw_samples[s]; } offset += div_blocks[[[b]]]; [[bd]][0].ra_block = 0; [[bd]][1].ra_block = 0; } memmove(ctx->raw_samples[c] - sconf->max_order, ctx->raw_samples[c] - sconf->max_order + sconf->frame_length, sizeof(*ctx->raw_samples[c]) * sconf->max_order); return 0; }

[[[[Adv]]]]: static int decode_blocks(ALSDecContext *ctx, unsigned int ra_frame, unsigned int c, const unsigned int *div_blocks, unsigned int *js_blocks) { ALSSpecificConfig *sconf = &ctx->sconf; unsigned int offset = 0; unsigned int [[secs]]; ALSBlockData [[heartening]][2] = { { 0 } }; [[heartening]][0].ra_block = ra_frame; [[heartening]][0].const_block = ctx->const_block; [[heartening]][0].shift_lsbs = ctx->shift_lsbs; [[heartening]][0].opt_order = ctx->opt_order; [[heartening]][0].store_prev_samples = ctx->store_prev_samples; [[heartening]][0].use_ltp = ctx->use_ltp; [[heartening]][0].ltp_lag = ctx->ltp_lag; [[heartening]][0].ltp_gain = ctx->ltp_gain[0]; [[heartening]][0].quant_cof = ctx->quant_cof[0]; [[heartening]][0].lpc_cof = ctx->lpc_cof[0]; [[heartening]][0].prev_raw_samples = ctx->prev_raw_samples; [[heartening]][0].js_blocks = *js_blocks; [[heartening]][1].ra_block = ra_frame; [[heartening]][1].const_block = ctx->const_block; [[heartening]][1].shift_lsbs = ctx->shift_lsbs; [[heartening]][1].opt_order = ctx->opt_order; [[heartening]][1].store_prev_samples = ctx->store_prev_samples; [[heartening]][1].use_ltp = ctx->use_ltp; [[heartening]][1].ltp_lag = ctx->ltp_lag; [[heartening]][1].ltp_gain = ctx->ltp_gain[0]; [[heartening]][1].quant_cof = ctx->quant_cof[0]; [[heartening]][1].lpc_cof = ctx->lpc_cof[0]; [[heartening]][1].prev_raw_samples = ctx->prev_raw_samples; [[heartening]][1].js_blocks = *(js_blocks + 1); for ([[secs]] = 0; [[secs]] < ctx->num_blocks; [[secs]]++) { unsigned int s; [[heartening]][0].block_length = div_blocks[[[secs]]]; [[heartening]][1].block_length = div_blocks[[[secs]]]; [[heartening]][0].raw_samples = ctx->raw_samples[c ] + offset; [[heartening]][1].raw_samples = ctx->raw_samples[c + 1] + offset; [[heartening]][0].raw_other = [[heartening]][1].raw_samples; [[heartening]][1].raw_other = [[heartening]][0].raw_samples; if(read_decode_block(ctx, &[[heartening]][0]) || read_decode_block(ctx, &[[heartening]][1])) { zero_remaining([[secs]], ctx->num_blocks, div_blocks, [[heartening]][0].raw_samples); zero_remaining([[secs]], ctx->num_blocks, div_blocks, [[heartening]][1].raw_samples); return -1; } if ([[heartening]][0].js_blocks) { if ([[heartening]][1].js_blocks) av_log(ctx->avctx, AV_LOG_WARNING, "Invalid channel pair!\n"); for (s = 0; s < div_blocks[[[secs]]]; s++) [[heartening]][0].raw_samples[s] = [[heartening]][1].raw_samples[s] - [[heartening]][0].raw_samples[s]; } else if ([[heartening]][1].js_blocks) { for (s = 0; s < div_blocks[[[secs]]]; s++) [[heartening]][1].raw_samples[s] = [[heartening]][1].raw_samples[s] + [[heartening]][0].raw_samples[s]; } offset += div_blocks[[[secs]]]; [[heartening]][0].ra_block = 0; [[heartening]][1].ra_block = 0; } memmove(ctx->raw_samples[c] - sconf->max_order, ctx->raw_samples[c] - sconf->max_order + sconf->frame_length, sizeof(*ctx->raw_samples[c]) * sconf->max_order); return 0; }


--------------------------------------------- Result 56 ---------------------------------------------
[Succeeded / Failed / Skipped / Total] 15 / 18 / 23 / 56:   2%|         | 56/2690 [00:26<21:05,  2.08it/s]